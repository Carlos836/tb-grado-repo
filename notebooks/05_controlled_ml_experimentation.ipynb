{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè¶ Experimentaci√≥n Controlada con German Credit Dataset\n",
        "\n",
        "## üìã Objetivos del Notebook\n",
        "\n",
        "Este notebook implementa una **experimentaci√≥n controlada** enfocada en:\n",
        "\n",
        "1. **German Credit Dataset** espec√≠ficamente\n",
        "2. **Optimizaci√≥n con Optuna** para cada modelo\n",
        "3. **M√©tricas detalladas**: AUC, PSI, Traffic Light\n",
        "4. **Comparaci√≥n entre**: Train, Test, Holdout\n",
        "5. **An√°lisis por algoritmo** individual\n",
        "\n",
        "## üéØ M√©tricas de Evaluaci√≥n\n",
        "\n",
        "### M√©tricas Principales:\n",
        "- **AUC-ROC**: Capacidad discriminante del modelo\n",
        "- **PSI (Population Stability Index)**: Estabilidad de distribuci√≥n entre muestras\n",
        "- **Traffic Light**: Precisi√≥n en grupos de riesgo para rating bancario\n",
        "\n",
        "### Traffic Light Methodology:\n",
        "- **Verde**: Modelo predice correctamente la probabilidad de default\n",
        "- **Amarillo**: Subestimaci√≥n o sobrestimaci√≥n leve\n",
        "- **Rojo**: Subestimaci√≥n o sobrestimaci√≥n significativa\n",
        "\n",
        "## üöÄ Modelos a Optimizar\n",
        "\n",
        "1. **XGBoost** - Gradient Boosting optimizado\n",
        "2. **CatBoost** - Gradient Boosting con manejo de categ√≥ricas\n",
        "3. **LightGBM** - Gradient Boosting eficiente\n",
        "4. **RandomForest** - Ensemble de √°rboles\n",
        "5. **LogisticRegression** - Modelo lineal baseline\n",
        "\n",
        "## üìä Estructura de Evaluaci√≥n\n",
        "\n",
        "Para cada modelo optimizado:\n",
        "- **Train Performance**: M√©tricas en datos de entrenamiento\n",
        "- **Test Performance**: M√©tricas en datos de prueba\n",
        "- **Holdout Performance**: M√©tricas en datos de validaci√≥n\n",
        "- **Comparaci√≥n**: An√°lisis de estabilidad y generalizaci√≥n\n",
        "\n",
        "---\n",
        "\n",
        "**¬°Empecemos con la experimentaci√≥n controlada!** üéØ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Librer√≠as importadas correctamente\n"
          ]
        }
      ],
      "source": [
        "# Importaci√≥n de librer√≠as\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import MedianPruner\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Modelos espec√≠ficos\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "# UCI Repository\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Configuraci√≥n\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas correctamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Directorio del proyecto: c:\\Users\\carlo\\OneDrive\\Documentos\\repos\\tb-grado-repo\\notebooks\\..\n",
            "üìä N√∫mero de trials Optuna: 50\n",
            "üîÑ Folds de CV: 5\n"
          ]
        }
      ],
      "source": [
        "# Configuraci√≥n del proyecto\n",
        "PROJECT_ROOT = Path('..')\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
        "CONFIGS_DIR = PROJECT_ROOT / 'configs'\n",
        "\n",
        "# Crear directorios si no existen\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Configuraci√≥n de experimento\n",
        "RANDOM_STATE = 42\n",
        "N_TRIALS = 50  # N√∫mero de trials para Optuna\n",
        "CV_FOLDS = 5   # Folds para cross-validation\n",
        "\n",
        "print(f\"üìÅ Directorio del proyecto: {PROJECT_ROOT.absolute()}\")\n",
        "print(f\"üìä N√∫mero de trials Optuna: {N_TRIALS}\")\n",
        "print(f\"üîÑ Folds de CV: {CV_FOLDS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Cargando German Credit Dataset...\n",
            "‚úÖ Dataset cargado exitosamente\n",
            "   üìä Forma de X: (1000, 20)\n",
            "   üìä Forma de y: (1000, 1)\n",
            "   üéØ Variable objetivo: class\n",
            "\n",
            "üìã Informaci√≥n del dataset:\n",
            "   Features: ['Attribute1', 'Attribute2', 'Attribute3', 'Attribute4', 'Attribute5', 'Attribute6', 'Attribute7', 'Attribute8', 'Attribute9', 'Attribute10', 'Attribute11', 'Attribute12', 'Attribute13', 'Attribute14', 'Attribute15', 'Attribute16', 'Attribute17', 'Attribute18', 'Attribute19', 'Attribute20']\n",
            "   Tipos de datos: {dtype('O'): 13, dtype('int64'): 7}\n",
            "   Valores √∫nicos en target: {1: 700, 2: 300}\n"
          ]
        }
      ],
      "source": [
        "# Cargar German Credit Dataset\n",
        "print(\"üì• Cargando German Credit Dataset...\")\n",
        "\n",
        "try:\n",
        "    # Cargar dataset desde UCI Repository\n",
        "    german_credit = fetch_ucirepo(id=144)\n",
        "    \n",
        "    # Obtener datos\n",
        "    X = german_credit.data.features\n",
        "    y = german_credit.data.targets\n",
        "    \n",
        "    print(f\"‚úÖ Dataset cargado exitosamente\")\n",
        "    print(f\"   üìä Forma de X: {X.shape}\")\n",
        "    print(f\"   üìä Forma de y: {y.shape}\")\n",
        "    print(f\"   üéØ Variable objetivo: {y.columns[0]}\")\n",
        "    \n",
        "    # Mostrar informaci√≥n del dataset\n",
        "    print(f\"\\nüìã Informaci√≥n del dataset:\")\n",
        "    print(f\"   Features: {list(X.columns)}\")\n",
        "    print(f\"   Tipos de datos: {X.dtypes.value_counts().to_dict()}\")\n",
        "    print(f\"   Valores √∫nicos en target: {y.iloc[:, 0].value_counts().to_dict()}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error cargando dataset: {e}\")\n",
        "    print(\"üîÑ Intentando cargar desde archivo local...\")\n",
        "    \n",
        "    # Intentar cargar desde archivo local si existe\n",
        "    local_file = DATA_DIR / 'german_credit.csv'\n",
        "    if local_file.exists():\n",
        "        df = pd.read_csv(local_file)\n",
        "        X = df.drop('target', axis=1)\n",
        "        y = df[['target']]\n",
        "        print(f\"‚úÖ Dataset cargado desde archivo local\")\n",
        "    else:\n",
        "        print(f\"‚ùå No se pudo cargar el dataset\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Preprocesando datos...\n",
            "üìä Distribuci√≥n del target:\n",
            "   Good Credit (0): 700 (70.0%)\n",
            "   Bad Credit (1): 300 (30.0%)\n",
            "\n",
            "üìã Tipos de variables:\n",
            "   Categ√≥ricas: 13 - ['Attribute1', 'Attribute3', 'Attribute4', 'Attribute6', 'Attribute7', 'Attribute9', 'Attribute10', 'Attribute12', 'Attribute14', 'Attribute15', 'Attribute17', 'Attribute19', 'Attribute20']\n",
            "   Num√©ricas: 7 - ['Attribute2', 'Attribute5', 'Attribute8', 'Attribute11', 'Attribute13', 'Attribute16', 'Attribute18']\n",
            "‚úÖ Variables categ√≥ricas codificadas\n",
            "üìä Forma final: (1000, 20)\n"
          ]
        }
      ],
      "source": [
        "# Preprocesamiento de datos\n",
        "print(\"üîß Preprocesando datos...\")\n",
        "\n",
        "# Convertir target a binario (1 = bad credit, 0 = good credit)\n",
        "y_binary = (y.iloc[:, 0] == 2).astype(int)  # 2 = bad credit en German dataset\n",
        "\n",
        "print(f\"üìä Distribuci√≥n del target:\")\n",
        "print(f\"   Good Credit (0): {(y_binary == 0).sum()} ({(y_binary == 0).mean()*100:.1f}%)\")\n",
        "print(f\"   Bad Credit (1): {(y_binary == 1).sum()} ({(y_binary == 1).mean()*100:.1f}%)\")\n",
        "\n",
        "# Identificar variables categ√≥ricas y num√©ricas\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"\\nüìã Tipos de variables:\")\n",
        "print(f\"   Categ√≥ricas: {len(categorical_cols)} - {categorical_cols}\")\n",
        "print(f\"   Num√©ricas: {len(numerical_cols)} - {numerical_cols}\")\n",
        "\n",
        "# Codificar variables categ√≥ricas\n",
        "X_encoded = X.copy()\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(f\"‚úÖ Variables categ√≥ricas codificadas\")\n",
        "print(f\"üìä Forma final: {X_encoded.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Dividiendo datos en Train/Test/Holdout...\n",
            "‚úÖ Divisi√≥n de datos completada:\n",
            "   üèãÔ∏è Train: 600 muestras (60%)\n",
            "   üß™ Test: 200 muestras (20%)\n",
            "   üîí Holdout: 200 muestras (20%)\n",
            "\n",
            "üìä Distribuci√≥n del target por conjunto:\n",
            "   Train: 0.300 (180/600)\n",
            "   Test: 0.300 (60/200)\n",
            "   Holdout: 0.300 (60/200)\n"
          ]
        }
      ],
      "source": [
        "# Divisi√≥n de datos: Train (60%) / Test (20%) / Holdout (20%)\n",
        "print(\"üìä Dividiendo datos en Train/Test/Holdout...\")\n",
        "\n",
        "# Primera divisi√≥n: Train+Test (80%) / Holdout (20%)\n",
        "X_temp, X_holdout, y_temp, y_holdout = train_test_split(\n",
        "    X_encoded, y_binary, \n",
        "    test_size=0.2, \n",
        "    random_state=RANDOM_STATE, \n",
        "    stratify=y_binary\n",
        ")\n",
        "\n",
        "# Segunda divisi√≥n: Train (60%) / Test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_temp, y_temp, \n",
        "    test_size=0.25,  # 0.25 de 0.8 = 0.2 del total\n",
        "    random_state=RANDOM_STATE, \n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Divisi√≥n de datos completada:\")\n",
        "print(f\"   üèãÔ∏è Train: {X_train.shape[0]} muestras (60%)\")\n",
        "print(f\"   üß™ Test: {X_test.shape[0]} muestras (20%)\")\n",
        "print(f\"   üîí Holdout: {X_holdout.shape[0]} muestras (20%)\")\n",
        "\n",
        "# Verificar distribuci√≥n del target en cada conjunto\n",
        "print(f\"\\nüìä Distribuci√≥n del target por conjunto:\")\n",
        "for name, y_set in [('Train', y_train), ('Test', y_test), ('Holdout', y_holdout)]:\n",
        "    bad_rate = y_set.mean()\n",
        "    print(f\"   {name}: {bad_rate:.3f} ({y_set.sum()}/{len(y_set)})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Clase de m√©tricas creada\n"
          ]
        }
      ],
      "source": [
        "# Clase para m√©tricas de evaluaci√≥n\n",
        "class CreditScoringMetrics:\n",
        "    \"\"\"\n",
        "    Clase para calcular m√©tricas espec√≠ficas de scoring crediticio\n",
        "    \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_auc_roc(y_true, y_pred_proba):\n",
        "        \"\"\"\n",
        "        Calcula AUC-ROC\n",
        "        \"\"\"\n",
        "        return roc_auc_score(y_true, y_pred_proba)\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_psi(expected, actual, bins=10):\n",
        "        \"\"\"\n",
        "        Calcula Population Stability Index (PSI)\n",
        "        \n",
        "        Args:\n",
        "            expected: Distribuci√≥n esperada (train)\n",
        "            actual: Distribuci√≥n actual (test/holdout)\n",
        "            bins: N√∫mero de bins para discretizar\n",
        "        \n",
        "        Returns:\n",
        "            PSI value\n",
        "        \"\"\"\n",
        "        # Crear bins basados en la distribuci√≥n esperada\n",
        "        breakpoints = np.linspace(0, 1, bins + 1)\n",
        "        breakpoints[0] = -np.inf\n",
        "        breakpoints[-1] = np.inf\n",
        "        \n",
        "        # Discretizar ambas distribuciones\n",
        "        expected_binned = pd.cut(expected, bins=breakpoints, labels=False)\n",
        "        actual_binned = pd.cut(actual, bins=breakpoints, labels=False)\n",
        "        \n",
        "        # Calcular frecuencias\n",
        "        expected_freq = pd.Series(expected_binned).value_counts(normalize=True, sort=False)\n",
        "        actual_freq = pd.Series(actual_binned).value_counts(normalize=True, sort=False)\n",
        "        \n",
        "        # Asegurar que ambos tengan los mismos bins\n",
        "        for i in range(bins):\n",
        "            if i not in expected_freq.index:\n",
        "                expected_freq[i] = 0\n",
        "            if i not in actual_freq.index:\n",
        "                actual_freq[i] = 0\n",
        "        \n",
        "        expected_freq = expected_freq.sort_index()\n",
        "        actual_freq = actual_freq.sort_index()\n",
        "        \n",
        "        # Calcular PSI\n",
        "        psi = 0\n",
        "        for i in range(bins):\n",
        "            if expected_freq.iloc[i] > 0:\n",
        "                psi += (actual_freq.iloc[i] - expected_freq.iloc[i]) * \\\n",
        "                       np.log(actual_freq.iloc[i] / expected_freq.iloc[i])\n",
        "        \n",
        "        return psi\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_traffic_light(y_true, y_pred_proba, n_groups=10):\n",
        "        \"\"\"\n",
        "        Calcula Traffic Light para grupos de riesgo\n",
        "        \n",
        "        Args:\n",
        "            y_true: Valores reales\n",
        "            y_pred_proba: Probabilidades predichas\n",
        "            n_groups: N√∫mero de grupos de riesgo\n",
        "        \n",
        "        Returns:\n",
        "            Dict con estad√≠sticas de Traffic Light\n",
        "        \"\"\"\n",
        "        # Crear grupos de riesgo basados en probabilidades predichas\n",
        "        df = pd.DataFrame({\n",
        "            'actual': y_true,\n",
        "            'predicted': y_pred_proba\n",
        "        })\n",
        "        \n",
        "        # Ordenar por probabilidad predicha (descendente)\n",
        "        df = df.sort_values('predicted', ascending=False).reset_index(drop=True)\n",
        "        \n",
        "        # Crear grupos de riesgo\n",
        "        group_size = len(df) // n_groups\n",
        "        df['group'] = 0\n",
        "        \n",
        "        for i in range(n_groups):\n",
        "            start_idx = i * group_size\n",
        "            if i == n_groups - 1:  # √öltimo grupo incluye el resto\n",
        "                end_idx = len(df)\n",
        "            else:\n",
        "                end_idx = (i + 1) * group_size\n",
        "            \n",
        "            df.loc[start_idx:end_idx-1, 'group'] = i + 1\n",
        "        \n",
        "        # Calcular m√©tricas por grupo\n",
        "        group_stats = []\n",
        "        for group in range(1, n_groups + 1):\n",
        "            group_data = df[df['group'] == group]\n",
        "            if len(group_data) > 0:\n",
        "                actual_rate = group_data['actual'].mean()\n",
        "                predicted_rate = group_data['predicted'].mean()\n",
        "                \n",
        "                # Determinar color del sem√°foro\n",
        "                diff = abs(actual_rate - predicted_rate)\n",
        "                if diff <= 0.05:  # 5% de tolerancia\n",
        "                    color = 'green'\n",
        "                elif diff <= 0.10:  # 10% de tolerancia\n",
        "                    color = 'yellow'\n",
        "                else:\n",
        "                    color = 'red'\n",
        "                \n",
        "                group_stats.append({\n",
        "                    'group': group,\n",
        "                    'actual_rate': actual_rate,\n",
        "                    'predicted_rate': predicted_rate,\n",
        "                    'difference': diff,\n",
        "                    'color': color,\n",
        "                    'size': len(group_data)\n",
        "                })\n",
        "        \n",
        "        # Calcular estad√≠sticas generales\n",
        "        colors = [stat['color'] for stat in group_stats]\n",
        "        green_pct = colors.count('green') / len(colors) * 100\n",
        "        yellow_pct = colors.count('yellow') / len(colors) * 100\n",
        "        red_pct = colors.count('red') / len(colors) * 100\n",
        "        \n",
        "        return {\n",
        "            'group_stats': group_stats,\n",
        "            'green_percentage': green_pct,\n",
        "            'yellow_percentage': yellow_pct,\n",
        "            'red_percentage': red_pct,\n",
        "            'total_groups': len(group_stats)\n",
        "        }\n",
        "    \n",
        "    @classmethod\n",
        "    def evaluate_model(cls, y_true, y_pred_proba, y_train_proba=None):\n",
        "        \"\"\"\n",
        "        Eval√∫a un modelo con todas las m√©tricas\n",
        "        \n",
        "        Args:\n",
        "            y_true: Valores reales\n",
        "            y_pred_proba: Probabilidades predichas\n",
        "            y_train_proba: Probabilidades en train (para PSI)\n",
        "        \n",
        "        Returns:\n",
        "            Dict con todas las m√©tricas\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "        \n",
        "        # AUC-ROC\n",
        "        results['auc_roc'] = cls.calculate_auc_roc(y_true, y_pred_proba)\n",
        "        \n",
        "        # PSI (si se proporcionan datos de train)\n",
        "        if y_train_proba is not None:\n",
        "            results['psi'] = cls.calculate_psi(y_train_proba, y_pred_proba)\n",
        "        \n",
        "        # Traffic Light\n",
        "        traffic_light = cls.calculate_traffic_light(y_true, y_pred_proba)\n",
        "        results['traffic_light'] = traffic_light\n",
        "        \n",
        "        return results\n",
        "\n",
        "print(\"‚úÖ Clase de m√©tricas creada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Clase de optimizaci√≥n creada\n"
          ]
        }
      ],
      "source": [
        "# Clase para optimizaci√≥n con Optuna\n",
        "class OptunaOptimizer:\n",
        "    \"\"\"\n",
        "    Clase para optimizar modelos con Optuna\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, X_train, y_train, cv_folds=5, n_trials=50):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.cv_folds = cv_folds\n",
        "        self.n_trials = n_trials\n",
        "        self.best_params = {}\n",
        "        self.best_scores = {}\n",
        "        \n",
        "    def optimize_xgboost(self):\n",
        "        \"\"\"\n",
        "        Optimiza XGBoost con Optuna\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
        "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = xgb.XGBClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['xgboost'] = study.best_params\n",
        "        self.best_scores['xgboost'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_lightgbm(self):\n",
        "        \"\"\"\n",
        "        Optimiza LightGBM con Optuna\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
        "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
        "                'random_state': RANDOM_STATE,\n",
        "                'verbose': -1\n",
        "            }\n",
        "            \n",
        "            model = lgb.LGBMClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['lightgbm'] = study.best_params\n",
        "        self.best_scores['lightgbm'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_catboost(self):\n",
        "        \"\"\"\n",
        "        Optimiza CatBoost con Optuna\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'iterations': trial.suggest_int('iterations', 100, 1000),\n",
        "                'depth': trial.suggest_int('depth', 3, 10),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
        "                'random_seed': RANDOM_STATE,\n",
        "                'verbose': False\n",
        "            }\n",
        "            \n",
        "            model = cb.CatBoostClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['catboost'] = study.best_params\n",
        "        self.best_scores['catboost'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_random_forest(self):\n",
        "        \"\"\"\n",
        "        Optimiza Random Forest con Optuna\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = RandomForestClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['random_forest'] = study.best_params\n",
        "        self.best_scores['random_forest'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_logistic_regression(self):\n",
        "        \"\"\"\n",
        "        Optimiza Logistic Regression con Optuna\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 0.01, 100, log=True),\n",
        "                'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "                'solver': 'liblinear',  # Compatible con l1 y l2\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = LogisticRegression(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['logistic_regression'] = study.best_params\n",
        "        self.best_scores['logistic_regression'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "\n",
        "print(\"‚úÖ Clase de optimizaci√≥n creada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Optimizador inicializado\n",
            "   üìä Datos de entrenamiento: (600, 20)\n",
            "   üîÑ Folds de CV: 5\n",
            "   üéØ Trials por modelo: 50\n"
          ]
        }
      ],
      "source": [
        "# Inicializar optimizador\n",
        "optimizer = OptunaOptimizer(X_train, y_train, cv_folds=CV_FOLDS, n_trials=N_TRIALS)\n",
        "\n",
        "print(f\"üöÄ Optimizador inicializado\")\n",
        "print(f\"   üìä Datos de entrenamiento: {X_train.shape}\")\n",
        "print(f\"   üîÑ Folds de CV: {CV_FOLDS}\")\n",
        "print(f\"   üéØ Trials por modelo: {N_TRIALS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizar todos los modelos\n",
        "print(\"üî• OPTIMIZANDO TODOS LOS MODELOS...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Lista de modelos a optimizar\n",
        "models_to_optimize = [\n",
        "    ('XGBoost', optimizer.optimize_xgboost),\n",
        "    ('LightGBM', optimizer.optimize_lightgbm),\n",
        "    ('CatBoost', optimizer.optimize_catboost),\n",
        "    ('RandomForest', optimizer.optimize_random_forest),\n",
        "    ('LogisticRegression', optimizer.optimize_logistic_regression)\n",
        "]\n",
        "\n",
        "# Optimizar cada modelo\n",
        "for model_name, optimize_func in models_to_optimize:\n",
        "    print(f\"\\nüî• Optimizando {model_name}...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        best_params = optimize_func()\n",
        "        end_time = time.time()\n",
        "        \n",
        "        print(f\"‚úÖ {model_name} optimizado en {end_time - start_time:.1f} segundos\")\n",
        "        print(f\"   üèÜ Mejor CV Score: {optimizer.best_scores[model_name.lower().replace(' ', '_')]:.4f}\")\n",
        "        print(f\"   ‚öôÔ∏è Mejores par√°metros: {best_params}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error optimizando {model_name}: {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Optimizaci√≥n completada para todos los modelos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen de optimizaci√≥n\n",
        "print(\"üìä RESUMEN DE OPTIMIZACI√ìN\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for model_name, score in optimizer.best_scores.items():\n",
        "    print(f\"{model_name.upper()}: {score:.4f}\")\n",
        "\n",
        "# Encontrar el mejor modelo\n",
        "best_model_name = max(optimizer.best_scores, key=optimizer.best_scores.get)\n",
        "best_score = optimizer.best_scores[best_model_name]\n",
        "\n",
        "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name.upper()}\")\n",
        "print(f\"üìä Mejor CV Score: {best_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar modelos optimizados y evaluar\n",
        "print(\"üèãÔ∏è Entrenando modelos optimizados...\")\n",
        "\n",
        "# Crear modelos con mejores par√°metros\n",
        "models = {\n",
        "    'XGBoost': xgb.XGBClassifier(**optimizer.best_params['xgboost'], random_state=RANDOM_STATE),\n",
        "    'LightGBM': lgb.LGBMClassifier(**optimizer.best_params['lightgbm'], random_state=RANDOM_STATE, verbose=-1),\n",
        "    'CatBoost': cb.CatBoostClassifier(**optimizer.best_params['catboost'], random_seed=RANDOM_STATE, verbose=False),\n",
        "    'RandomForest': RandomForestClassifier(**optimizer.best_params['random_forest'], random_state=RANDOM_STATE),\n",
        "    'LogisticRegression': LogisticRegression(**optimizer.best_params['logistic_regression'], random_state=RANDOM_STATE)\n",
        "}\n",
        "\n",
        "# Entrenar todos los modelos\n",
        "trained_models = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"   Entrenando {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    trained_models[name] = model\n",
        "\n",
        "print(\"‚úÖ Todos los modelos entrenados\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluar modelos en Train, Test y Holdout\n",
        "print(\"üìä EVALUANDO MODELOS EN TRAIN/TEST/HOLDOUT...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in trained_models.items():\n",
        "    print(f\"\\nüîç Evaluando {model_name}...\")\n",
        "    \n",
        "    # Predicciones en cada conjunto\n",
        "    train_proba = model.predict_proba(X_train)[:, 1]\n",
        "    test_proba = model.predict_proba(X_test)[:, 1]\n",
        "    holdout_proba = model.predict_proba(X_holdout)[:, 1]\n",
        "    \n",
        "    # Evaluar en cada conjunto\n",
        "    train_metrics = CreditScoringMetrics.evaluate_model(y_train, train_proba)\n",
        "    test_metrics = CreditScoringMetrics.evaluate_model(y_test, test_proba, train_proba)\n",
        "    holdout_metrics = CreditScoringMetrics.evaluate_model(y_holdout, holdout_proba, train_proba)\n",
        "    \n",
        "    results[model_name] = {\n",
        "        'train': train_metrics,\n",
        "        'test': test_metrics,\n",
        "        'holdout': holdout_metrics\n",
        "    }\n",
        "    \n",
        "    # Mostrar resultados\n",
        "    print(f\"   üìà Train  - AUC: {train_metrics['auc_roc']:.4f}, PSI: N/A, Green: {train_metrics['traffic_light']['green_percentage']:.1f}%\")\n",
        "    print(f\"   üß™ Test   - AUC: {test_metrics['auc_roc']:.4f}, PSI: {test_metrics['psi']:.4f}, Green: {test_metrics['traffic_light']['green_percentage']:.1f}%\")\n",
        "    print(f\"   üîí Holdout - AUC: {holdout_metrics['auc_roc']:.4f}, PSI: {holdout_metrics['psi']:.4f}, Green: {holdout_metrics['traffic_light']['green_percentage']:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear tabla comparativa\n",
        "print(\"üìã TABLA COMPARATIVA DE RESULTADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Crear DataFrame con resultados\n",
        "comparison_data = []\n",
        "\n",
        "for model_name, model_results in results.items():\n",
        "    for dataset in ['train', 'test', 'holdout']:\n",
        "        metrics = model_results[dataset]\n",
        "        \n",
        "        row = {\n",
        "            'Modelo': model_name,\n",
        "            'Dataset': dataset.capitalize(),\n",
        "            'AUC-ROC': metrics['auc_roc'],\n",
        "            'PSI': metrics.get('psi', np.nan),\n",
        "            'Traffic_Light_Green_%': metrics['traffic_light']['green_percentage'],\n",
        "            'Traffic_Light_Yellow_%': metrics['traffic_light']['yellow_percentage'],\n",
        "            'Traffic_Light_Red_%': metrics['traffic_light']['red_percentage']\n",
        "        }\n",
        "        comparison_data.append(row)\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "# Mostrar tabla\n",
        "display(comparison_df.round(4))\n",
        "\n",
        "# Guardar resultados\n",
        "comparison_df.to_csv(RESULTS_DIR / 'model_comparison_results.csv', index=False)\n",
        "print(f\"\\nüíæ Resultados guardados en: {RESULTS_DIR / 'model_comparison_results.csv'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizaciones\n",
        "print(\"üìä CREANDO VISUALIZACIONES...\")\n",
        "\n",
        "# Configurar subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Comparaci√≥n de Modelos por Dataset', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. AUC-ROC por dataset\n",
        "ax1 = axes[0, 0]\n",
        "pivot_auc = comparison_df.pivot(index='Modelo', columns='Dataset', values='AUC-ROC')\n",
        "pivot_auc.plot(kind='bar', ax=ax1, width=0.8)\n",
        "ax1.set_title('AUC-ROC por Dataset')\n",
        "ax1.set_ylabel('AUC-ROC')\n",
        "ax1.legend(title='Dataset')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.axhline(y=0.65, color='red', linestyle='--', alpha=0.7, label='Umbral (0.65)')\n",
        "\n",
        "# 2. PSI por dataset (solo test y holdout)\n",
        "ax2 = axes[0, 1]\n",
        "psi_data = comparison_df[comparison_df['Dataset'].isin(['Test', 'Holdout'])]\n",
        "pivot_psi = psi_data.pivot(index='Modelo', columns='Dataset', values='PSI')\n",
        "pivot_psi.plot(kind='bar', ax=ax2, width=0.8)\n",
        "ax2.set_title('PSI por Dataset')\n",
        "ax2.set_ylabel('PSI')\n",
        "ax2.legend(title='Dataset')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.axhline(y=0.10, color='red', linestyle='--', alpha=0.7, label='Umbral (0.10)')\n",
        "\n",
        "# 3. Traffic Light Green % por dataset\n",
        "ax3 = axes[1, 0]\n",
        "pivot_green = comparison_df.pivot(index='Modelo', columns='Dataset', values='Traffic_Light_Green_%')\n",
        "pivot_green.plot(kind='bar', ax=ax3, width=0.8)\n",
        "ax3.set_title('Traffic Light Green % por Dataset')\n",
        "ax3.set_ylabel('Green %')\n",
        "ax3.legend(title='Dataset')\n",
        "ax3.tick_params(axis='x', rotation=45)\n",
        "ax3.axhline(y=80, color='red', linestyle='--', alpha=0.7, label='Umbral (80%)')\n",
        "\n",
        "# 4. Comparaci√≥n de estabilidad (AUC Test vs Holdout)\n",
        "ax4 = axes[1, 1]\n",
        "test_auc = comparison_df[comparison_df['Dataset'] == 'Test']['AUC-ROC'].values\n",
        "holdout_auc = comparison_df[comparison_df['Dataset'] == 'Holdout']['AUC-ROC'].values\n",
        "models_list = comparison_df[comparison_df['Dataset'] == 'Test']['Modelo'].values\n",
        "\n",
        "x = np.arange(len(models_list))\n",
        "width = 0.35\n",
        "\n",
        "ax4.bar(x - width/2, test_auc, width, label='Test', alpha=0.8)\n",
        "ax4.bar(x + width/2, holdout_auc, width, label='Holdout', alpha=0.8)\n",
        "\n",
        "ax4.set_title('Estabilidad: Test vs Holdout AUC')\n",
        "ax4.set_ylabel('AUC-ROC')\n",
        "ax4.set_xticks(x)\n",
        "ax4.set_xticklabels(models_list, rotation=45)\n",
        "ax4.legend()\n",
        "ax4.axhline(y=0.65, color='red', linestyle='--', alpha=0.7, label='Umbral (0.65)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Visualizaciones completadas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lisis detallado del mejor modelo\n",
        "print(\"üèÜ AN√ÅLISIS DEL MEJOR MODELO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Encontrar el mejor modelo basado en AUC en holdout\n",
        "holdout_results = comparison_df[comparison_df['Dataset'] == 'Holdout']\n",
        "best_model_name = holdout_results.loc[holdout_results['AUC-ROC'].idxmax(), 'Modelo']\n",
        "best_model_auc = holdout_results['AUC-ROC'].max()\n",
        "\n",
        "print(f\"ü•á Mejor modelo: {best_model_name}\")\n",
        "print(f\"üìä Mejor AUC en Holdout: {best_model_auc:.4f}\")\n",
        "\n",
        "# Mostrar m√©tricas detalladas del mejor modelo\n",
        "best_model_results = results[best_model_name]\n",
        "\n",
        "print(f\"\\nüìà M√âTRICAS DETALLADAS DE {best_model_name.upper()}:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for dataset, metrics in best_model_results.items():\n",
        "    print(f\"\\n{dataset.upper()}:\")\n",
        "    print(f\"   AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
        "    if 'psi' in metrics:\n",
        "        print(f\"   PSI: {metrics['psi']:.4f}\")\n",
        "    print(f\"   Traffic Light:\")\n",
        "    print(f\"      Verde: {metrics['traffic_light']['green_percentage']:.1f}%\")\n",
        "    print(f\"      Amarillo: {metrics['traffic_light']['yellow_percentage']:.1f}%\")\n",
        "    print(f\"      Rojo: {metrics['traffic_light']['red_percentage']:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen ejecutivo\n",
        "print(\"üìã RESUMEN EJECUTIVO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Estad√≠sticas generales\n",
        "print(f\"\\nüìä ESTAD√çSTICAS GENERALES:\")\n",
        "print(f\"   Total de modelos evaluados: {len(trained_models)}\")\n",
        "print(f\"   Mejor AUC en Holdout: {best_model_auc:.4f}\")\n",
        "print(f\"   Modelos que superan umbral AUC (0.65): {len(holdout_results[holdout_results['AUC-ROC'] >= 0.65])}\")\n",
        "\n",
        "# An√°lisis de estabilidad\n",
        "print(f\"\\nüîÑ AN√ÅLISIS DE ESTABILIDAD:\")\n",
        "for model_name in trained_models.keys():\n",
        "    test_auc = comparison_df[(comparison_df['Modelo'] == model_name) & (comparison_df['Dataset'] == 'Test')]['AUC-ROC'].iloc[0]\n",
        "    holdout_auc = comparison_df[(comparison_df['Modelo'] == model_name) & (comparison_df['Dataset'] == 'Holdout')]['AUC-ROC'].iloc[0]\n",
        "    stability = abs(test_auc - holdout_auc)\n",
        "    \n",
        "    print(f\"   {model_name}: {stability:.4f} ({'‚úÖ Estable' if stability < 0.05 else '‚ö†Ô∏è Inestable'})\")\n",
        "\n",
        "# Recomendaciones\n",
        "print(f\"\\nüí° RECOMENDACIONES:\")\n",
        "print(f\"   1. Modelo recomendado: {best_model_name}\")\n",
        "print(f\"   2. AUC en Holdout: {best_model_auc:.4f} ({'‚úÖ Cumple' if best_model_auc >= 0.65 else '‚ùå No cumple'} umbral)\")\n",
        "\n",
        "if best_model_auc < 0.65:\n",
        "    print(f\"   3. ‚ö†Ô∏è Ning√∫n modelo alcanza el umbral m√≠nimo de AUC (0.65)\")\n",
        "    print(f\"      Considerar: Feature engineering, m√°s datos, o modelos m√°s complejos\")\n",
        "\n",
        "print(f\"\\n‚úÖ An√°lisis completo finalizado\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
