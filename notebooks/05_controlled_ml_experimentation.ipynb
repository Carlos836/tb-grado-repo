{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè¶ Experimentaci√≥n Controlada con German Credit Dataset\n",
        "\n",
        "## üìã Objetivos del Notebook\n",
        "\n",
        "Este notebook implementa una **experimentaci√≥n controlada** enfocada en:\n",
        "\n",
        "1. **German Credit Dataset** espec√≠ficamente\n",
        "2. **Optimizaci√≥n con Optuna** para cada modelo\n",
        "3. **M√©tricas detalladas**: AUC, PSI, Traffic Light\n",
        "4. **Comparaci√≥n entre**: Train, Test, Holdout\n",
        "5. **An√°lisis por algoritmo** individual\n",
        "\n",
        "## üéØ M√©tricas de Evaluaci√≥n\n",
        "\n",
        "### M√©tricas Principales:\n",
        "- **AUC-ROC**: Capacidad discriminante del modelo\n",
        "- **PSI (Population Stability Index)**: Estabilidad de distribuci√≥n entre muestras\n",
        "- **Traffic Light**: Precisi√≥n en grupos de riesgo para rating bancario\n",
        "\n",
        "### Traffic Light Methodology:\n",
        "- **Verde**: Modelo predice correctamente la probabilidad de default\n",
        "- **Amarillo**: Subestimaci√≥n o sobrestimaci√≥n leve\n",
        "- **Rojo**: Subestimaci√≥n o sobrestimaci√≥n significativa\n",
        "\n",
        "## üöÄ Modelos a Optimizar\n",
        "\n",
        "1. **XGBoost** - Gradient Boosting optimizado\n",
        "2. **CatBoost** - Gradient Boosting con manejo de categ√≥ricas\n",
        "3. **LightGBM** - Gradient Boosting eficiente\n",
        "4. **RandomForest** - Ensemble de √°rboles\n",
        "5. **LogisticRegression** - Modelo lineal baseline\n",
        "\n",
        "## üìä Estructura de Evaluaci√≥n\n",
        "\n",
        "Para cada modelo optimizado:\n",
        "- **Train Performance**: M√©tricas en datos de entrenamiento\n",
        "- **Test Performance**: M√©tricas en datos de prueba\n",
        "- **Holdout Performance**: M√©tricas en datos de validaci√≥n\n",
        "- **Comparaci√≥n**: An√°lisis de estabilidad y generalizaci√≥n\n",
        "\n",
        "---\n",
        "\n",
        "**¬°Empecemos con la experimentaci√≥n controlada!** üéØ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Librer√≠as importadas correctamente\n"
          ]
        }
      ],
      "source": [
        "# Importaci√≥n de librer√≠as\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import MedianPruner\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Modelos espec√≠ficos\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "# UCI Repository\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Configuraci√≥n\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas correctamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Directorio del proyecto: c:\\Users\\carlo\\OneDrive\\Documentos\\repos\\tb-grado-repo\\notebooks\\..\n",
            "üìä N√∫mero de trials Optuna: 50\n",
            "üîÑ Folds de CV: 5\n"
          ]
        }
      ],
      "source": [
        "# Configuraci√≥n del proyecto\n",
        "PROJECT_ROOT = Path('..')\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
        "CONFIGS_DIR = PROJECT_ROOT / 'configs'\n",
        "\n",
        "# Crear directorios si no existen\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Configuraci√≥n de experimento\n",
        "RANDOM_STATE = 42\n",
        "N_TRIALS = 100  # Aumentado para grillas m√°s finas\n",
        "CV_FOLDS = 5   # Folds para cross-validation\n",
        "\n",
        "print(f\"üìÅ Directorio del proyecto: {PROJECT_ROOT.absolute()}\")\n",
        "print(f\"üìä N√∫mero de trials Optuna: {N_TRIALS}\")\n",
        "print(f\"üîÑ Folds de CV: {CV_FOLDS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Cargando German Credit Dataset...\n",
            "‚úÖ Dataset cargado exitosamente\n",
            "   üìä Forma de X: (1000, 20)\n",
            "   üìä Forma de y: (1000, 1)\n",
            "   üéØ Variable objetivo: class\n",
            "\n",
            "üìã Informaci√≥n del dataset:\n",
            "   Features: ['Attribute1', 'Attribute2', 'Attribute3', 'Attribute4', 'Attribute5', 'Attribute6', 'Attribute7', 'Attribute8', 'Attribute9', 'Attribute10', 'Attribute11', 'Attribute12', 'Attribute13', 'Attribute14', 'Attribute15', 'Attribute16', 'Attribute17', 'Attribute18', 'Attribute19', 'Attribute20']\n",
            "   Tipos de datos: {dtype('O'): 13, dtype('int64'): 7}\n",
            "   Valores √∫nicos en target: {1: 700, 2: 300}\n"
          ]
        }
      ],
      "source": [
        "# Cargar German Credit Dataset\n",
        "print(\"üì• Cargando German Credit Dataset...\")\n",
        "\n",
        "try:\n",
        "    # Cargar dataset desde UCI Repository\n",
        "    german_credit = fetch_ucirepo(id=144)\n",
        "    \n",
        "    # Obtener datos\n",
        "    X = german_credit.data.features\n",
        "    y = german_credit.data.targets\n",
        "    \n",
        "    print(f\"‚úÖ Dataset cargado exitosamente\")\n",
        "    print(f\"   üìä Forma de X: {X.shape}\")\n",
        "    print(f\"   üìä Forma de y: {y.shape}\")\n",
        "    print(f\"   üéØ Variable objetivo: {y.columns[0]}\")\n",
        "    \n",
        "    # Mostrar informaci√≥n del dataset\n",
        "    print(f\"\\nüìã Informaci√≥n del dataset:\")\n",
        "    print(f\"   Features: {list(X.columns)}\")\n",
        "    print(f\"   Tipos de datos: {X.dtypes.value_counts().to_dict()}\")\n",
        "    print(f\"   Valores √∫nicos en target: {y.iloc[:, 0].value_counts().to_dict()}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error cargando dataset: {e}\")\n",
        "    print(\"üîÑ Intentando cargar desde archivo local...\")\n",
        "    \n",
        "    # Intentar cargar desde archivo local si existe\n",
        "    local_file = DATA_DIR / 'german_credit.csv'\n",
        "    if local_file.exists():\n",
        "        df = pd.read_csv(local_file)\n",
        "        X = df.drop('target', axis=1)\n",
        "        y = df[['target']]\n",
        "        print(f\"‚úÖ Dataset cargado desde archivo local\")\n",
        "    else:\n",
        "        print(f\"‚ùå No se pudo cargar el dataset\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Preprocesando datos...\n",
            "üìä Distribuci√≥n del target:\n",
            "   Good Credit (0): 700 (70.0%)\n",
            "   Bad Credit (1): 300 (30.0%)\n",
            "\n",
            "üìã Tipos de variables:\n",
            "   Categ√≥ricas: 13 - ['Attribute1', 'Attribute3', 'Attribute4', 'Attribute6', 'Attribute7', 'Attribute9', 'Attribute10', 'Attribute12', 'Attribute14', 'Attribute15', 'Attribute17', 'Attribute19', 'Attribute20']\n",
            "   Num√©ricas: 7 - ['Attribute2', 'Attribute5', 'Attribute8', 'Attribute11', 'Attribute13', 'Attribute16', 'Attribute18']\n",
            "‚úÖ Variables categ√≥ricas codificadas\n",
            "üìä Forma final: (1000, 20)\n"
          ]
        }
      ],
      "source": [
        "# Preprocesamiento de datos\n",
        "print(\"üîß Preprocesando datos...\")\n",
        "\n",
        "# Convertir target a binario (1 = bad credit, 0 = good credit)\n",
        "y_binary = (y.iloc[:, 0] == 2).astype(int)  # 2 = bad credit en German dataset\n",
        "\n",
        "print(f\"üìä Distribuci√≥n del target:\")\n",
        "print(f\"   Good Credit (0): {(y_binary == 0).sum()} ({(y_binary == 0).mean()*100:.1f}%)\")\n",
        "print(f\"   Bad Credit (1): {(y_binary == 1).sum()} ({(y_binary == 1).mean()*100:.1f}%)\")\n",
        "\n",
        "# Identificar variables categ√≥ricas y num√©ricas\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"\\nüìã Tipos de variables:\")\n",
        "print(f\"   Categ√≥ricas: {len(categorical_cols)} - {categorical_cols}\")\n",
        "print(f\"   Num√©ricas: {len(numerical_cols)} - {numerical_cols}\")\n",
        "\n",
        "# Codificar variables categ√≥ricas\n",
        "X_encoded = X.copy()\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(f\"‚úÖ Variables categ√≥ricas codificadas\")\n",
        "print(f\"üìä Forma final: {X_encoded.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Dividiendo datos en Train/Test/Holdout...\n",
            "‚úÖ Divisi√≥n de datos completada:\n",
            "   üèãÔ∏è Train: 600 muestras (60%)\n",
            "   üß™ Test: 200 muestras (20%)\n",
            "   üîí Holdout: 200 muestras (20%)\n",
            "\n",
            "üìä Distribuci√≥n del target por conjunto:\n",
            "   Train: 0.300 (180/600)\n",
            "   Test: 0.300 (60/200)\n",
            "   Holdout: 0.300 (60/200)\n"
          ]
        }
      ],
      "source": [
        "# Divisi√≥n de datos: Train (60%) / Test (20%) / Holdout (20%)\n",
        "print(\"üìä Dividiendo datos en Train/Test/Holdout...\")\n",
        "\n",
        "# Primera divisi√≥n: Train+Test (80%) / Holdout (20%)\n",
        "X_temp, X_holdout, y_temp, y_holdout = train_test_split(\n",
        "    X_encoded, y_binary, \n",
        "    test_size=0.2, \n",
        "    random_state=RANDOM_STATE, \n",
        "    stratify=y_binary\n",
        ")\n",
        "\n",
        "# Segunda divisi√≥n: Train (60%) / Test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_temp, y_temp, \n",
        "    test_size=0.25,  # 0.25 de 0.8 = 0.2 del total\n",
        "    random_state=RANDOM_STATE, \n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Divisi√≥n de datos completada:\")\n",
        "print(f\"   üèãÔ∏è Train: {X_train.shape[0]} muestras (60%)\")\n",
        "print(f\"   üß™ Test: {X_test.shape[0]} muestras (20%)\")\n",
        "print(f\"   üîí Holdout: {X_holdout.shape[0]} muestras (20%)\")\n",
        "\n",
        "# Verificar distribuci√≥n del target en cada conjunto\n",
        "print(f\"\\nüìä Distribuci√≥n del target por conjunto:\")\n",
        "for name, y_set in [('Train', y_train), ('Test', y_test), ('Holdout', y_holdout)]:\n",
        "    bad_rate = y_set.mean()\n",
        "    print(f\"   {name}: {bad_rate:.3f} ({y_set.sum()}/{len(y_set)})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Clase de m√©tricas creada\n"
          ]
        }
      ],
      "source": [
        "# Clase para m√©tricas de evaluaci√≥n\n",
        "class CreditScoringMetrics:\n",
        "    \"\"\"\n",
        "    Clase para calcular m√©tricas espec√≠ficas de scoring crediticio\n",
        "    \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_auc_roc(y_true, y_pred_proba):\n",
        "        \"\"\"\n",
        "        Calcula AUC-ROC\n",
        "        \"\"\"\n",
        "        return roc_auc_score(y_true, y_pred_proba)\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_psi(expected, actual, bins=10):\n",
        "        \"\"\"\n",
        "        Calcula Population Stability Index (PSI)\n",
        "        \n",
        "        Args:\n",
        "            expected: Distribuci√≥n esperada (train)\n",
        "            actual: Distribuci√≥n actual (test/holdout)\n",
        "            bins: N√∫mero de bins para discretizar\n",
        "        \n",
        "        Returns:\n",
        "            PSI value\n",
        "        \"\"\"\n",
        "        # Crear bins basados en la distribuci√≥n esperada\n",
        "        breakpoints = np.linspace(0, 1, bins + 1)\n",
        "        breakpoints[0] = -np.inf\n",
        "        breakpoints[-1] = np.inf\n",
        "        \n",
        "        # Discretizar ambas distribuciones\n",
        "        expected_binned = pd.cut(expected, bins=breakpoints, labels=False)\n",
        "        actual_binned = pd.cut(actual, bins=breakpoints, labels=False)\n",
        "        \n",
        "        # Calcular frecuencias\n",
        "        expected_freq = pd.Series(expected_binned).value_counts(normalize=True, sort=False)\n",
        "        actual_freq = pd.Series(actual_binned).value_counts(normalize=True, sort=False)\n",
        "        \n",
        "        # Asegurar que ambos tengan los mismos bins\n",
        "        for i in range(bins):\n",
        "            if i not in expected_freq.index:\n",
        "                expected_freq[i] = 0\n",
        "            if i not in actual_freq.index:\n",
        "                actual_freq[i] = 0\n",
        "        \n",
        "        expected_freq = expected_freq.sort_index()\n",
        "        actual_freq = actual_freq.sort_index()\n",
        "        \n",
        "        # Calcular PSI\n",
        "        psi = 0\n",
        "        for i in range(bins):\n",
        "            if expected_freq.iloc[i] > 0:\n",
        "                psi += (actual_freq.iloc[i] - expected_freq.iloc[i]) * \\\n",
        "                       np.log(actual_freq.iloc[i] / expected_freq.iloc[i])\n",
        "        \n",
        "        return psi\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_traffic_light(y_true, y_pred_proba, n_groups=10):\n",
        "        \"\"\"\n",
        "        Calcula Traffic Light para grupos de riesgo por deciles\n",
        "        \n",
        "        Args:\n",
        "            y_true: Valores reales\n",
        "            y_pred_proba: Probabilidades predichas\n",
        "            n_groups: N√∫mero de grupos de riesgo (deciles)\n",
        "        \n",
        "        Returns:\n",
        "            Dict con estad√≠sticas de Traffic Light\n",
        "        \"\"\"\n",
        "        # Crear DataFrame con datos\n",
        "        df = pd.DataFrame({\n",
        "            'actual': y_true,\n",
        "            'predicted': y_pred_proba\n",
        "        })\n",
        "        \n",
        "        # Crear deciles basados en probabilidades predichas (descendente)\n",
        "        # Decil 1 = mayor riesgo, Decil 10 = menor riesgo\n",
        "        df['decile'] = pd.qcut(df['predicted'], q=n_groups, labels=False, duplicates='drop') + 1\n",
        "        \n",
        "        # Calcular m√©tricas por decil\n",
        "        group_stats = []\n",
        "        for decile in range(1, n_groups + 1):\n",
        "            decile_data = df[df['decile'] == decile]\n",
        "            if len(decile_data) > 0:\n",
        "                actual_rate = decile_data['actual'].mean()\n",
        "                predicted_rate = decile_data['predicted'].mean()\n",
        "                \n",
        "                # Determinar color del sem√°foro\n",
        "                diff = abs(actual_rate - predicted_rate)\n",
        "                if diff <= 0.05:  # 5% de tolerancia\n",
        "                    color = 'green'\n",
        "                elif diff <= 0.10:  # 10% de tolerancia\n",
        "                    color = 'yellow'\n",
        "                else:\n",
        "                    color = 'red'\n",
        "                \n",
        "                group_stats.append({\n",
        "                    'decile': decile,\n",
        "                    'actual_rate': actual_rate,\n",
        "                    'predicted_rate': predicted_rate,\n",
        "                    'difference': diff,\n",
        "                    'color': color,\n",
        "                    'size': len(decile_data),\n",
        "                    'min_prob': decile_data['predicted'].min(),\n",
        "                    'max_prob': decile_data['predicted'].max(),\n",
        "                    'avg_prob': decile_data['predicted'].mean()\n",
        "                })\n",
        "        \n",
        "        # Calcular estad√≠sticas generales\n",
        "        colors = [stat['color'] for stat in group_stats]\n",
        "        green_pct = colors.count('green') / len(colors) * 100\n",
        "        yellow_pct = colors.count('yellow') / len(colors) * 100\n",
        "        red_pct = colors.count('red') / len(colors) * 100\n",
        "        \n",
        "        return {\n",
        "            'group_stats': group_stats,\n",
        "            'green_percentage': green_pct,\n",
        "            'yellow_percentage': yellow_pct,\n",
        "            'red_percentage': red_pct,\n",
        "            'total_groups': len(group_stats)\n",
        "        }\n",
        "    \n",
        "    @classmethod\n",
        "    def evaluate_model(cls, y_true, y_pred_proba, y_train_proba=None):\n",
        "        \"\"\"\n",
        "        Eval√∫a un modelo con todas las m√©tricas\n",
        "        \n",
        "        Args:\n",
        "            y_true: Valores reales\n",
        "            y_pred_proba: Probabilidades predichas\n",
        "            y_train_proba: Probabilidades en train (para PSI)\n",
        "        \n",
        "        Returns:\n",
        "            Dict con todas las m√©tricas\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "        \n",
        "        # AUC-ROC\n",
        "        results['auc_roc'] = cls.calculate_auc_roc(y_true, y_pred_proba)\n",
        "        \n",
        "        # PSI (si se proporcionan datos de train)\n",
        "        if y_train_proba is not None:\n",
        "            results['psi'] = cls.calculate_psi(y_train_proba, y_pred_proba)\n",
        "        \n",
        "        # Traffic Light\n",
        "        traffic_light = cls.calculate_traffic_light(y_true, y_pred_proba)\n",
        "        results['traffic_light'] = traffic_light\n",
        "        \n",
        "        return results\n",
        "\n",
        "print(\"‚úÖ Clase de m√©tricas creada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Clase de optimizaci√≥n creada\n"
          ]
        }
      ],
      "source": [
        "# Clase para optimizaci√≥n con Optuna\n",
        "class OptunaOptimizer:\n",
        "    \"\"\"\n",
        "    Clase para optimizar modelos con Optuna\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, X_train, y_train, cv_folds=5, n_trials=50):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.cv_folds = cv_folds\n",
        "        self.n_trials = n_trials\n",
        "        self.best_params = {}\n",
        "        self.best_scores = {}\n",
        "        \n",
        "    def optimize_xgboost(self):\n",
        "        \"\"\"\n",
        "        Optimiza XGBoost con Optuna - Enfocado en reducir overfitting\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 150),  # Reducido\n",
        "                'max_depth': trial.suggest_int('max_depth', 2, 8),  # M√°s restrictivo\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.10),  # M√°s conservador\n",
        "                'subsample': trial.suggest_float('subsample', 0.1, 0.5),  # M√°s regularizaci√≥n\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 0.9),  # M√°s regularizaci√≥n\n",
        "                'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 125.0),  # L1 regularizaci√≥n\n",
        "                'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 125.0),  # L2 regularizaci√≥n\n",
        "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # Control de overfitting\n",
        "                'gamma': trial.suggest_float('gamma', 0, 2),  # Regularizaci√≥n adicional\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = xgb.XGBClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['xgboost'] = study.best_params\n",
        "        self.best_scores['xgboost'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_lightgbm(self):\n",
        "        \"\"\"\n",
        "        Optimiza LightGBM con Optuna - Enfocado en reducir overfitting\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 200),  # Reducido\n",
        "                'max_depth': trial.suggest_int('max_depth', 2, 10),  # M√°s restrictivo\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15),  # M√°s conservador\n",
        "                'subsample': trial.suggest_float('subsample', 0.1, 0.5),  # M√°s regularizaci√≥n\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 0.9),  # M√°s regularizaci√≥n\n",
        "                'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 125.0),  # L1 regularizaci√≥n\n",
        "                'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 125.0),  # L2 regularizaci√≥n\n",
        "                'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),  # Control de overfitting\n",
        "                'min_split_gain': trial.suggest_float('min_split_gain', 0, 1),  # Regularizaci√≥n adicional\n",
        "                'random_state': RANDOM_STATE,\n",
        "                'verbose': -1\n",
        "            }\n",
        "            \n",
        "            model = lgb.LGBMClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['lightgbm'] = study.best_params\n",
        "        self.best_scores['lightgbm'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_catboost(self):\n",
        "        \"\"\"\n",
        "        Optimiza CatBoost con Optuna - Enfocado en reducir overfitting\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'iterations': trial.suggest_int('iterations', 50, 250),  # Reducido\n",
        "                'depth': trial.suggest_int('depth', 2, 6),  # M√°s restrictivo\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),  # M√°s conservador\n",
        "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 100),  # L2 regularizaci√≥n\n",
        "                'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
        "                'subsample': trial.suggest_float('subsample', 0.7, 0.9),  # M√°s regularizaci√≥n\n",
        "                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 0.5),  # Regularizaci√≥n\n",
        "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),  # Control de overfitting\n",
        "                'random_seed': RANDOM_STATE,\n",
        "                'verbose': False\n",
        "            }\n",
        "            \n",
        "            model = cb.CatBoostClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['catboost'] = study.best_params\n",
        "        self.best_scores['catboost'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_random_forest(self):\n",
        "        \"\"\"\n",
        "        Optimiza Random Forest con Optuna - Enfocado en reducir overfitting\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 200),  # Reducido\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 10),  # M√°s restrictivo\n",
        "                'min_samples_split': trial.suggest_int('min_samples_split', 5, 20),  # M√°s restrictivo\n",
        "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 10),  # M√°s restrictivo\n",
        "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),  # Sin None\n",
        "                'bootstrap': True,  # Bootstrap para regularizaci√≥n\n",
        "                'max_samples': trial.suggest_float('max_samples', 0.7, 0.9),  # Submuestreo\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = RandomForestClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['random_forest'] = study.best_params\n",
        "        self.best_scores['random_forest'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_logistic_regression(self):\n",
        "        \"\"\"\n",
        "        Optimiza Logistic Regression con Optuna - Enfocado en reducir overfitting\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 0.01, 10, log=True),  # M√°s restrictivo\n",
        "                'penalty': trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet']),\n",
        "                'solver': 'saga',  # Compatible con elasticnet\n",
        "                'l1_ratio': trial.suggest_float('l1_ratio', 0.1, 0.9),  # Para elasticnet\n",
        "                'max_iter': 1000,  # M√°s iteraciones\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = LogisticRegression(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['logistic_regression'] = study.best_params\n",
        "        self.best_scores['logistic_regression'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "\n",
        "print(\"‚úÖ Clase de optimizaci√≥n creada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Optimizador inicializado\n",
            "   üìä Datos de entrenamiento: (600, 20)\n",
            "   üîÑ Folds de CV: 5\n",
            "   üéØ Trials por modelo: 50\n"
          ]
        }
      ],
      "source": [
        "# Inicializar optimizador\n",
        "optimizer = OptunaOptimizer(X_train, y_train, cv_folds=CV_FOLDS, n_trials=N_TRIALS)\n",
        "\n",
        "print(f\"üöÄ Optimizador inicializado\")\n",
        "print(f\"   üìä Datos de entrenamiento: {X_train.shape}\")\n",
        "print(f\"   üîÑ Folds de CV: {CV_FOLDS}\")\n",
        "print(f\"   üéØ Trials por modelo: {N_TRIALS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-17 15:39:17,272] A new study created in memory with name: no-name-81b4ed15-fdd7-43c0-a2c2-716c52421b09\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî• OPTIMIZANDO TODOS LOS MODELOS...\n",
            "==================================================\n",
            "\n",
            "üî• Optimizando XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-17 15:39:17,871] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 87, 'max_depth': 8, 'learning_rate': 0.07587945476302646, 'subsample': 0.3394633936788146, 'colsample_bytree': 0.7312037280884873, 'reg_alpha': 19.583715589991712, 'reg_lambda': 7.354643159808113, 'min_child_weight': 9, 'gamma': 1.2022300234864176}. Best is trial 0 with value: 0.5.\n",
            "[I 2025-10-17 15:39:18,834] Trial 1 finished with value: 0.5 and parameters: {'n_estimators': 121, 'max_depth': 2, 'learning_rate': 0.0972918866945795, 'subsample': 0.4329770563201687, 'colsample_bytree': 0.7424678221356552, 'reg_alpha': 22.80993840416687, 'reg_lambda': 23.007223280693886, 'min_child_weight': 4, 'gamma': 1.0495128632644757}. Best is trial 0 with value: 0.5.\n",
            "[I 2025-10-17 15:39:19,405] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 93, 'max_depth': 4, 'learning_rate': 0.06506676052501416, 'subsample': 0.15579754426081674, 'colsample_bytree': 0.7584289297070436, 'reg_alpha': 45.8585942273821, 'reg_lambda': 57.06314102870779, 'min_child_weight': 8, 'gamma': 0.39934756431671947}. Best is trial 0 with value: 0.5.\n",
            "[I 2025-10-17 15:39:19,957] Trial 3 finished with value: 0.5994378306878307 and parameters: {'n_estimators': 101, 'max_depth': 6, 'learning_rate': 0.014180537144799797, 'subsample': 0.34301794076057535, 'colsample_bytree': 0.7341048247374583, 'reg_alpha': 8.224943963861412, 'reg_lambda': 118.61580360294133, 'min_child_weight': 10, 'gamma': 1.6167946962329223}. Best is trial 3 with value: 0.5994378306878307.\n",
            "[I 2025-10-17 15:39:20,403] Trial 4 finished with value: 0.5 and parameters: {'n_estimators': 80, 'max_depth': 2, 'learning_rate': 0.07158097238609412, 'subsample': 0.27606099749584057, 'colsample_bytree': 0.7244076469689558, 'reg_alpha': 61.94759607289765, 'reg_lambda': 4.395126287290777, 'min_child_weight': 10, 'gamma': 0.5175599632000338}. Best is trial 3 with value: 0.5994378306878307.\n",
            "[I 2025-10-17 15:39:20,834] Trial 5 finished with value: 0.5 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.05680612190600298, 'subsample': 0.31868411173731187, 'colsample_bytree': 0.7369708911051054, 'reg_alpha': 121.20112000779336, 'reg_lambda': 96.9140896378032, 'min_child_weight': 10, 'gamma': 1.7896547008552977}. Best is trial 3 with value: 0.5994378306878307.\n",
            "[I 2025-10-17 15:39:21,248] Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 110, 'max_depth': 8, 'learning_rate': 0.017964325184672756, 'subsample': 0.1783931449676581, 'colsample_bytree': 0.7090454577821076, 'reg_alpha': 40.73375831233172, 'reg_lambda': 48.645793482216305, 'min_child_weight': 3, 'gamma': 1.6574750183038587}. Best is trial 3 with value: 0.5994378306878307.\n",
            "[I 2025-10-17 15:39:21,688] Trial 7 finished with value: 0.5 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.058842647484242366, 'subsample': 0.15636968998990508, 'colsample_bytree': 0.8604393961508079, 'reg_alpha': 9.411375395603375, 'reg_lambda': 123.3621783814046, 'min_child_weight': 8, 'gamma': 0.3974313630683448}. Best is trial 3 with value: 0.5994378306878307.\n",
            "[I 2025-10-17 15:39:22,060] Trial 8 finished with value: 0.7142857142857142 and parameters: {'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.07361716094628554, 'subsample': 0.3916028672163949, 'colsample_bytree': 0.8542540693371892, 'reg_alpha': 9.348177001587887, 'reg_lambda': 44.872369495179655, 'min_child_weight': 2, 'gamma': 1.726206851751187}. Best is trial 8 with value: 0.7142857142857142.\n",
            "[I 2025-10-17 15:39:22,491] Trial 9 finished with value: 0.5 and parameters: {'n_estimators': 112, 'max_depth': 4, 'learning_rate': 0.015720251525742128, 'subsample': 0.2243929286862649, 'colsample_bytree': 0.7650366644053493, 'reg_alpha': 91.2278116744242, 'reg_lambda': 79.73092817226612, 'min_child_weight': 9, 'gamma': 0.9444298503238986}. Best is trial 8 with value: 0.7142857142857142.\n",
            "[I 2025-10-17 15:39:23,039] Trial 10 finished with value: 0.5 and parameters: {'n_estimators': 52, 'max_depth': 6, 'learning_rate': 0.03769247903052364, 'subsample': 0.47465950130295914, 'colsample_bytree': 0.895844696439752, 'reg_alpha': 86.31185948878624, 'reg_lambda': 32.31507637992639, 'min_child_weight': 1, 'gamma': 1.9386261455081895}. Best is trial 8 with value: 0.7142857142857142.\n",
            "[I 2025-10-17 15:39:23,592] Trial 11 finished with value: 0.7318121693121692 and parameters: {'n_estimators': 147, 'max_depth': 6, 'learning_rate': 0.03895424648532502, 'subsample': 0.3822340495549849, 'colsample_bytree': 0.8139438617739845, 'reg_alpha': 3.966904768602154, 'reg_lambda': 117.53335226124616, 'min_child_weight': 6, 'gamma': 1.4814240611836327}. Best is trial 11 with value: 0.7318121693121692.\n",
            "[I 2025-10-17 15:39:24,163] Trial 12 finished with value: 0.5 and parameters: {'n_estimators': 144, 'max_depth': 6, 'learning_rate': 0.03835472613444918, 'subsample': 0.40150453237089584, 'colsample_bytree': 0.821814772686749, 'reg_alpha': 34.38317316298189, 'reg_lambda': 78.49260386246817, 'min_child_weight': 6, 'gamma': 1.3867400411201398}. Best is trial 11 with value: 0.7318121693121692.\n",
            "[I 2025-10-17 15:39:24,934] Trial 13 finished with value: 0.7645502645502645 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.039234221707997896, 'subsample': 0.39236452092136653, 'colsample_bytree': 0.8166284869762422, 'reg_alpha': 3.291131901836877, 'reg_lambda': 41.38940053136723, 'min_child_weight': 6, 'gamma': 1.3710092162578684}. Best is trial 13 with value: 0.7645502645502645.\n",
            "[I 2025-10-17 15:39:25,647] Trial 14 finished with value: 0.7714947089947091 and parameters: {'n_estimators': 149, 'max_depth': 7, 'learning_rate': 0.04397484995849731, 'subsample': 0.49840679574448554, 'colsample_bytree': 0.7979409097155367, 'reg_alpha': 2.7567857408156784, 'reg_lambda': 75.31385949233461, 'min_child_weight': 6, 'gamma': 0.8014695857116751}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:26,281] Trial 15 finished with value: 0.5 and parameters: {'n_estimators': 132, 'max_depth': 7, 'learning_rate': 0.028622696463867413, 'subsample': 0.4750244637464093, 'colsample_bytree': 0.7897096113780152, 'reg_alpha': 67.47066683621411, 'reg_lambda': 72.22326995095453, 'min_child_weight': 5, 'gamma': 0.7709106214069948}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:26,882] Trial 16 finished with value: 0.5999007936507936 and parameters: {'n_estimators': 133, 'max_depth': 7, 'learning_rate': 0.049662386717915646, 'subsample': 0.4918585998724917, 'colsample_bytree': 0.7896543803933558, 'reg_alpha': 26.657532329995455, 'reg_lambda': 98.6615436236377, 'min_child_weight': 7, 'gamma': 0.02635842876184702}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:27,385] Trial 17 finished with value: 0.5 and parameters: {'n_estimators': 132, 'max_depth': 5, 'learning_rate': 0.048740687461325, 'subsample': 0.4366137650070001, 'colsample_bytree': 0.8379348850423535, 'reg_alpha': 54.56886921317782, 'reg_lambda': 31.23470034938862, 'min_child_weight': 5, 'gamma': 0.6802085534834015}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:27,914] Trial 18 finished with value: 0.5 and parameters: {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.028392126702585587, 'subsample': 0.10604448319363502, 'colsample_bytree': 0.7707491548436209, 'reg_alpha': 82.03987491924995, 'reg_lambda': 61.57951130967117, 'min_child_weight': 4, 'gamma': 1.2146899766801897}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:28,576] Trial 19 finished with value: 0.7692129629629629 and parameters: {'n_estimators': 139, 'max_depth': 5, 'learning_rate': 0.08915507162992636, 'subsample': 0.27274311439987087, 'colsample_bytree': 0.8810846065879611, 'reg_alpha': 1.0617419514838984, 'reg_lambda': 97.29500727354494, 'min_child_weight': 7, 'gamma': 0.08671419184671691}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:29,181] Trial 20 finished with value: 0.5 and parameters: {'n_estimators': 137, 'max_depth': 5, 'learning_rate': 0.09966028459647208, 'subsample': 0.2698419830708595, 'colsample_bytree': 0.8996310015361614, 'reg_alpha': 112.9482618461621, 'reg_lambda': 98.19573895994917, 'min_child_weight': 7, 'gamma': 0.03489074720830345}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:29,850] Trial 21 finished with value: 0.7704695767195766 and parameters: {'n_estimators': 138, 'max_depth': 7, 'learning_rate': 0.08893216927518144, 'subsample': 0.2442485298837102, 'colsample_bytree': 0.8745104876923269, 'reg_alpha': 1.5137176153225123, 'reg_lambda': 89.12445607309327, 'min_child_weight': 7, 'gamma': 0.20475399031323377}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:31,545] Trial 22 finished with value: 0.5 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.08408583968841997, 'subsample': 0.23029472882524335, 'colsample_bytree': 0.8779690257681977, 'reg_alpha': 18.060436963080637, 'reg_lambda': 87.60774333925177, 'min_child_weight': 7, 'gamma': 0.23558031646630043}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:32,230] Trial 23 finished with value: 0.5 and parameters: {'n_estimators': 140, 'max_depth': 6, 'learning_rate': 0.08720328760371508, 'subsample': 0.2251380320745703, 'colsample_bytree': 0.8733169348855281, 'reg_alpha': 32.95375161613852, 'reg_lambda': 107.023556432377, 'min_child_weight': 8, 'gamma': 0.2146316265548558}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:32,881] Trial 24 finished with value: 0.7698412698412699 and parameters: {'n_estimators': 126, 'max_depth': 7, 'learning_rate': 0.08945919575716665, 'subsample': 0.2847649283601959, 'colsample_bytree': 0.8418829365077973, 'reg_alpha': 1.3124765447876663, 'reg_lambda': 70.51777675060994, 'min_child_weight': 7, 'gamma': 0.18879201971858917}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:33,587] Trial 25 finished with value: 0.6416666666666667 and parameters: {'n_estimators': 124, 'max_depth': 7, 'learning_rate': 0.08308825307293906, 'subsample': 0.29946857873479305, 'colsample_bytree': 0.8365460992894015, 'reg_alpha': 12.369743172387183, 'reg_lambda': 72.4401034869725, 'min_child_weight': 5, 'gamma': 0.6360796306887847}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:34,330] Trial 26 finished with value: 0.5 and parameters: {'n_estimators': 103, 'max_depth': 8, 'learning_rate': 0.06521804212196486, 'subsample': 0.19963060600416926, 'colsample_bytree': 0.8461933850148282, 'reg_alpha': 30.483585473512033, 'reg_lambda': 85.1667528771977, 'min_child_weight': 4, 'gamma': 0.27831247065110326}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:34,846] Trial 27 finished with value: 0.5 and parameters: {'n_estimators': 68, 'max_depth': 7, 'learning_rate': 0.09353884120941976, 'subsample': 0.25615782634866097, 'colsample_bytree': 0.7980618028049963, 'reg_alpha': 17.949511587073868, 'reg_lambda': 68.71867180566123, 'min_child_weight': 6, 'gamma': 0.8570634689532316}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:35,545] Trial 28 finished with value: 0.5 and parameters: {'n_estimators': 132, 'max_depth': 8, 'learning_rate': 0.08093067277908157, 'subsample': 0.3114464566203801, 'colsample_bytree': 0.8274594911096137, 'reg_alpha': 44.35360933963883, 'reg_lambda': 55.443555059618504, 'min_child_weight': 8, 'gamma': 0.5159548805998221}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:36,377] Trial 29 finished with value: 0.7701388888888889 and parameters: {'n_estimators': 125, 'max_depth': 8, 'learning_rate': 0.07734371460437037, 'subsample': 0.36995489008099336, 'colsample_bytree': 0.8571544955452453, 'reg_alpha': 0.198344671852015, 'reg_lambda': 88.932782521382, 'min_child_weight': 9, 'gamma': 0.3548368065005788}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:37,111] Trial 30 finished with value: 0.6849206349206349 and parameters: {'n_estimators': 143, 'max_depth': 8, 'learning_rate': 0.07884882279816971, 'subsample': 0.3595849191581006, 'colsample_bytree': 0.8707512802279974, 'reg_alpha': 16.287038382883612, 'reg_lambda': 108.91890547426463, 'min_child_weight': 9, 'gamma': 0.41998198654539237}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:37,792] Trial 31 finished with value: 0.768154761904762 and parameters: {'n_estimators': 124, 'max_depth': 8, 'learning_rate': 0.09364429510614922, 'subsample': 0.33423557632521717, 'colsample_bytree': 0.8622142138280047, 'reg_alpha': 1.7044048064984927, 'reg_lambda': 89.75726967224196, 'min_child_weight': 9, 'gamma': 0.21164602700576451}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:38,498] Trial 32 finished with value: 0.5 and parameters: {'n_estimators': 118, 'max_depth': 7, 'learning_rate': 0.06799405067955812, 'subsample': 0.4285428039467068, 'colsample_bytree': 0.845686785408725, 'reg_alpha': 24.927348147181, 'reg_lambda': 79.9997617672665, 'min_child_weight': 7, 'gamma': 0.3093972815854337}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:39,154] Trial 33 finished with value: 0.5 and parameters: {'n_estimators': 128, 'max_depth': 7, 'learning_rate': 0.09213532842278205, 'subsample': 0.29732588342515376, 'colsample_bytree': 0.8085286423963672, 'reg_alpha': 20.8029840148337, 'reg_lambda': 68.90824304869055, 'min_child_weight': 8, 'gamma': 0.6044531592848033}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:39,899] Trial 34 finished with value: 0.6904431216931217 and parameters: {'n_estimators': 108, 'max_depth': 8, 'learning_rate': 0.0761268125701318, 'subsample': 0.3583843020634358, 'colsample_bytree': 0.7825361577690793, 'reg_alpha': 10.864761585532465, 'reg_lambda': 60.701193386888136, 'min_child_weight': 8, 'gamma': 1.0750320432309037}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:41,601] Trial 35 finished with value: 0.7692791005291005 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.048821627646106515, 'subsample': 0.2448798581966228, 'colsample_bytree': 0.8860794173857823, 'reg_alpha': 1.0126308326139357, 'reg_lambda': 91.01211628059667, 'min_child_weight': 6, 'gamma': 0.140386624198233}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:42,172] Trial 36 finished with value: 0.5 and parameters: {'n_estimators': 115, 'max_depth': 7, 'learning_rate': 0.09706769916390674, 'subsample': 0.19979037113852535, 'colsample_bytree': 0.8324955855847788, 'reg_alpha': 15.640913155128441, 'reg_lambda': 107.16963145010405, 'min_child_weight': 9, 'gamma': 0.398538892773207}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:42,688] Trial 37 finished with value: 0.7646825396825397 and parameters: {'n_estimators': 93, 'max_depth': 8, 'learning_rate': 0.06103104665683848, 'subsample': 0.43388406635948806, 'colsample_bytree': 0.7503185214391948, 'reg_alpha': 6.745504224225602, 'reg_lambda': 13.409821786594897, 'min_child_weight': 10, 'gamma': 0.52010389926339}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:43,172] Trial 38 finished with value: 0.5 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.07170064239515786, 'subsample': 0.3329933226275724, 'colsample_bytree': 0.8555365588607062, 'reg_alpha': 39.63198915132802, 'reg_lambda': 54.25977118432151, 'min_child_weight': 4, 'gamma': 0.7609269779045128}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:43,622] Trial 39 finished with value: 0.5 and parameters: {'n_estimators': 105, 'max_depth': 3, 'learning_rate': 0.05357972571068971, 'subsample': 0.28426469135969556, 'colsample_bytree': 0.8874445449056134, 'reg_alpha': 21.836155399934963, 'reg_lambda': 76.52008080667817, 'min_child_weight': 7, 'gamma': 0.3355277839604067}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:44,414] Trial 40 finished with value: 0.5 and parameters: {'n_estimators': 120, 'max_depth': 8, 'learning_rate': 0.07683936792565757, 'subsample': 0.4548357868814748, 'colsample_bytree': 0.8015659748555057, 'reg_alpha': 54.43377863378497, 'reg_lambda': 65.64773869760246, 'min_child_weight': 5, 'gamma': 0.1244229839222924}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:45,012] Trial 41 finished with value: 0.7662367724867725 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.045577337161415966, 'subsample': 0.2526850228802275, 'colsample_bytree': 0.8671379812574185, 'reg_alpha': 0.6831718636329391, 'reg_lambda': 92.85246912653257, 'min_child_weight': 6, 'gamma': 0.15497538711399422}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:45,630] Trial 42 finished with value: 0.7119047619047619 and parameters: {'n_estimators': 143, 'max_depth': 6, 'learning_rate': 0.08687424906480273, 'subsample': 0.24280346407675904, 'colsample_bytree': 0.8870330636461251, 'reg_alpha': 9.680468395353971, 'reg_lambda': 84.4420407944051, 'min_child_weight': 6, 'gamma': 0.4331829762921786}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:46,268] Trial 43 finished with value: 0.7599537037037039 and parameters: {'n_estimators': 146, 'max_depth': 7, 'learning_rate': 0.05312922619440533, 'subsample': 0.16118232521065096, 'colsample_bytree': 0.8477247943964527, 'reg_alpha': 6.907313392616203, 'reg_lambda': 103.45454626070845, 'min_child_weight': 8, 'gamma': 0.012251325056043677}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:46,771] Trial 44 finished with value: 0.6065145502645503 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.04408086730856919, 'subsample': 0.1869183062444142, 'colsample_bytree': 0.886165572289926, 'reg_alpha': 12.572706918672978, 'reg_lambda': 92.32725458869531, 'min_child_weight': 3, 'gamma': 0.13397438869013206}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:47,262] Trial 45 finished with value: 0.5305555555555556 and parameters: {'n_estimators': 127, 'max_depth': 7, 'learning_rate': 0.027743321557800574, 'subsample': 0.1324722318639537, 'colsample_bytree': 0.8629665626947983, 'reg_alpha': 6.109097304430534, 'reg_lambda': 83.2162745691878, 'min_child_weight': 7, 'gamma': 0.502943733017889}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:47,825] Trial 46 finished with value: 0.7688492063492064 and parameters: {'n_estimators': 142, 'max_depth': 7, 'learning_rate': 0.061328226759344906, 'subsample': 0.3129882339202258, 'colsample_bytree': 0.8934365718415083, 'reg_alpha': 1.7164156870099476, 'reg_lambda': 75.25072546224972, 'min_child_weight': 10, 'gamma': 0.3341975707040414}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:48,353] Trial 47 finished with value: 0.5 and parameters: {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.03177124134815963, 'subsample': 0.2069625662916083, 'colsample_bytree': 0.7215332938520478, 'reg_alpha': 25.9134843275007, 'reg_lambda': 111.2761014751924, 'min_child_weight': 5, 'gamma': 0.9927726442508529}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:48,785] Trial 48 finished with value: 0.5646825396825397 and parameters: {'n_estimators': 97, 'max_depth': 7, 'learning_rate': 0.06958353235953249, 'subsample': 0.3615050246529167, 'colsample_bytree': 0.8539591879305257, 'reg_alpha': 13.999767613100035, 'reg_lambda': 102.44966735790146, 'min_child_weight': 6, 'gamma': 1.1777574150936991}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:49,194] Trial 49 finished with value: 0.5 and parameters: {'n_estimators': 76, 'max_depth': 6, 'learning_rate': 0.043188043628866385, 'subsample': 0.2871389859752282, 'colsample_bytree': 0.8771631272212226, 'reg_alpha': 73.10143330070464, 'reg_lambda': 118.43871596938527, 'min_child_weight': 3, 'gamma': 0.1861506908237423}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:49,198] A new study created in memory with name: no-name-410c01a1-98eb-4c08-bb7d-10f94d33a8c4\n",
            "[I 2025-10-17 15:39:49,342] Trial 0 finished with value: 0.7014550264550264 and parameters: {'n_estimators': 106, 'max_depth': 10, 'learning_rate': 0.11247915185359669, 'subsample': 0.3394633936788146, 'colsample_bytree': 0.7312037280884873, 'reg_alpha': 19.583715589991712, 'reg_lambda': 7.354643159808113, 'min_child_samples': 45, 'min_split_gain': 0.6011150117432088}. Best is trial 0 with value: 0.7014550264550264.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ XGBoost optimizado en 31.9 segundos\n",
            "   üèÜ Mejor CV Score: 0.7715\n",
            "   ‚öôÔ∏è Mejores par√°metros: {'n_estimators': 149, 'max_depth': 7, 'learning_rate': 0.04397484995849731, 'subsample': 0.49840679574448554, 'colsample_bytree': 0.7979409097155367, 'reg_alpha': 2.7567857408156784, 'reg_lambda': 75.31385949233461, 'min_child_weight': 6, 'gamma': 0.8014695857116751}\n",
            "\n",
            "üî• Optimizando LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-17 15:39:49,513] Trial 1 finished with value: 0.6892857142857143 and parameters: {'n_estimators': 156, 'max_depth': 2, 'learning_rate': 0.1457873793026792, 'subsample': 0.4329770563201687, 'colsample_bytree': 0.7424678221356552, 'reg_alpha': 22.80993840416687, 'reg_lambda': 23.007223280693886, 'min_child_samples': 22, 'min_split_gain': 0.5247564316322378}. Best is trial 0 with value: 0.7014550264550264.\n",
            "[I 2025-10-17 15:39:49,648] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 115, 'max_depth': 4, 'learning_rate': 0.09565940526113312, 'subsample': 0.15579754426081674, 'colsample_bytree': 0.7584289297070436, 'reg_alpha': 45.8585942273821, 'reg_lambda': 57.06314102870779, 'min_child_samples': 42, 'min_split_gain': 0.19967378215835974}. Best is trial 0 with value: 0.7014550264550264.\n",
            "[I 2025-10-17 15:39:49,845] Trial 3 finished with value: 0.7518849206349207 and parameters: {'n_estimators': 127, 'max_depth': 7, 'learning_rate': 0.01650305778079968, 'subsample': 0.34301794076057535, 'colsample_bytree': 0.7341048247374583, 'reg_alpha': 8.224943963861412, 'reg_lambda': 118.61580360294133, 'min_child_samples': 49, 'min_split_gain': 0.8083973481164611}. Best is trial 3 with value: 0.7518849206349207.\n",
            "[I 2025-10-17 15:39:49,982] Trial 4 finished with value: 0.5 and parameters: {'n_estimators': 95, 'max_depth': 2, 'learning_rate': 0.10579262371170195, 'subsample': 0.27606099749584057, 'colsample_bytree': 0.7244076469689558, 'reg_alpha': 61.94759607289765, 'reg_lambda': 4.395126287290777, 'min_child_samples': 47, 'min_split_gain': 0.2587799816000169}. Best is trial 3 with value: 0.7518849206349207.\n",
            "[I 2025-10-17 15:39:50,139] Trial 5 finished with value: 0.5 and parameters: {'n_estimators': 150, 'max_depth': 4, 'learning_rate': 0.0828095229648935, 'subsample': 0.31868411173731187, 'colsample_bytree': 0.7369708911051054, 'reg_alpha': 121.20112000779336, 'reg_lambda': 96.9140896378032, 'min_child_samples': 48, 'min_split_gain': 0.8948273504276488}. Best is trial 3 with value: 0.7518849206349207.\n",
            "[I 2025-10-17 15:39:50,296] Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 140, 'max_depth': 10, 'learning_rate': 0.022388950287268727, 'subsample': 0.1783931449676581, 'colsample_bytree': 0.7090454577821076, 'reg_alpha': 40.73375831233172, 'reg_lambda': 48.645793482216305, 'min_child_samples': 21, 'min_split_gain': 0.8287375091519293}. Best is trial 3 with value: 0.7518849206349207.\n",
            "[I 2025-10-17 15:39:50,478] Trial 7 finished with value: 0.7688161375661376 and parameters: {'n_estimators': 103, 'max_depth': 4, 'learning_rate': 0.08597745164215477, 'subsample': 0.15636968998990508, 'colsample_bytree': 0.8604393961508079, 'reg_alpha': 9.411375395603375, 'reg_lambda': 123.3621783814046, 'min_child_samples': 41, 'min_split_gain': 0.1987156815341724}. Best is trial 7 with value: 0.7688161375661376.\n",
            "[I 2025-10-17 15:39:50,621] Trial 8 finished with value: 0.7640542328042328 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.10896002813866638, 'subsample': 0.3916028672163949, 'colsample_bytree': 0.8542540693371892, 'reg_alpha': 9.348177001587887, 'reg_lambda': 44.872369495179655, 'min_child_samples': 14, 'min_split_gain': 0.8631034258755935}. Best is trial 7 with value: 0.7688161375661376.\n",
            "[I 2025-10-17 15:39:50,779] Trial 9 finished with value: 0.5 and parameters: {'n_estimators': 144, 'max_depth': 4, 'learning_rate': 0.01889816904004331, 'subsample': 0.2243929286862649, 'colsample_bytree': 0.7650366644053493, 'reg_alpha': 91.2278116744242, 'reg_lambda': 79.73092817226612, 'min_child_samples': 46, 'min_split_gain': 0.4722149251619493}. Best is trial 7 with value: 0.7688161375661376.\n",
            "[I 2025-10-17 15:39:51,029] Trial 10 finished with value: 0.5 and parameters: {'n_estimators': 192, 'max_depth': 6, 'learning_rate': 0.054281669391805114, 'subsample': 0.10718475024592794, 'colsample_bytree': 0.8962141652178608, 'reg_alpha': 86.31185948878624, 'reg_lambda': 121.63241632012613, 'min_child_samples': 35, 'min_split_gain': 0.0397996060770148}. Best is trial 7 with value: 0.7688161375661376.\n",
            "[I 2025-10-17 15:39:51,268] Trial 11 finished with value: 0.7811507936507937 and parameters: {'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.1317704252752519, 'subsample': 0.47323351944263115, 'colsample_bytree': 0.8574488745971842, 'reg_alpha': 2.683211185605666, 'reg_lambda': 37.31763787753863, 'min_child_samples': 13, 'min_split_gain': 0.9980525992325887}. Best is trial 11 with value: 0.7811507936507937.\n",
            "[I 2025-10-17 15:39:51,478] Trial 12 finished with value: 0.5638888888888889 and parameters: {'n_estimators': 51, 'max_depth': 7, 'learning_rate': 0.1400839024529601, 'subsample': 0.4921484768975404, 'colsample_bytree': 0.8311498440452599, 'reg_alpha': 34.38317316298189, 'reg_lambda': 78.49260386246817, 'min_child_samples': 33, 'min_split_gain': 0.3309605669285303}. Best is trial 11 with value: 0.7811507936507937.\n",
            "[I 2025-10-17 15:39:51,730] Trial 13 finished with value: 0.7802910052910053 and parameters: {'n_estimators': 76, 'max_depth': 8, 'learning_rate': 0.06411981054363017, 'subsample': 0.4997449754566207, 'colsample_bytree': 0.8749048825997123, 'reg_alpha': 3.291131901836877, 'reg_lambda': 30.270211129244466, 'min_child_samples': 26, 'min_split_gain': 0.998024633462006}. Best is trial 11 with value: 0.7811507936507937.\n",
            "[I 2025-10-17 15:39:52,002] Trial 14 finished with value: 0.7850198412698413 and parameters: {'n_estimators': 74, 'max_depth': 8, 'learning_rate': 0.04537051061598461, 'subsample': 0.49840679574448554, 'colsample_bytree': 0.8998375993934207, 'reg_alpha': 2.4827800326410725, 'reg_lambda': 34.313634716372164, 'min_child_samples': 12, 'min_split_gain': 0.9550788336373541}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:52,258] Trial 15 finished with value: 0.5 and parameters: {'n_estimators': 73, 'max_depth': 8, 'learning_rate': 0.04194056590002803, 'subsample': 0.4407328365449625, 'colsample_bytree': 0.818300219924282, 'reg_alpha': 67.68763777122705, 'reg_lambda': 31.93421404381624, 'min_child_samples': 10, 'min_split_gain': 0.6512900913402648}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:52,476] Trial 16 finished with value: 0.6892857142857143 and parameters: {'n_estimators': 75, 'max_depth': 6, 'learning_rate': 0.12753549772758185, 'subsample': 0.43442912591076105, 'colsample_bytree': 0.889898579028525, 'reg_alpha': 26.657532329995455, 'reg_lambda': 69.12871310407967, 'min_child_samples': 15, 'min_split_gain': 0.7321918525638057}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:52,770] Trial 17 finished with value: 0.5 and parameters: {'n_estimators': 64, 'max_depth': 8, 'learning_rate': 0.06552085598261642, 'subsample': 0.3781640052202573, 'colsample_bytree': 0.7940365532744825, 'reg_alpha': 54.56886921317782, 'reg_lambda': 18.906406570696888, 'min_child_samples': 17, 'min_split_gain': 0.9986226644565402}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:53,051] Trial 18 finished with value: 0.5 and parameters: {'n_estimators': 86, 'max_depth': 9, 'learning_rate': 0.03860997487068867, 'subsample': 0.4610628594861362, 'colsample_bytree': 0.8437544823736347, 'reg_alpha': 82.03987491924995, 'reg_lambda': 42.841187514881085, 'min_child_samples': 11, 'min_split_gain': 0.7273089243909263}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:53,321] Trial 19 finished with value: 0.5 and parameters: {'n_estimators': 177, 'max_depth': 7, 'learning_rate': 0.1282618071523506, 'subsample': 0.3902577738349137, 'colsample_bytree': 0.8790871049507756, 'reg_alpha': 122.45053845721563, 'reg_lambda': 59.971211856041336, 'min_child_samples': 20, 'min_split_gain': 0.9216308282819146}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:53,536] Trial 20 finished with value: 0.5 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.06779666224537007, 'subsample': 0.27319810244193404, 'colsample_bytree': 0.8020180532220813, 'reg_alpha': 104.83952463156888, 'reg_lambda': 17.43236543488178, 'min_child_samples': 30, 'min_split_gain': 0.44639876282017127}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:53,822] Trial 21 finished with value: 0.7824735449735449 and parameters: {'n_estimators': 82, 'max_depth': 8, 'learning_rate': 0.044802148273611835, 'subsample': 0.4960831961151187, 'colsample_bytree': 0.8713688972118849, 'reg_alpha': 3.192656653569079, 'reg_lambda': 32.99731278484707, 'min_child_samples': 25, 'min_split_gain': 0.9961235061901988}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:54,211] Trial 22 finished with value: 0.7844907407407409 and parameters: {'n_estimators': 88, 'max_depth': 9, 'learning_rate': 0.035909477175449206, 'subsample': 0.4770871856119706, 'colsample_bytree': 0.8987376729511162, 'reg_alpha': 2.4101289464294395, 'reg_lambda': 36.52779290491098, 'min_child_samples': 24, 'min_split_gain': 0.9587619265918045}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:54,517] Trial 23 finished with value: 0.703670634920635 and parameters: {'n_estimators': 90, 'max_depth': 9, 'learning_rate': 0.03810309681003332, 'subsample': 0.40884918266744374, 'colsample_bytree': 0.8979747400043582, 'reg_alpha': 17.267523799470638, 'reg_lambda': 51.88251039870773, 'min_child_samples': 25, 'min_split_gain': 0.7597734115548298}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:54,822] Trial 24 finished with value: 0.6892857142857143 and parameters: {'n_estimators': 119, 'max_depth': 10, 'learning_rate': 0.02923459300356444, 'subsample': 0.462663719079335, 'colsample_bytree': 0.875998595835013, 'reg_alpha': 29.73241643850438, 'reg_lambda': 30.51331992923414, 'min_child_samples': 26, 'min_split_gain': 0.919603310407603}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:55,183] Trial 25 finished with value: 0.788260582010582 and parameters: {'n_estimators': 79, 'max_depth': 9, 'learning_rate': 0.054798927182801965, 'subsample': 0.48558118114172155, 'colsample_bytree': 0.8769283854522034, 'reg_alpha': 0.20654693057726847, 'reg_lambda': 13.06892973869958, 'min_child_samples': 29, 'min_split_gain': 0.6260840291849177}. Best is trial 25 with value: 0.788260582010582.\n",
            "[I 2025-10-17 15:39:55,479] Trial 26 finished with value: 0.7254960317460318 and parameters: {'n_estimators': 101, 'max_depth': 9, 'learning_rate': 0.05455073834599178, 'subsample': 0.4179858301054507, 'colsample_bytree': 0.8857973800123112, 'reg_alpha': 17.06474593104088, 'reg_lambda': 12.013732412418761, 'min_child_samples': 30, 'min_split_gain': 0.5963178535332743}. Best is trial 25 with value: 0.788260582010582.\n",
            "[I 2025-10-17 15:39:55,748] Trial 27 finished with value: 0.5 and parameters: {'n_estimators': 65, 'max_depth': 10, 'learning_rate': 0.053549119530452785, 'subsample': 0.4586425653241406, 'colsample_bytree': 0.8359079401488366, 'reg_alpha': 38.587049876662356, 'reg_lambda': 24.080451514305754, 'min_child_samples': 18, 'min_split_gain': 0.6619718219780059}. Best is trial 25 with value: 0.788260582010582.\n",
            "[I 2025-10-17 15:39:56,068] Trial 28 finished with value: 0.7570105820105821 and parameters: {'n_estimators': 129, 'max_depth': 9, 'learning_rate': 0.010325688904075016, 'subsample': 0.3670482123789033, 'colsample_bytree': 0.863595203610821, 'reg_alpha': 13.450288533973406, 'reg_lambda': 4.100999280521291, 'min_child_samples': 34, 'min_split_gain': 0.3824329530215292}. Best is trial 25 with value: 0.788260582010582.\n",
            "[I 2025-10-17 15:39:56,416] Trial 29 finished with value: 0.7912037037037037 and parameters: {'n_estimators': 110, 'max_depth': 10, 'learning_rate': 0.07409265653208359, 'subsample': 0.35376581331497314, 'colsample_bytree': 0.898273859191043, 'reg_alpha': 0.19489892822749993, 'reg_lambda': 0.9938694645855488, 'min_child_samples': 38, 'min_split_gain': 0.5753595623166196}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:56,681] Trial 30 finished with value: 0.6891203703703704 and parameters: {'n_estimators': 111, 'max_depth': 10, 'learning_rate': 0.07867536873728653, 'subsample': 0.35731846475739426, 'colsample_bytree': 0.8142742465562167, 'reg_alpha': 22.39129810512233, 'reg_lambda': 0.6790764871455792, 'min_child_samples': 38, 'min_split_gain': 0.5598612051343225}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:57,015] Trial 31 finished with value: 0.7845238095238095 and parameters: {'n_estimators': 99, 'max_depth': 10, 'learning_rate': 0.07272240182650724, 'subsample': 0.4742739242460068, 'colsample_bytree': 0.897791874055471, 'reg_alpha': 1.7599891282645566, 'reg_lambda': 12.27919111853383, 'min_child_samples': 29, 'min_split_gain': 0.6877973334033258}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:57,366] Trial 32 finished with value: 0.7886243386243387 and parameters: {'n_estimators': 101, 'max_depth': 10, 'learning_rate': 0.07348193942185823, 'subsample': 0.44204899241454154, 'colsample_bytree': 0.8858500409216865, 'reg_alpha': 0.6242629937892896, 'reg_lambda': 12.335902219673287, 'min_child_samples': 38, 'min_split_gain': 0.6527979696650192}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:57,648] Trial 33 finished with value: 0.7033068783068783 and parameters: {'n_estimators': 108, 'max_depth': 10, 'learning_rate': 0.09070320462625484, 'subsample': 0.4328876232582776, 'colsample_bytree': 0.880195388153635, 'reg_alpha': 18.778893847327037, 'reg_lambda': 10.28993217780025, 'min_child_samples': 43, 'min_split_gain': 0.5275344726707771}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:57,913] Trial 34 finished with value: 0.759292328042328 and parameters: {'n_estimators': 120, 'max_depth': 9, 'learning_rate': 0.05825193621224059, 'subsample': 0.3167207739175855, 'colsample_bytree': 0.845887159610641, 'reg_alpha': 10.520332442057205, 'reg_lambda': 23.597644416359017, 'min_child_samples': 39, 'min_split_gain': 0.6125868283743223}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:58,162] Trial 35 finished with value: 0.6892857142857143 and parameters: {'n_estimators': 94, 'max_depth': 7, 'learning_rate': 0.09967451267111849, 'subsample': 0.4148707854266387, 'colsample_bytree': 0.8678294741312595, 'reg_alpha': 28.016038667061284, 'reg_lambda': 16.375490500668526, 'min_child_samples': 37, 'min_split_gain': 0.44251574724866327}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:58,420] Trial 36 finished with value: 0.7361772486772487 and parameters: {'n_estimators': 163, 'max_depth': 10, 'learning_rate': 0.07246428881291446, 'subsample': 0.4457052001452615, 'colsample_bytree': 0.8860896670042208, 'reg_alpha': 15.812021353605807, 'reg_lambda': 0.6332220348002409, 'min_child_samples': 43, 'min_split_gain': 0.5695779410411511}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:58,656] Trial 37 finished with value: 0.5 and parameters: {'n_estimators': 135, 'max_depth': 8, 'learning_rate': 0.04636880010324612, 'subsample': 0.26808846198254777, 'colsample_bytree': 0.7685732674384602, 'reg_alpha': 49.102817335934596, 'reg_lambda': 6.014429471735166, 'min_child_samples': 50, 'min_split_gain': 0.7908216234214986}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:58,890] Trial 38 finished with value: 0.7737433862433863 and parameters: {'n_estimators': 79, 'max_depth': 9, 'learning_rate': 0.07880951740134179, 'subsample': 0.324796454976644, 'colsample_bytree': 0.8859890350284053, 'reg_alpha': 9.20662206514848, 'reg_lambda': 24.43331015611266, 'min_child_samples': 33, 'min_split_gain': 0.38574429721319203}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:59,194] Trial 39 finished with value: 0.7894841269841268 and parameters: {'n_estimators': 109, 'max_depth': 10, 'learning_rate': 0.02727960283882231, 'subsample': 0.2337653952040344, 'colsample_bytree': 0.8484656272682467, 'reg_alpha': 0.16621306812846937, 'reg_lambda': 9.23291292794965, 'min_child_samples': 36, 'min_split_gain': 0.5025983745604649}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:59,431] Trial 40 finished with value: 0.6891203703703704 and parameters: {'n_estimators': 114, 'max_depth': 3, 'learning_rate': 0.02635291380994111, 'subsample': 0.23485531968409268, 'colsample_bytree': 0.8522268828861442, 'reg_alpha': 22.27383651962026, 'reg_lambda': 7.212135524922375, 'min_child_samples': 40, 'min_split_gain': 0.5105747551928839}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:59,726] Trial 41 finished with value: 0.7882275132275132 and parameters: {'n_estimators': 107, 'max_depth': 10, 'learning_rate': 0.048650967557963706, 'subsample': 0.21185225980544445, 'colsample_bytree': 0.8665911057377311, 'reg_alpha': 0.6942426445540909, 'reg_lambda': 14.923357573381498, 'min_child_samples': 36, 'min_split_gain': 0.6257148271470532}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:59,998] Trial 42 finished with value: 0.7690145502645503 and parameters: {'n_estimators': 105, 'max_depth': 10, 'learning_rate': 0.05991676401831031, 'subsample': 0.1994304426258614, 'colsample_bytree': 0.867776476396216, 'reg_alpha': 9.262811087902705, 'reg_lambda': 14.48925729664379, 'min_child_samples': 37, 'min_split_gain': 0.627638177175579}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:00,346] Trial 43 finished with value: 0.7611772486772488 and parameters: {'n_estimators': 126, 'max_depth': 10, 'learning_rate': 0.031922625899502656, 'subsample': 0.24316460377153937, 'colsample_bytree': 0.8597878036566171, 'reg_alpha': 7.6578810129504005, 'reg_lambda': 113.48034693994244, 'min_child_samples': 36, 'min_split_gain': 0.6791718151145716}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:00,659] Trial 44 finished with value: 0.7893518518518519 and parameters: {'n_estimators': 95, 'max_depth': 10, 'learning_rate': 0.0894126292588403, 'subsample': 0.2024272345178432, 'colsample_bytree': 0.8346817528838969, 'reg_alpha': 1.0502206828924636, 'reg_lambda': 20.30867685207982, 'min_child_samples': 32, 'min_split_gain': 0.49832887049269603}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:00,894] Trial 45 finished with value: 0.7480820105820106 and parameters: {'n_estimators': 95, 'max_depth': 10, 'learning_rate': 0.1150106615687278, 'subsample': 0.16336069802522596, 'colsample_bytree': 0.8277721331191229, 'reg_alpha': 13.01767227401581, 'reg_lambda': 21.50977796268044, 'min_child_samples': 33, 'min_split_gain': 0.4848330426053632}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:01,214] Trial 46 finished with value: 0.7794642857142857 and parameters: {'n_estimators': 119, 'max_depth': 9, 'learning_rate': 0.08831878131433771, 'subsample': 0.1307465324548382, 'colsample_bytree': 0.8443120004840863, 'reg_alpha': 6.936546294062533, 'reg_lambda': 8.432959536597966, 'min_child_samples': 28, 'min_split_gain': 0.5562431580962377}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:01,492] Trial 47 finished with value: 0.6892857142857143 and parameters: {'n_estimators': 99, 'max_depth': 9, 'learning_rate': 0.09282106715644638, 'subsample': 0.2919448868466051, 'colsample_bytree': 0.8192388435266688, 'reg_alpha': 32.037177979337535, 'reg_lambda': 1.6662388663640222, 'min_child_samples': 32, 'min_split_gain': 0.4011434341089599}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:01,734] Trial 48 finished with value: 0.5 and parameters: {'n_estimators': 132, 'max_depth': 10, 'learning_rate': 0.10338689613335098, 'subsample': 0.19159234312409013, 'colsample_bytree': 0.8487353862662498, 'reg_alpha': 71.06629647633679, 'reg_lambda': 103.18327737781448, 'min_child_samples': 45, 'min_split_gain': 0.2969824850188918}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:01,956] Trial 49 finished with value: 0.5 and parameters: {'n_estimators': 93, 'max_depth': 9, 'learning_rate': 0.08153386955269303, 'subsample': 0.24991404680653295, 'colsample_bytree': 0.8367884605011304, 'reg_alpha': 112.02166025069332, 'reg_lambda': 26.655490348178816, 'min_child_samples': 41, 'min_split_gain': 0.21401625423883797}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:01,956] A new study created in memory with name: no-name-fbbbc82f-7375-46ba-a5f1-be4b7787f7e6\n",
            "[W 2025-10-17 15:40:02,005] Trial 0 failed with parameters: {'iterations': 125, 'depth': 6, 'learning_rate': 0.07587945476302646, 'l2_leaf_reg': 60.26718993550662, 'bootstrap_type': 'Bayesian', 'subsample': 0.7116167224336398, 'colsample_bylevel': 0.4464704583099741, 'min_data_in_leaf': 34} because of the following error: ValueError('\\nAll the 5 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n5 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"C:\\\\Users\\\\carlo\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"C:\\\\Users\\\\carlo\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\catboost\\\\core.py\", line 5245, in fit\\n    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\\n  File \"C:\\\\Users\\\\carlo\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\catboost\\\\core.py\", line 2395, in _fit\\n    train_params = self._prepare_train_params(\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\carlo\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\catboost\\\\core.py\", line 2321, in _prepare_train_params\\n    _check_train_params(params)\\n  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\\n  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\\n_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:16: Error: bayesian bootstrap doesn\\'t support \\'subsample\\' option\\n').\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_30572\\3897334495.py\", line 97, in objective\n",
            "    cv_scores = cross_val_score(model, self.X_train, self.y_train,\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 684, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "                 ^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 431, in cross_validate\n",
            "    _warn_or_raise_about_fit_failures(results, error_score)\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n",
            "    raise ValueError(all_fits_failed_message)\n",
            "ValueError: \n",
            "All the 5 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
            "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 2395, in _fit\n",
            "    train_params = self._prepare_train_params(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 2321, in _prepare_train_params\n",
            "    _check_train_params(params)\n",
            "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
            "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
            "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:16: Error: bayesian bootstrap doesn't support 'subsample' option\n",
            "\n",
            "[W 2025-10-17 15:40:02,009] Trial 0 failed with value None.\n",
            "[I 2025-10-17 15:40:02,013] A new study created in memory with name: no-name-2cb31fcd-90db-45f3-8796-7addd573f687\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LightGBM optimizado en 12.8 segundos\n",
            "   üèÜ Mejor CV Score: 0.7912\n",
            "   ‚öôÔ∏è Mejores par√°metros: {'n_estimators': 110, 'max_depth': 10, 'learning_rate': 0.07409265653208359, 'subsample': 0.35376581331497314, 'colsample_bytree': 0.898273859191043, 'reg_alpha': 0.19489892822749993, 'reg_lambda': 0.9938694645855488, 'min_child_samples': 38, 'min_split_gain': 0.5753595623166196}\n",
            "\n",
            "üî• Optimizando CatBoost...\n",
            "‚ùå Error optimizando CatBoost: \n",
            "All the 5 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
            "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 2395, in _fit\n",
            "    train_params = self._prepare_train_params(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 2321, in _prepare_train_params\n",
            "    _check_train_params(params)\n",
            "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
            "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
            "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:16: Error: bayesian bootstrap doesn't support 'subsample' option\n",
            "\n",
            "\n",
            "üî• Optimizando RandomForest...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-17 15:40:03,846] Trial 0 finished with value: 0.8146164021164021 and parameters: {'n_estimators': 106, 'max_depth': 10, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_samples': 0.7116167224336398}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:06,770] Trial 1 finished with value: 0.8095899470899471 and parameters: {'n_estimators': 180, 'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_samples': 0.7424678221356552}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:08,625] Trial 2 finished with value: 0.8070767195767197 and parameters: {'n_estimators': 77, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'max_samples': 0.8223705789444758}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:10,082] Trial 3 finished with value: 0.8066137566137564 and parameters: {'n_estimators': 71, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'max_samples': 0.8028468876827223}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:12,331] Trial 4 finished with value: 0.7986772486772487 and parameters: {'n_estimators': 139, 'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_samples': 0.8931264066149118}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:15,121] Trial 5 finished with value: 0.8072089947089947 and parameters: {'n_estimators': 172, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'max_samples': 0.799035382022254}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:16,052] Trial 6 finished with value: 0.8036375661375661 and parameters: {'n_estimators': 55, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_samples': 0.8093420558686559}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:17,349] Trial 7 finished with value: 0.8101190476190476 and parameters: {'n_estimators': 77, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'max_samples': 0.8843748470046233}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:18,761] Trial 8 finished with value: 0.806547619047619 and parameters: {'n_estimators': 63, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_samples': 0.8657475018303858}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:20,756] Trial 9 finished with value: 0.8133597883597883 and parameters: {'n_estimators': 103, 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_samples': 0.8973773873201034}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:22,920] Trial 10 finished with value: 0.8055555555555556 and parameters: {'n_estimators': 130, 'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': 'log2', 'max_samples': 0.7077450399922366}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:24,717] Trial 11 finished with value: 0.8137566137566138 and parameters: {'n_estimators': 111, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_samples': 0.7475567594199607}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:26,493] Trial 12 finished with value: 0.8133597883597883 and parameters: {'n_estimators': 108, 'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_samples': 0.7435707167672675}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:29,483] Trial 13 finished with value: 0.807936507936508 and parameters: {'n_estimators': 147, 'max_depth': 9, 'min_samples_split': 20, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'max_samples': 0.7057366506189365}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:31,345] Trial 14 finished with value: 0.8156084656084657 and parameters: {'n_estimators': 102, 'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7543072368572136}. Best is trial 14 with value: 0.8156084656084657.\n",
            "[I 2025-10-17 15:40:33,051] Trial 15 finished with value: 0.809457671957672 and parameters: {'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': 'log2', 'max_samples': 0.7620074454211203}. Best is trial 14 with value: 0.8156084656084657.\n",
            "[I 2025-10-17 15:40:35,739] Trial 16 finished with value: 0.8196428571428571 and parameters: {'n_estimators': 160, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7753679382964325}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:38,212] Trial 17 finished with value: 0.816468253968254 and parameters: {'n_estimators': 157, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7770097536666538}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:40,806] Trial 18 finished with value: 0.8139550264550264 and parameters: {'n_estimators': 162, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7794609473123135}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:43,820] Trial 19 finished with value: 0.815542328042328 and parameters: {'n_estimators': 196, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.8391390051301513}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:46,663] Trial 20 finished with value: 0.8150793650793651 and parameters: {'n_estimators': 155, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_samples': 0.779408130836683}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:49,875] Trial 21 finished with value: 0.816931216931217 and parameters: {'n_estimators': 125, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7739045227239499}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:52,147] Trial 22 finished with value: 0.8126322751322752 and parameters: {'n_estimators': 130, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7731171102150268}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:55,699] Trial 23 finished with value: 0.8118386243386244 and parameters: {'n_estimators': 187, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.7909524065346867}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:58,680] Trial 24 finished with value: 0.8157407407407409 and parameters: {'n_estimators': 164, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_samples': 0.7269649395161287}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:01,078] Trial 25 finished with value: 0.811441798941799 and parameters: {'n_estimators': 144, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_samples': 0.8280089418372203}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:03,478] Trial 26 finished with value: 0.8194444444444444 and parameters: {'n_estimators': 120, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7671879256550396}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:05,632] Trial 27 finished with value: 0.8171296296296295 and parameters: {'n_estimators': 120, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7274806134583092}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:07,725] Trial 28 finished with value: 0.818584656084656 and parameters: {'n_estimators': 117, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7256651482861207}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:09,283] Trial 29 finished with value: 0.8162037037037037 and parameters: {'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_samples': 0.7251825519322062}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:11,565] Trial 30 finished with value: 0.8140211640211641 and parameters: {'n_estimators': 118, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.762612867529147}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:13,714] Trial 31 finished with value: 0.8143518518518519 and parameters: {'n_estimators': 119, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7289439110262834}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:15,948] Trial 32 finished with value: 0.8098544973544973 and parameters: {'n_estimators': 131, 'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_samples': 0.7351197321480644}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:17,320] Trial 33 finished with value: 0.8099206349206349 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.7193822350414272}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:19,856] Trial 34 finished with value: 0.8142195767195768 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7170847506546885}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:21,738] Trial 35 finished with value: 0.8150132275132276 and parameters: {'n_estimators': 116, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_samples': 0.7011040551906399}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:24,612] Trial 36 finished with value: 0.8111111111111111 and parameters: {'n_estimators': 175, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.7577492381125084}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:26,915] Trial 37 finished with value: 0.8093915343915346 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_samples': 0.7360248081343999}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:28,275] Trial 38 finished with value: 0.8119708994708995 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_samples': 0.8122541331127795}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:30,321] Trial 39 finished with value: 0.8140211640211641 and parameters: {'n_estimators': 134, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7477414909421436}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:32,671] Trial 40 finished with value: 0.8189814814814815 and parameters: {'n_estimators': 122, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.796716095944518}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:34,585] Trial 41 finished with value: 0.8186507936507936 and parameters: {'n_estimators': 123, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7925082071390059}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:37,250] Trial 42 finished with value: 0.8147486772486774 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.7899664277375841}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:39,054] Trial 43 finished with value: 0.8192460317460316 and parameters: {'n_estimators': 111, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7964177746459714}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:40,767] Trial 44 finished with value: 0.8196428571428571 and parameters: {'n_estimators': 106, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7985251157495628}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:42,334] Trial 45 finished with value: 0.8122354497354497 and parameters: {'n_estimators': 97, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_samples': 0.8082917172710189}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:44,054] Trial 46 finished with value: 0.8009920634920633 and parameters: {'n_estimators': 111, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.823330944102179}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:45,801] Trial 47 finished with value: 0.8131613756613756 and parameters: {'n_estimators': 107, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.8019780334212069}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:47,234] Trial 48 finished with value: 0.8140211640211641 and parameters: {'n_estimators': 85, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_samples': 0.8435836054665443}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:48,834] Trial 49 finished with value: 0.8128306878306878 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.7678220130015694}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:48,838] A new study created in memory with name: no-name-bcb64d72-26a1-41d0-aa1c-c1495721d431\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ RandomForest optimizado en 106.8 segundos\n",
            "‚ùå Error optimizando RandomForest: 'randomforest'\n",
            "\n",
            "üî• Optimizando LogisticRegression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-17 15:41:50,436] Trial 0 finished with value: 0.5261243386243386 and parameters: {'C': 0.13292918943162169, 'penalty': 'l1', 'l1_ratio': 0.22481491235394924}. Best is trial 0 with value: 0.5261243386243386.\n",
            "[I 2025-10-17 15:41:51,739] Trial 1 finished with value: 0.5263227513227513 and parameters: {'C': 0.029375384576328288, 'penalty': 'l2', 'l1_ratio': 0.6664580622368363}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:41:53,290] Trial 2 finished with value: 0.5188492063492063 and parameters: {'C': 0.011527987128232402, 'penalty': 'l1', 'l1_ratio': 0.24545997376568052}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:41:54,603] Trial 3 finished with value: 0.5263227513227513 and parameters: {'C': 0.03549878832196503, 'penalty': 'l2', 'l1_ratio': 0.3329833121584336}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:41:56,256] Trial 4 finished with value: 0.5263227513227513 and parameters: {'C': 0.6847920095574779, 'penalty': 'elasticnet', 'l1_ratio': 0.46485598737362877}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:41:57,926] Trial 5 finished with value: 0.5263227513227513 and parameters: {'C': 2.267398652378039, 'penalty': 'elasticnet', 'l1_ratio': 0.13716033017599819}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:41:59,592] Trial 6 finished with value: 0.5262566137566138 and parameters: {'C': 0.6647135865318028, 'penalty': 'elasticnet', 'l1_ratio': 0.8725056264596475}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:01,509] Trial 7 finished with value: 0.5263227513227513 and parameters: {'C': 2.6619018884890564, 'penalty': 'elasticnet', 'l1_ratio': 0.45212199499168104}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:03,121] Trial 8 finished with value: 0.526058201058201 and parameters: {'C': 0.023233503515390115, 'penalty': 'elasticnet', 'l1_ratio': 0.3070239852800135}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:05,057] Trial 9 finished with value: 0.5263227513227513 and parameters: {'C': 0.9717775305059632, 'penalty': 'elasticnet', 'l1_ratio': 0.24788356442042164}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:06,424] Trial 10 finished with value: 0.5263227513227513 and parameters: {'C': 0.11795939393640552, 'penalty': 'l2', 'l1_ratio': 0.7396121299403545}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:08,407] Trial 11 finished with value: 0.5263227513227513 and parameters: {'C': 0.048643296031797754, 'penalty': 'l2', 'l1_ratio': 0.641509177726393}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:11,802] Trial 12 finished with value: 0.5263227513227513 and parameters: {'C': 0.05838891112221528, 'penalty': 'l2', 'l1_ratio': 0.6015069159252542}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:13,410] Trial 13 finished with value: 0.5262566137566138 and parameters: {'C': 0.010535758678621911, 'penalty': 'l2', 'l1_ratio': 0.38487297866799497}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:14,730] Trial 14 finished with value: 0.5263227513227513 and parameters: {'C': 0.1792743083935294, 'penalty': 'l2', 'l1_ratio': 0.596462156415521}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:16,085] Trial 15 finished with value: 0.5263227513227513 and parameters: {'C': 0.036151333283231245, 'penalty': 'l2', 'l1_ratio': 0.8477649146326477}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:17,598] Trial 16 finished with value: 0.5262566137566138 and parameters: {'C': 0.02042244444660552, 'penalty': 'l2', 'l1_ratio': 0.7228552117727759}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:19,961] Trial 17 finished with value: 0.5263227513227514 and parameters: {'C': 0.3289097827655384, 'penalty': 'l1', 'l1_ratio': 0.36983024111903656}. Best is trial 17 with value: 0.5263227513227514.\n",
            "[I 2025-10-17 15:42:21,694] Trial 18 finished with value: 0.5263227513227513 and parameters: {'C': 5.698424265594236, 'penalty': 'l1', 'l1_ratio': 0.5136010781213356}. Best is trial 17 with value: 0.5263227513227514.\n",
            "[I 2025-10-17 15:42:23,276] Trial 19 finished with value: 0.5263888888888889 and parameters: {'C': 0.3124672248985641, 'penalty': 'l1', 'l1_ratio': 0.727434095713347}. Best is trial 19 with value: 0.5263888888888889.\n",
            "[I 2025-10-17 15:42:24,759] Trial 20 finished with value: 0.5262566137566138 and parameters: {'C': 0.39330693639946823, 'penalty': 'l1', 'l1_ratio': 0.5359127730493034}. Best is trial 19 with value: 0.5263888888888889.\n",
            "[I 2025-10-17 15:42:26,259] Trial 21 finished with value: 0.5263888888888889 and parameters: {'C': 0.28055263269872655, 'penalty': 'l1', 'l1_ratio': 0.7478924398897913}. Best is trial 19 with value: 0.5263888888888889.\n",
            "[I 2025-10-17 15:42:27,750] Trial 22 finished with value: 0.5264550264550264 and parameters: {'C': 0.2857518769502799, 'penalty': 'l1', 'l1_ratio': 0.7900905793405165}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:29,260] Trial 23 finished with value: 0.5263227513227513 and parameters: {'C': 0.21242129802055154, 'penalty': 'l1', 'l1_ratio': 0.8069546223208686}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:30,794] Trial 24 finished with value: 0.526058201058201 and parameters: {'C': 0.07572045504875334, 'penalty': 'l1', 'l1_ratio': 0.7571567793589762}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:32,355] Trial 25 finished with value: 0.5263227513227513 and parameters: {'C': 1.3128294870183799, 'penalty': 'l1', 'l1_ratio': 0.7742200222566037}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:33,961] Trial 26 finished with value: 0.5261904761904762 and parameters: {'C': 0.4476556292630487, 'penalty': 'l1', 'l1_ratio': 0.6825007459857451}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:35,479] Trial 27 finished with value: 0.5263888888888889 and parameters: {'C': 0.2468877195053605, 'penalty': 'l1', 'l1_ratio': 0.81677013563455}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:36,975] Trial 28 finished with value: 0.5259920634920635 and parameters: {'C': 0.09112084128938681, 'penalty': 'l1', 'l1_ratio': 0.8870161645817215}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:38,496] Trial 29 finished with value: 0.5262566137566137 and parameters: {'C': 0.13832801925474145, 'penalty': 'l1', 'l1_ratio': 0.7045364040410494}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:39,979] Trial 30 finished with value: 0.5262566137566138 and parameters: {'C': 0.6061372748886079, 'penalty': 'l1', 'l1_ratio': 0.5961191262276462}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:41,459] Trial 31 finished with value: 0.5262566137566138 and parameters: {'C': 0.23581794422148672, 'penalty': 'l1', 'l1_ratio': 0.8256131232422185}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:43,019] Trial 32 finished with value: 0.5264550264550264 and parameters: {'C': 0.2855234436435021, 'penalty': 'l1', 'l1_ratio': 0.7924815894498289}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:44,564] Trial 33 finished with value: 0.5263227513227513 and parameters: {'C': 1.1617238130717205, 'penalty': 'l1', 'l1_ratio': 0.897443067519333}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:46,179] Trial 34 finished with value: 0.5261904761904762 and parameters: {'C': 0.14497654743603186, 'penalty': 'l1', 'l1_ratio': 0.7752210521091049}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:47,829] Trial 35 finished with value: 0.5261904761904762 and parameters: {'C': 0.45373737774953327, 'penalty': 'l1', 'l1_ratio': 0.635062157993675}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:49,573] Trial 36 finished with value: 0.5263227513227514 and parameters: {'C': 0.3270668520659719, 'penalty': 'l1', 'l1_ratio': 0.7980328843877673}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:51,053] Trial 37 finished with value: 0.5262566137566138 and parameters: {'C': 1.9796536718765174, 'penalty': 'l1', 'l1_ratio': 0.6835509081365174}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:52,530] Trial 38 finished with value: 0.5261904761904762 and parameters: {'C': 0.6639711228389134, 'penalty': 'l1', 'l1_ratio': 0.8520219446407394}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:54,082] Trial 39 finished with value: 0.5263888888888889 and parameters: {'C': 0.26868637059853395, 'penalty': 'l1', 'l1_ratio': 0.7313829443798119}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:55,515] Trial 40 finished with value: 0.5260582010582011 and parameters: {'C': 0.11167200675136221, 'penalty': 'l1', 'l1_ratio': 0.648322031353402}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:56,967] Trial 41 finished with value: 0.5261904761904762 and parameters: {'C': 0.16625690046643957, 'penalty': 'l1', 'l1_ratio': 0.8228071215126476}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:58,438] Trial 42 finished with value: 0.5262566137566138 and parameters: {'C': 0.2332252554125754, 'penalty': 'l1', 'l1_ratio': 0.7664261923539729}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:59,910] Trial 43 finished with value: 0.5263227513227513 and parameters: {'C': 0.8919456131875128, 'penalty': 'elasticnet', 'l1_ratio': 0.8000558868703834}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:01,399] Trial 44 finished with value: 0.5261243386243387 and parameters: {'C': 0.5259987383095315, 'penalty': 'l1', 'l1_ratio': 0.8606508154190307}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:02,885] Trial 45 finished with value: 0.5263227513227514 and parameters: {'C': 0.325809551100651, 'penalty': 'l1', 'l1_ratio': 0.7089586567887852}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:04,701] Trial 46 finished with value: 0.5263227513227513 and parameters: {'C': 0.8654688364534009, 'penalty': 'elasticnet', 'l1_ratio': 0.5505479973599966}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:06,386] Trial 47 finished with value: 0.5262566137566138 and parameters: {'C': 0.19035737913167386, 'penalty': 'l1', 'l1_ratio': 0.7452958224801045}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:07,900] Trial 48 finished with value: 0.5259920634920635 and parameters: {'C': 0.08707399575367727, 'penalty': 'l1', 'l1_ratio': 0.15651449147364632}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:09,436] Trial 49 finished with value: 0.5263227513227513 and parameters: {'C': 1.6278777842464567, 'penalty': 'elasticnet', 'l1_ratio': 0.4706001850195148}. Best is trial 22 with value: 0.5264550264550264.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LogisticRegression optimizado en 80.6 segundos\n",
            "‚ùå Error optimizando LogisticRegression: 'logisticregression'\n",
            "\n",
            "‚úÖ Optimizaci√≥n completada para todos los modelos\n"
          ]
        }
      ],
      "source": [
        "# Optimizar todos los modelos\n",
        "print(\"üî• OPTIMIZANDO TODOS LOS MODELOS...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Lista de modelos a optimizar\n",
        "models_to_optimize = [\n",
        "    ('XGBoost', optimizer.optimize_xgboost),\n",
        "    ('LightGBM', optimizer.optimize_lightgbm),\n",
        "    ('CatBoost', optimizer.optimize_catboost),\n",
        "    ('RandomForest', optimizer.optimize_random_forest),\n",
        "    ('LogisticRegression', optimizer.optimize_logistic_regression)\n",
        "]\n",
        "\n",
        "# Optimizar cada modelo\n",
        "for model_name, optimize_func in models_to_optimize:\n",
        "    print(f\"\\nüî• Optimizando {model_name}...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        best_params = optimize_func()\n",
        "        end_time = time.time()\n",
        "        \n",
        "        print(f\"‚úÖ {model_name} optimizado en {end_time - start_time:.1f} segundos\")\n",
        "        print(f\"   üèÜ Mejor CV Score: {optimizer.best_scores[model_name.lower().replace(' ', '_')]:.4f}\")\n",
        "        print(f\"   ‚öôÔ∏è Mejores par√°metros: {best_params}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error optimizando {model_name}: {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Optimizaci√≥n completada para todos los modelos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä RESUMEN DE OPTIMIZACI√ìN\n",
            "==================================================\n",
            "XGBOOST: 0.7715\n",
            "LIGHTGBM: 0.7912\n",
            "RANDOM_FOREST: 0.8196\n",
            "LOGISTIC_REGRESSION: 0.5265\n",
            "\n",
            "üèÜ MEJOR MODELO: RANDOM_FOREST\n",
            "üìä Mejor CV Score: 0.8196\n"
          ]
        }
      ],
      "source": [
        "# Resumen de optimizaci√≥n\n",
        "print(\"üìä RESUMEN DE OPTIMIZACI√ìN\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for model_name, score in optimizer.best_scores.items():\n",
        "    print(f\"{model_name.upper()}: {score:.4f}\")\n",
        "\n",
        "# Encontrar el mejor modelo\n",
        "best_model_name = max(optimizer.best_scores, key=optimizer.best_scores.get)\n",
        "best_score = optimizer.best_scores[best_model_name]\n",
        "\n",
        "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name.upper()}\")\n",
        "print(f\"üìä Mejor CV Score: {best_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèãÔ∏è Entrenando modelos optimizados...\n",
            "   Entrenando XGBoost...\n",
            "   Entrenando LightGBM...\n",
            "   Entrenando RandomForest...\n",
            "‚úÖ Todos los modelos entrenados\n"
          ]
        }
      ],
      "source": [
        "# Entrenar modelos optimizados y evaluar\n",
        "print(\"üèãÔ∏è Entrenando modelos optimizados...\")\n",
        "\n",
        "# Crear modelos con mejores par√°metros\n",
        "models = {\n",
        "    'XGBoost': xgb.XGBClassifier(**optimizer.best_params['xgboost'], random_state=RANDOM_STATE),\n",
        "    'LightGBM': lgb.LGBMClassifier(**optimizer.best_params['lightgbm'], random_state=RANDOM_STATE, verbose=-1),\n",
        "   # 'CatBoost': cb.CatBoostClassifier(**optimizer.best_params['catboost'], random_seed=RANDOM_STATE, verbose=False),\n",
        "    'RandomForest': RandomForestClassifier(**optimizer.best_params['random_forest'], random_state=RANDOM_STATE),\n",
        "   # 'LogisticRegression': LogisticRegression(**optimizer.best_params['logistic_regression'], random_state=RANDOM_STATE)\n",
        "}\n",
        "\n",
        "# Entrenar todos los modelos\n",
        "trained_models = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"   Entrenando {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    trained_models[name] = model\n",
        "\n",
        "print(\"‚úÖ Todos los modelos entrenados\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä EVALUANDO MODELOS EN TRAIN/TEST/HOLDOUT...\n",
            "============================================================\n",
            "\n",
            "üîç Evaluando XGBoost...\n",
            "   üìà Train  - AUC: 0.8091, PSI: N/A, Green: 30.0%\n",
            "   üß™ Test   - AUC: 0.7139, PSI: 0.0557, Green: 30.0%\n",
            "   üîí Holdout - AUC: 0.7779, PSI: 0.0083, Green: 10.0%\n",
            "\n",
            "üîç Evaluando LightGBM...\n",
            "   üìà Train  - AUC: 0.9353, PSI: N/A, Green: 10.0%\n",
            "   üß™ Test   - AUC: 0.7455, PSI: inf, Green: 40.0%\n",
            "   üîí Holdout - AUC: 0.7913, PSI: inf, Green: 40.0%\n",
            "\n",
            "üîç Evaluando RandomForest...\n",
            "   üìà Train  - AUC: 0.9525, PSI: N/A, Green: 0.0%\n",
            "   üß™ Test   - AUC: 0.7469, PSI: 0.2022, Green: 40.0%\n",
            "   üîí Holdout - AUC: 0.7963, PSI: 0.0751, Green: 40.0%\n"
          ]
        }
      ],
      "source": [
        "# Evaluar modelos en Train, Test y Holdout\n",
        "print(\"üìä EVALUANDO MODELOS EN TRAIN/TEST/HOLDOUT...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in trained_models.items():\n",
        "    print(f\"\\nüîç Evaluando {model_name}...\")\n",
        "    \n",
        "    # Predicciones en cada conjunto\n",
        "    train_proba = model.predict_proba(X_train)[:, 1]\n",
        "    test_proba = model.predict_proba(X_test)[:, 1]\n",
        "    holdout_proba = model.predict_proba(X_holdout)[:, 1]\n",
        "    \n",
        "    # Evaluar en cada conjunto\n",
        "    train_metrics = CreditScoringMetrics.evaluate_model(y_train, train_proba)\n",
        "    test_metrics = CreditScoringMetrics.evaluate_model(y_test, test_proba, train_proba)\n",
        "    holdout_metrics = CreditScoringMetrics.evaluate_model(y_holdout, holdout_proba, train_proba)\n",
        "    \n",
        "    results[model_name] = {\n",
        "        'train': train_metrics,\n",
        "        'test': test_metrics,\n",
        "        'holdout': holdout_metrics\n",
        "    }\n",
        "    \n",
        "    # Mostrar resultados\n",
        "    print(f\"   üìà Train  - AUC: {train_metrics['auc_roc']:.4f}, PSI: N/A, Green: {train_metrics['traffic_light']['green_percentage']:.1f}%\")\n",
        "    print(f\"   üß™ Test   - AUC: {test_metrics['auc_roc']:.4f}, PSI: {test_metrics['psi']:.4f}, Green: {test_metrics['traffic_light']['green_percentage']:.1f}%\")\n",
        "    print(f\"   üîí Holdout - AUC: {holdout_metrics['auc_roc']:.4f}, PSI: {holdout_metrics['psi']:.4f}, Green: {holdout_metrics['traffic_light']['green_percentage']:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "source code string cannot contain null bytes (<string>)",
          "output_type": "error",
          "traceback": [
            "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
            "  File \u001b[92m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3546\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexec(open('simple_exec.py').read())\u001b[39m\n",
            "  \u001b[36mFile \u001b[39m\u001b[32m<string>\u001b[39m\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m source code string cannot contain null bytes\n"
          ]
        }
      ],
      "source": [
        "exec(open('simple_exec.py').read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "source code string cannot contain null bytes (<string>)",
          "output_type": "error",
          "traceback": [
            "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
            "  File \u001b[92m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3546\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexec(open('complete_traffic_light.py').read())\u001b[39m\n",
            "  \u001b[36mFile \u001b[39m\u001b[32m<string>\u001b[39m\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m source code string cannot contain null bytes\n"
          ]
        }
      ],
      "source": [
        "exec(open('complete_traffic_light.py').read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistical Traffic Light functions loaded successfully\n",
            "Evaluating models with statistical Traffic Light...\n",
            "Evaluating XGBoost with statistical Traffic Light...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'scipy.stats' has no attribute 'binom_test'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Evaluate models with statistical Traffic Light\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mEvaluating models with statistical Traffic Light...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results_statistical = \u001b[43mevaluate_models_statistical\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrained_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_holdout\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mStatistical evaluation completed\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:93\u001b[39m, in \u001b[36mevaluate_models_statistical\u001b[39m\u001b[34m(models, X_train, y_train, X_test, y_test, X_holdout, y_holdout)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:32\u001b[39m, in \u001b[36mcalculate_traffic_light_statistical\u001b[39m\u001b[34m(y_true, y_pred_proba, n_groups, alpha)\u001b[39m\n",
            "\u001b[31mAttributeError\u001b[39m: module 'scipy.stats' has no attribute 'binom_test'"
          ]
        }
      ],
      "source": [
        "exec(open('traffic_light_fix.py').read())\n",
        "\n",
        "# Evaluate models with statistical Traffic Light\n",
        "print('Evaluating models with statistical Traffic Light...')\n",
        "results_statistical = evaluate_models_statistical(\n",
        "    trained_models, X_train, y_train, X_test, y_test, X_holdout, y_holdout\n",
        ")\n",
        "\n",
        "print('Statistical evaluation completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "source code string cannot contain null bytes (<string>)",
          "output_type": "error",
          "traceback": [
            "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
            "  File \u001b[92m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3546\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexec(open('simple_exec.py').read())\u001b[39m\n",
            "  \u001b[36mFile \u001b[39m\u001b[32m<string>\u001b[39m\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m source code string cannot contain null bytes\n"
          ]
        }
      ],
      "source": [
        "exec(open('simple_exec.py').read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistical Traffic Light functions loaded successfully\n",
            "Evaluating models with statistical Traffic Light...\n",
            "Evaluating XGBoost with statistical Traffic Light...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'scipy.stats' has no attribute 'binom_test'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m exec(\u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mtraffic_light_fix.py\u001b[39m\u001b[33m'\u001b[39m).read())\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mEvaluating models with statistical Traffic Light...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results_statistical = \u001b[43mevaluate_models_statistical\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrained_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_holdout\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mStatistical evaluation completed\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:93\u001b[39m, in \u001b[36mevaluate_models_statistical\u001b[39m\u001b[34m(models, X_train, y_train, X_test, y_test, X_holdout, y_holdout)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:32\u001b[39m, in \u001b[36mcalculate_traffic_light_statistical\u001b[39m\u001b[34m(y_true, y_pred_proba, n_groups, alpha)\u001b[39m\n",
            "\u001b[31mAttributeError\u001b[39m: module 'scipy.stats' has no attribute 'binom_test'"
          ]
        }
      ],
      "source": [
        "# Traffic Light Statistical Analysis\n",
        "exec(open('traffic_light_fix.py').read())\n",
        "\n",
        "print('Evaluating models with statistical Traffic Light...')\n",
        "results_statistical = evaluate_models_statistical(\n",
        "    trained_models, X_train, y_train, X_test, y_test, X_holdout, y_holdout\n",
        ")\n",
        "\n",
        "print('Statistical evaluation completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistical Traffic Light functions loaded successfully\n",
            "Evaluating models with statistical Traffic Light...\n",
            "Evaluating XGBoost with statistical Traffic Light...\n",
            "   Train  - Green: 50.0%, Yellow: 0.0%, Red: 50.0%\n",
            "   Test   - Green: 90.0%, Yellow: 10.0%, Red: 0.0%\n",
            "   Holdout - Green: 90.0%, Yellow: 0.0%, Red: 10.0%\n",
            "Evaluating LightGBM with statistical Traffic Light...\n",
            "   Train  - Green: 60.0%, Yellow: 10.0%, Red: 30.0%\n",
            "   Test   - Green: 100.0%, Yellow: 0.0%, Red: 0.0%\n",
            "   Holdout - Green: 100.0%, Yellow: 0.0%, Red: 0.0%\n",
            "Evaluating RandomForest with statistical Traffic Light...\n",
            "   Train  - Green: 50.0%, Yellow: 0.0%, Red: 50.0%\n",
            "   Test   - Green: 100.0%, Yellow: 0.0%, Red: 0.0%\n",
            "   Holdout - Green: 100.0%, Yellow: 0.0%, Red: 0.0%\n",
            "Statistical evaluation completed\n"
          ]
        }
      ],
      "source": [
        "# Traffic Light Statistical Analysis\n",
        "exec(open('traffic_light_fix.py').read())\n",
        "\n",
        "print('Evaluating models with statistical Traffic Light...')\n",
        "results_statistical = evaluate_models_statistical(\n",
        "    trained_models, X_train, y_train, X_test, y_test, X_holdout, y_holdout\n",
        ")\n",
        "\n",
        "print('Statistical evaluation completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "ename": "UnicodeDecodeError",
          "evalue": "'charmap' codec can't decode byte 0x81 in position 747: character maps to <undefined>",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m exec(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexecute_basel_traffic_light.py\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py:23\u001b[39m, in \u001b[36mIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs.charmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m.errors,decoding_table)[\u001b[32m0\u001b[39m]\n",
            "\u001b[31mUnicodeDecodeError\u001b[39m: 'charmap' codec can't decode byte 0x81 in position 747: character maps to <undefined>"
          ]
        }
      ],
      "source": [
        "exec(open('execute_basel_traffic_light.py').read())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
