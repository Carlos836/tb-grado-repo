{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🏦 Experimentación Controlada con German Credit Dataset\n",
        "\n",
        "## 📋 Objetivos del Notebook\n",
        "\n",
        "Este notebook implementa una **experimentación controlada** enfocada en:\n",
        "\n",
        "1. **German Credit Dataset** específicamente\n",
        "2. **Optimización con Optuna** para cada modelo\n",
        "3. **Métricas detalladas**: AUC, PSI, Traffic Light\n",
        "4. **Comparación entre**: Train, Test, Holdout\n",
        "5. **Análisis por algoritmo** individual\n",
        "\n",
        "## 🎯 Métricas de Evaluación\n",
        "\n",
        "### Métricas Principales:\n",
        "- **AUC-ROC**: Capacidad discriminante del modelo\n",
        "- **PSI (Population Stability Index)**: Estabilidad de distribución entre muestras\n",
        "- **Traffic Light**: Precisión en grupos de riesgo para rating bancario\n",
        "\n",
        "### Traffic Light Methodology:\n",
        "- **Verde**: Modelo predice correctamente la probabilidad de default\n",
        "- **Amarillo**: Subestimación o sobrestimación leve\n",
        "- **Rojo**: Subestimación o sobrestimación significativa\n",
        "\n",
        "## 🚀 Modelos a Optimizar\n",
        "\n",
        "1. **XGBoost** - Gradient Boosting optimizado\n",
        "2. **CatBoost** - Gradient Boosting con manejo de categóricas\n",
        "3. **LightGBM** - Gradient Boosting eficiente\n",
        "4. **RandomForest** - Ensemble de árboles\n",
        "5. **LogisticRegression** - Modelo lineal baseline\n",
        "\n",
        "## 📊 Estructura de Evaluación\n",
        "\n",
        "Para cada modelo optimizado:\n",
        "- **Train Performance**: Métricas en datos de entrenamiento\n",
        "- **Test Performance**: Métricas en datos de prueba\n",
        "- **Holdout Performance**: Métricas en datos de validación\n",
        "- **Comparación**: Análisis de estabilidad y generalización\n",
        "\n",
        "---\n",
        "\n",
        "**¡Empecemos con la experimentación controlada!** 🎯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Librerías importadas correctamente\n"
          ]
        }
      ],
      "source": [
        "# Importación de librerías\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import MedianPruner\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Modelos específicos\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "# UCI Repository\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Configuración\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"✅ Librerías importadas correctamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 Directorio del proyecto: c:\\Users\\carlo\\OneDrive\\Documentos\\repos\\tb-grado-repo\\notebooks\\..\n",
            "📊 Número de trials Optuna: 50\n",
            "🔄 Folds de CV: 5\n"
          ]
        }
      ],
      "source": [
        "# Configuración del proyecto\n",
        "PROJECT_ROOT = Path('..')\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
        "CONFIGS_DIR = PROJECT_ROOT / 'configs'\n",
        "\n",
        "# Crear directorios si no existen\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Configuración de experimento\n",
        "RANDOM_STATE = 42\n",
        "N_TRIALS = 100  # Aumentado para grillas más finas\n",
        "CV_FOLDS = 5   # Folds para cross-validation\n",
        "\n",
        "print(f\"📁 Directorio del proyecto: {PROJECT_ROOT.absolute()}\")\n",
        "print(f\"📊 Número de trials Optuna: {N_TRIALS}\")\n",
        "print(f\"🔄 Folds de CV: {CV_FOLDS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📥 Cargando German Credit Dataset...\n",
            "✅ Dataset cargado exitosamente\n",
            "   📊 Forma de X: (1000, 20)\n",
            "   📊 Forma de y: (1000, 1)\n",
            "   🎯 Variable objetivo: class\n",
            "\n",
            "📋 Información del dataset:\n",
            "   Features: ['Attribute1', 'Attribute2', 'Attribute3', 'Attribute4', 'Attribute5', 'Attribute6', 'Attribute7', 'Attribute8', 'Attribute9', 'Attribute10', 'Attribute11', 'Attribute12', 'Attribute13', 'Attribute14', 'Attribute15', 'Attribute16', 'Attribute17', 'Attribute18', 'Attribute19', 'Attribute20']\n",
            "   Tipos de datos: {dtype('O'): 13, dtype('int64'): 7}\n",
            "   Valores únicos en target: {1: 700, 2: 300}\n"
          ]
        }
      ],
      "source": [
        "# Cargar German Credit Dataset\n",
        "print(\"📥 Cargando German Credit Dataset...\")\n",
        "\n",
        "try:\n",
        "    # Cargar dataset desde UCI Repository\n",
        "    german_credit = fetch_ucirepo(id=144)\n",
        "    \n",
        "    # Obtener datos\n",
        "    X = german_credit.data.features\n",
        "    y = german_credit.data.targets\n",
        "    \n",
        "    print(f\"✅ Dataset cargado exitosamente\")\n",
        "    print(f\"   📊 Forma de X: {X.shape}\")\n",
        "    print(f\"   📊 Forma de y: {y.shape}\")\n",
        "    print(f\"   🎯 Variable objetivo: {y.columns[0]}\")\n",
        "    \n",
        "    # Mostrar información del dataset\n",
        "    print(f\"\\n📋 Información del dataset:\")\n",
        "    print(f\"   Features: {list(X.columns)}\")\n",
        "    print(f\"   Tipos de datos: {X.dtypes.value_counts().to_dict()}\")\n",
        "    print(f\"   Valores únicos en target: {y.iloc[:, 0].value_counts().to_dict()}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error cargando dataset: {e}\")\n",
        "    print(\"🔄 Intentando cargar desde archivo local...\")\n",
        "    \n",
        "    # Intentar cargar desde archivo local si existe\n",
        "    local_file = DATA_DIR / 'german_credit.csv'\n",
        "    if local_file.exists():\n",
        "        df = pd.read_csv(local_file)\n",
        "        X = df.drop('target', axis=1)\n",
        "        y = df[['target']]\n",
        "        print(f\"✅ Dataset cargado desde archivo local\")\n",
        "    else:\n",
        "        print(f\"❌ No se pudo cargar el dataset\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Preprocesando datos...\n",
            "📊 Distribución del target:\n",
            "   Good Credit (0): 700 (70.0%)\n",
            "   Bad Credit (1): 300 (30.0%)\n",
            "\n",
            "📋 Tipos de variables:\n",
            "   Categóricas: 13 - ['Attribute1', 'Attribute3', 'Attribute4', 'Attribute6', 'Attribute7', 'Attribute9', 'Attribute10', 'Attribute12', 'Attribute14', 'Attribute15', 'Attribute17', 'Attribute19', 'Attribute20']\n",
            "   Numéricas: 7 - ['Attribute2', 'Attribute5', 'Attribute8', 'Attribute11', 'Attribute13', 'Attribute16', 'Attribute18']\n",
            "✅ Variables categóricas codificadas\n",
            "📊 Forma final: (1000, 20)\n"
          ]
        }
      ],
      "source": [
        "# Preprocesamiento de datos\n",
        "print(\"🔧 Preprocesando datos...\")\n",
        "\n",
        "# Convertir target a binario (1 = bad credit, 0 = good credit)\n",
        "y_binary = (y.iloc[:, 0] == 2).astype(int)  # 2 = bad credit en German dataset\n",
        "\n",
        "print(f\"📊 Distribución del target:\")\n",
        "print(f\"   Good Credit (0): {(y_binary == 0).sum()} ({(y_binary == 0).mean()*100:.1f}%)\")\n",
        "print(f\"   Bad Credit (1): {(y_binary == 1).sum()} ({(y_binary == 1).mean()*100:.1f}%)\")\n",
        "\n",
        "# Identificar variables categóricas y numéricas\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"\\n📋 Tipos de variables:\")\n",
        "print(f\"   Categóricas: {len(categorical_cols)} - {categorical_cols}\")\n",
        "print(f\"   Numéricas: {len(numerical_cols)} - {numerical_cols}\")\n",
        "\n",
        "# Codificar variables categóricas\n",
        "X_encoded = X.copy()\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(f\"✅ Variables categóricas codificadas\")\n",
        "print(f\"📊 Forma final: {X_encoded.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Dividiendo datos en Train/Test/Holdout...\n",
            "✅ División de datos completada:\n",
            "   🏋️ Train: 600 muestras (60%)\n",
            "   🧪 Test: 200 muestras (20%)\n",
            "   🔒 Holdout: 200 muestras (20%)\n",
            "\n",
            "📊 Distribución del target por conjunto:\n",
            "   Train: 0.300 (180/600)\n",
            "   Test: 0.300 (60/200)\n",
            "   Holdout: 0.300 (60/200)\n"
          ]
        }
      ],
      "source": [
        "# División de datos: Train (60%) / Test (20%) / Holdout (20%)\n",
        "print(\"📊 Dividiendo datos en Train/Test/Holdout...\")\n",
        "\n",
        "# Primera división: Train+Test (80%) / Holdout (20%)\n",
        "X_temp, X_holdout, y_temp, y_holdout = train_test_split(\n",
        "    X_encoded, y_binary, \n",
        "    test_size=0.2, \n",
        "    random_state=RANDOM_STATE, \n",
        "    stratify=y_binary\n",
        ")\n",
        "\n",
        "# Segunda división: Train (60%) / Test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_temp, y_temp, \n",
        "    test_size=0.25,  # 0.25 de 0.8 = 0.2 del total\n",
        "    random_state=RANDOM_STATE, \n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"✅ División de datos completada:\")\n",
        "print(f\"   🏋️ Train: {X_train.shape[0]} muestras (60%)\")\n",
        "print(f\"   🧪 Test: {X_test.shape[0]} muestras (20%)\")\n",
        "print(f\"   🔒 Holdout: {X_holdout.shape[0]} muestras (20%)\")\n",
        "\n",
        "# Verificar distribución del target en cada conjunto\n",
        "print(f\"\\n📊 Distribución del target por conjunto:\")\n",
        "for name, y_set in [('Train', y_train), ('Test', y_test), ('Holdout', y_holdout)]:\n",
        "    bad_rate = y_set.mean()\n",
        "    print(f\"   {name}: {bad_rate:.3f} ({y_set.sum()}/{len(y_set)})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Clase de métricas creada\n"
          ]
        }
      ],
      "source": [
        "# Clase para métricas de evaluación\n",
        "class CreditScoringMetrics:\n",
        "    \"\"\"\n",
        "    Clase para calcular métricas específicas de scoring crediticio\n",
        "    \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_auc_roc(y_true, y_pred_proba):\n",
        "        \"\"\"\n",
        "        Calcula AUC-ROC\n",
        "        \"\"\"\n",
        "        return roc_auc_score(y_true, y_pred_proba)\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_psi(expected, actual, bins=10):\n",
        "        \"\"\"\n",
        "        Calcula Population Stability Index (PSI)\n",
        "        \n",
        "        Args:\n",
        "            expected: Distribución esperada (train)\n",
        "            actual: Distribución actual (test/holdout)\n",
        "            bins: Número de bins para discretizar\n",
        "        \n",
        "        Returns:\n",
        "            PSI value\n",
        "        \"\"\"\n",
        "        # Crear bins basados en la distribución esperada\n",
        "        breakpoints = np.linspace(0, 1, bins + 1)\n",
        "        breakpoints[0] = -np.inf\n",
        "        breakpoints[-1] = np.inf\n",
        "        \n",
        "        # Discretizar ambas distribuciones\n",
        "        expected_binned = pd.cut(expected, bins=breakpoints, labels=False)\n",
        "        actual_binned = pd.cut(actual, bins=breakpoints, labels=False)\n",
        "        \n",
        "        # Calcular frecuencias\n",
        "        expected_freq = pd.Series(expected_binned).value_counts(normalize=True, sort=False)\n",
        "        actual_freq = pd.Series(actual_binned).value_counts(normalize=True, sort=False)\n",
        "        \n",
        "        # Asegurar que ambos tengan los mismos bins\n",
        "        for i in range(bins):\n",
        "            if i not in expected_freq.index:\n",
        "                expected_freq[i] = 0\n",
        "            if i not in actual_freq.index:\n",
        "                actual_freq[i] = 0\n",
        "        \n",
        "        expected_freq = expected_freq.sort_index()\n",
        "        actual_freq = actual_freq.sort_index()\n",
        "        \n",
        "        # Calcular PSI\n",
        "        psi = 0\n",
        "        for i in range(bins):\n",
        "            if expected_freq.iloc[i] > 0:\n",
        "                psi += (actual_freq.iloc[i] - expected_freq.iloc[i]) * \\\n",
        "                       np.log(actual_freq.iloc[i] / expected_freq.iloc[i])\n",
        "        \n",
        "        return psi\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_traffic_light(y_true, y_pred_proba, n_groups=10):\n",
        "        \"\"\"\n",
        "        Calcula Traffic Light para grupos de riesgo por deciles\n",
        "        \n",
        "        Args:\n",
        "            y_true: Valores reales\n",
        "            y_pred_proba: Probabilidades predichas\n",
        "            n_groups: Número de grupos de riesgo (deciles)\n",
        "        \n",
        "        Returns:\n",
        "            Dict con estadísticas de Traffic Light\n",
        "        \"\"\"\n",
        "        # Crear DataFrame con datos\n",
        "        df = pd.DataFrame({\n",
        "            'actual': y_true,\n",
        "            'predicted': y_pred_proba\n",
        "        })\n",
        "        \n",
        "        # Crear deciles basados en probabilidades predichas (descendente)\n",
        "        # Decil 1 = mayor riesgo, Decil 10 = menor riesgo\n",
        "        df['decile'] = pd.qcut(df['predicted'], q=n_groups, labels=False, duplicates='drop') + 1\n",
        "        \n",
        "        # Calcular métricas por decil\n",
        "        group_stats = []\n",
        "        for decile in range(1, n_groups + 1):\n",
        "            decile_data = df[df['decile'] == decile]\n",
        "            if len(decile_data) > 0:\n",
        "                actual_rate = decile_data['actual'].mean()\n",
        "                predicted_rate = decile_data['predicted'].mean()\n",
        "                \n",
        "                # Determinar color del semáforo\n",
        "                diff = abs(actual_rate - predicted_rate)\n",
        "                if diff <= 0.05:  # 5% de tolerancia\n",
        "                    color = 'green'\n",
        "                elif diff <= 0.10:  # 10% de tolerancia\n",
        "                    color = 'yellow'\n",
        "                else:\n",
        "                    color = 'red'\n",
        "                \n",
        "                group_stats.append({\n",
        "                    'decile': decile,\n",
        "                    'actual_rate': actual_rate,\n",
        "                    'predicted_rate': predicted_rate,\n",
        "                    'difference': diff,\n",
        "                    'color': color,\n",
        "                    'size': len(decile_data),\n",
        "                    'min_prob': decile_data['predicted'].min(),\n",
        "                    'max_prob': decile_data['predicted'].max(),\n",
        "                    'avg_prob': decile_data['predicted'].mean()\n",
        "                })\n",
        "        \n",
        "        # Calcular estadísticas generales\n",
        "        colors = [stat['color'] for stat in group_stats]\n",
        "        green_pct = colors.count('green') / len(colors) * 100\n",
        "        yellow_pct = colors.count('yellow') / len(colors) * 100\n",
        "        red_pct = colors.count('red') / len(colors) * 100\n",
        "        \n",
        "        return {\n",
        "            'group_stats': group_stats,\n",
        "            'green_percentage': green_pct,\n",
        "            'yellow_percentage': yellow_pct,\n",
        "            'red_percentage': red_pct,\n",
        "            'total_groups': len(group_stats)\n",
        "        }\n",
        "    \n",
        "    @classmethod\n",
        "    def evaluate_model(cls, y_true, y_pred_proba, y_train_proba=None):\n",
        "        \"\"\"\n",
        "        Evalúa un modelo con todas las métricas\n",
        "        \n",
        "        Args:\n",
        "            y_true: Valores reales\n",
        "            y_pred_proba: Probabilidades predichas\n",
        "            y_train_proba: Probabilidades en train (para PSI)\n",
        "        \n",
        "        Returns:\n",
        "            Dict con todas las métricas\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "        \n",
        "        # AUC-ROC\n",
        "        results['auc_roc'] = cls.calculate_auc_roc(y_true, y_pred_proba)\n",
        "        \n",
        "        # PSI (si se proporcionan datos de train)\n",
        "        if y_train_proba is not None:\n",
        "            results['psi'] = cls.calculate_psi(y_train_proba, y_pred_proba)\n",
        "        \n",
        "        # Traffic Light\n",
        "        traffic_light = cls.calculate_traffic_light(y_true, y_pred_proba)\n",
        "        results['traffic_light'] = traffic_light\n",
        "        \n",
        "        return results\n",
        "\n",
        "print(\"✅ Clase de métricas creada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Clase de optimización creada\n"
          ]
        }
      ],
      "source": [
        "# Clase para optimización con Optuna\n",
        "class OptunaOptimizer:\n",
        "    \"\"\"\n",
        "    Clase para optimizar modelos con Optuna\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, X_train, y_train, cv_folds=5, n_trials=50):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.cv_folds = cv_folds\n",
        "        self.n_trials = n_trials\n",
        "        self.best_params = {}\n",
        "        self.best_scores = {}\n",
        "        \n",
        "    def optimize_xgboost(self):\n",
        "        \"\"\"\n",
        "        Optimiza XGBoost con Optuna - Enfocado en reducir overfitting\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 150),  # Reducido\n",
        "                'max_depth': trial.suggest_int('max_depth', 2, 8),  # Más restrictivo\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.10),  # Más conservador\n",
        "                'subsample': trial.suggest_float('subsample', 0.1, 0.5),  # Más regularización\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 0.9),  # Más regularización\n",
        "                'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 125.0),  # L1 regularización\n",
        "                'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 125.0),  # L2 regularización\n",
        "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # Control de overfitting\n",
        "                'gamma': trial.suggest_float('gamma', 0, 2),  # Regularización adicional\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = xgb.XGBClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['xgboost'] = study.best_params\n",
        "        self.best_scores['xgboost'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_lightgbm(self):\n",
        "        \"\"\"\n",
        "        Optimiza LightGBM con Optuna - Enfocado en reducir overfitting\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 200),  # Reducido\n",
        "                'max_depth': trial.suggest_int('max_depth', 2, 10),  # Más restrictivo\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15),  # Más conservador\n",
        "                'subsample': trial.suggest_float('subsample', 0.1, 0.5),  # Más regularización\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 0.9),  # Más regularización\n",
        "                'reg_alpha': trial.suggest_float('reg_alpha', 0.1, 125.0),  # L1 regularización\n",
        "                'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 125.0),  # L2 regularización\n",
        "                'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),  # Control de overfitting\n",
        "                'min_split_gain': trial.suggest_float('min_split_gain', 0, 1),  # Regularización adicional\n",
        "                'random_state': RANDOM_STATE,\n",
        "                'verbose': -1\n",
        "            }\n",
        "            \n",
        "            model = lgb.LGBMClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['lightgbm'] = study.best_params\n",
        "        self.best_scores['lightgbm'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_catboost(self):\n",
        "        \"\"\"\n",
        "        Optimiza CatBoost con Optuna - Enfocado en reducir overfitting\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'iterations': trial.suggest_int('iterations', 50, 250),  # Reducido\n",
        "                'depth': trial.suggest_int('depth', 2, 6),  # Más restrictivo\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),  # Más conservador\n",
        "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 100),  # L2 regularización\n",
        "                'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
        "                'subsample': trial.suggest_float('subsample', 0.7, 0.9),  # Más regularización\n",
        "                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.1, 0.5),  # Regularización\n",
        "                'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),  # Control de overfitting\n",
        "                'random_seed': RANDOM_STATE,\n",
        "                'verbose': False\n",
        "            }\n",
        "            \n",
        "            model = cb.CatBoostClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['catboost'] = study.best_params\n",
        "        self.best_scores['catboost'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_random_forest(self):\n",
        "        \"\"\"\n",
        "        Optimiza Random Forest con Optuna - Enfocado en reducir overfitting\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 200),  # Reducido\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 10),  # Más restrictivo\n",
        "                'min_samples_split': trial.suggest_int('min_samples_split', 5, 20),  # Más restrictivo\n",
        "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 10),  # Más restrictivo\n",
        "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),  # Sin None\n",
        "                'bootstrap': True,  # Bootstrap para regularización\n",
        "                'max_samples': trial.suggest_float('max_samples', 0.7, 0.9),  # Submuestreo\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = RandomForestClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['random_forest'] = study.best_params\n",
        "        self.best_scores['random_forest'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_logistic_regression(self):\n",
        "        \"\"\"\n",
        "        Optimiza Logistic Regression con Optuna - Enfocado en reducir overfitting\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 0.01, 10, log=True),  # Más restrictivo\n",
        "                'penalty': trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet']),\n",
        "                'solver': 'saga',  # Compatible con elasticnet\n",
        "                'l1_ratio': trial.suggest_float('l1_ratio', 0.1, 0.9),  # Para elasticnet\n",
        "                'max_iter': 1000,  # Más iteraciones\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = LogisticRegression(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['logistic_regression'] = study.best_params\n",
        "        self.best_scores['logistic_regression'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "\n",
        "print(\"✅ Clase de optimización creada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Optimizador inicializado\n",
            "   📊 Datos de entrenamiento: (600, 20)\n",
            "   🔄 Folds de CV: 5\n",
            "   🎯 Trials por modelo: 50\n"
          ]
        }
      ],
      "source": [
        "# Inicializar optimizador\n",
        "optimizer = OptunaOptimizer(X_train, y_train, cv_folds=CV_FOLDS, n_trials=N_TRIALS)\n",
        "\n",
        "print(f\"🚀 Optimizador inicializado\")\n",
        "print(f\"   📊 Datos de entrenamiento: {X_train.shape}\")\n",
        "print(f\"   🔄 Folds de CV: {CV_FOLDS}\")\n",
        "print(f\"   🎯 Trials por modelo: {N_TRIALS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-17 15:39:17,272] A new study created in memory with name: no-name-81b4ed15-fdd7-43c0-a2c2-716c52421b09\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔥 OPTIMIZANDO TODOS LOS MODELOS...\n",
            "==================================================\n",
            "\n",
            "🔥 Optimizando XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-17 15:39:17,871] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 87, 'max_depth': 8, 'learning_rate': 0.07587945476302646, 'subsample': 0.3394633936788146, 'colsample_bytree': 0.7312037280884873, 'reg_alpha': 19.583715589991712, 'reg_lambda': 7.354643159808113, 'min_child_weight': 9, 'gamma': 1.2022300234864176}. Best is trial 0 with value: 0.5.\n",
            "[I 2025-10-17 15:39:18,834] Trial 1 finished with value: 0.5 and parameters: {'n_estimators': 121, 'max_depth': 2, 'learning_rate': 0.0972918866945795, 'subsample': 0.4329770563201687, 'colsample_bytree': 0.7424678221356552, 'reg_alpha': 22.80993840416687, 'reg_lambda': 23.007223280693886, 'min_child_weight': 4, 'gamma': 1.0495128632644757}. Best is trial 0 with value: 0.5.\n",
            "[I 2025-10-17 15:39:19,405] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 93, 'max_depth': 4, 'learning_rate': 0.06506676052501416, 'subsample': 0.15579754426081674, 'colsample_bytree': 0.7584289297070436, 'reg_alpha': 45.8585942273821, 'reg_lambda': 57.06314102870779, 'min_child_weight': 8, 'gamma': 0.39934756431671947}. Best is trial 0 with value: 0.5.\n",
            "[I 2025-10-17 15:39:19,957] Trial 3 finished with value: 0.5994378306878307 and parameters: {'n_estimators': 101, 'max_depth': 6, 'learning_rate': 0.014180537144799797, 'subsample': 0.34301794076057535, 'colsample_bytree': 0.7341048247374583, 'reg_alpha': 8.224943963861412, 'reg_lambda': 118.61580360294133, 'min_child_weight': 10, 'gamma': 1.6167946962329223}. Best is trial 3 with value: 0.5994378306878307.\n",
            "[I 2025-10-17 15:39:20,403] Trial 4 finished with value: 0.5 and parameters: {'n_estimators': 80, 'max_depth': 2, 'learning_rate': 0.07158097238609412, 'subsample': 0.27606099749584057, 'colsample_bytree': 0.7244076469689558, 'reg_alpha': 61.94759607289765, 'reg_lambda': 4.395126287290777, 'min_child_weight': 10, 'gamma': 0.5175599632000338}. Best is trial 3 with value: 0.5994378306878307.\n",
            "[I 2025-10-17 15:39:20,834] Trial 5 finished with value: 0.5 and parameters: {'n_estimators': 116, 'max_depth': 4, 'learning_rate': 0.05680612190600298, 'subsample': 0.31868411173731187, 'colsample_bytree': 0.7369708911051054, 'reg_alpha': 121.20112000779336, 'reg_lambda': 96.9140896378032, 'min_child_weight': 10, 'gamma': 1.7896547008552977}. Best is trial 3 with value: 0.5994378306878307.\n",
            "[I 2025-10-17 15:39:21,248] Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 110, 'max_depth': 8, 'learning_rate': 0.017964325184672756, 'subsample': 0.1783931449676581, 'colsample_bytree': 0.7090454577821076, 'reg_alpha': 40.73375831233172, 'reg_lambda': 48.645793482216305, 'min_child_weight': 3, 'gamma': 1.6574750183038587}. Best is trial 3 with value: 0.5994378306878307.\n",
            "[I 2025-10-17 15:39:21,688] Trial 7 finished with value: 0.5 and parameters: {'n_estimators': 86, 'max_depth': 3, 'learning_rate': 0.058842647484242366, 'subsample': 0.15636968998990508, 'colsample_bytree': 0.8604393961508079, 'reg_alpha': 9.411375395603375, 'reg_lambda': 123.3621783814046, 'min_child_weight': 8, 'gamma': 0.3974313630683448}. Best is trial 3 with value: 0.5994378306878307.\n",
            "[I 2025-10-17 15:39:22,060] Trial 8 finished with value: 0.7142857142857142 and parameters: {'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.07361716094628554, 'subsample': 0.3916028672163949, 'colsample_bytree': 0.8542540693371892, 'reg_alpha': 9.348177001587887, 'reg_lambda': 44.872369495179655, 'min_child_weight': 2, 'gamma': 1.726206851751187}. Best is trial 8 with value: 0.7142857142857142.\n",
            "[I 2025-10-17 15:39:22,491] Trial 9 finished with value: 0.5 and parameters: {'n_estimators': 112, 'max_depth': 4, 'learning_rate': 0.015720251525742128, 'subsample': 0.2243929286862649, 'colsample_bytree': 0.7650366644053493, 'reg_alpha': 91.2278116744242, 'reg_lambda': 79.73092817226612, 'min_child_weight': 9, 'gamma': 0.9444298503238986}. Best is trial 8 with value: 0.7142857142857142.\n",
            "[I 2025-10-17 15:39:23,039] Trial 10 finished with value: 0.5 and parameters: {'n_estimators': 52, 'max_depth': 6, 'learning_rate': 0.03769247903052364, 'subsample': 0.47465950130295914, 'colsample_bytree': 0.895844696439752, 'reg_alpha': 86.31185948878624, 'reg_lambda': 32.31507637992639, 'min_child_weight': 1, 'gamma': 1.9386261455081895}. Best is trial 8 with value: 0.7142857142857142.\n",
            "[I 2025-10-17 15:39:23,592] Trial 11 finished with value: 0.7318121693121692 and parameters: {'n_estimators': 147, 'max_depth': 6, 'learning_rate': 0.03895424648532502, 'subsample': 0.3822340495549849, 'colsample_bytree': 0.8139438617739845, 'reg_alpha': 3.966904768602154, 'reg_lambda': 117.53335226124616, 'min_child_weight': 6, 'gamma': 1.4814240611836327}. Best is trial 11 with value: 0.7318121693121692.\n",
            "[I 2025-10-17 15:39:24,163] Trial 12 finished with value: 0.5 and parameters: {'n_estimators': 144, 'max_depth': 6, 'learning_rate': 0.03835472613444918, 'subsample': 0.40150453237089584, 'colsample_bytree': 0.821814772686749, 'reg_alpha': 34.38317316298189, 'reg_lambda': 78.49260386246817, 'min_child_weight': 6, 'gamma': 1.3867400411201398}. Best is trial 11 with value: 0.7318121693121692.\n",
            "[I 2025-10-17 15:39:24,934] Trial 13 finished with value: 0.7645502645502645 and parameters: {'n_estimators': 150, 'max_depth': 7, 'learning_rate': 0.039234221707997896, 'subsample': 0.39236452092136653, 'colsample_bytree': 0.8166284869762422, 'reg_alpha': 3.291131901836877, 'reg_lambda': 41.38940053136723, 'min_child_weight': 6, 'gamma': 1.3710092162578684}. Best is trial 13 with value: 0.7645502645502645.\n",
            "[I 2025-10-17 15:39:25,647] Trial 14 finished with value: 0.7714947089947091 and parameters: {'n_estimators': 149, 'max_depth': 7, 'learning_rate': 0.04397484995849731, 'subsample': 0.49840679574448554, 'colsample_bytree': 0.7979409097155367, 'reg_alpha': 2.7567857408156784, 'reg_lambda': 75.31385949233461, 'min_child_weight': 6, 'gamma': 0.8014695857116751}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:26,281] Trial 15 finished with value: 0.5 and parameters: {'n_estimators': 132, 'max_depth': 7, 'learning_rate': 0.028622696463867413, 'subsample': 0.4750244637464093, 'colsample_bytree': 0.7897096113780152, 'reg_alpha': 67.47066683621411, 'reg_lambda': 72.22326995095453, 'min_child_weight': 5, 'gamma': 0.7709106214069948}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:26,882] Trial 16 finished with value: 0.5999007936507936 and parameters: {'n_estimators': 133, 'max_depth': 7, 'learning_rate': 0.049662386717915646, 'subsample': 0.4918585998724917, 'colsample_bytree': 0.7896543803933558, 'reg_alpha': 26.657532329995455, 'reg_lambda': 98.6615436236377, 'min_child_weight': 7, 'gamma': 0.02635842876184702}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:27,385] Trial 17 finished with value: 0.5 and parameters: {'n_estimators': 132, 'max_depth': 5, 'learning_rate': 0.048740687461325, 'subsample': 0.4366137650070001, 'colsample_bytree': 0.8379348850423535, 'reg_alpha': 54.56886921317782, 'reg_lambda': 31.23470034938862, 'min_child_weight': 5, 'gamma': 0.6802085534834015}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:27,914] Trial 18 finished with value: 0.5 and parameters: {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.028392126702585587, 'subsample': 0.10604448319363502, 'colsample_bytree': 0.7707491548436209, 'reg_alpha': 82.03987491924995, 'reg_lambda': 61.57951130967117, 'min_child_weight': 4, 'gamma': 1.2146899766801897}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:28,576] Trial 19 finished with value: 0.7692129629629629 and parameters: {'n_estimators': 139, 'max_depth': 5, 'learning_rate': 0.08915507162992636, 'subsample': 0.27274311439987087, 'colsample_bytree': 0.8810846065879611, 'reg_alpha': 1.0617419514838984, 'reg_lambda': 97.29500727354494, 'min_child_weight': 7, 'gamma': 0.08671419184671691}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:29,181] Trial 20 finished with value: 0.5 and parameters: {'n_estimators': 137, 'max_depth': 5, 'learning_rate': 0.09966028459647208, 'subsample': 0.2698419830708595, 'colsample_bytree': 0.8996310015361614, 'reg_alpha': 112.9482618461621, 'reg_lambda': 98.19573895994917, 'min_child_weight': 7, 'gamma': 0.03489074720830345}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:29,850] Trial 21 finished with value: 0.7704695767195766 and parameters: {'n_estimators': 138, 'max_depth': 7, 'learning_rate': 0.08893216927518144, 'subsample': 0.2442485298837102, 'colsample_bytree': 0.8745104876923269, 'reg_alpha': 1.5137176153225123, 'reg_lambda': 89.12445607309327, 'min_child_weight': 7, 'gamma': 0.20475399031323377}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:31,545] Trial 22 finished with value: 0.5 and parameters: {'n_estimators': 124, 'max_depth': 5, 'learning_rate': 0.08408583968841997, 'subsample': 0.23029472882524335, 'colsample_bytree': 0.8779690257681977, 'reg_alpha': 18.060436963080637, 'reg_lambda': 87.60774333925177, 'min_child_weight': 7, 'gamma': 0.23558031646630043}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:32,230] Trial 23 finished with value: 0.5 and parameters: {'n_estimators': 140, 'max_depth': 6, 'learning_rate': 0.08720328760371508, 'subsample': 0.2251380320745703, 'colsample_bytree': 0.8733169348855281, 'reg_alpha': 32.95375161613852, 'reg_lambda': 107.023556432377, 'min_child_weight': 8, 'gamma': 0.2146316265548558}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:32,881] Trial 24 finished with value: 0.7698412698412699 and parameters: {'n_estimators': 126, 'max_depth': 7, 'learning_rate': 0.08945919575716665, 'subsample': 0.2847649283601959, 'colsample_bytree': 0.8418829365077973, 'reg_alpha': 1.3124765447876663, 'reg_lambda': 70.51777675060994, 'min_child_weight': 7, 'gamma': 0.18879201971858917}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:33,587] Trial 25 finished with value: 0.6416666666666667 and parameters: {'n_estimators': 124, 'max_depth': 7, 'learning_rate': 0.08308825307293906, 'subsample': 0.29946857873479305, 'colsample_bytree': 0.8365460992894015, 'reg_alpha': 12.369743172387183, 'reg_lambda': 72.4401034869725, 'min_child_weight': 5, 'gamma': 0.6360796306887847}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:34,330] Trial 26 finished with value: 0.5 and parameters: {'n_estimators': 103, 'max_depth': 8, 'learning_rate': 0.06521804212196486, 'subsample': 0.19963060600416926, 'colsample_bytree': 0.8461933850148282, 'reg_alpha': 30.483585473512033, 'reg_lambda': 85.1667528771977, 'min_child_weight': 4, 'gamma': 0.27831247065110326}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:34,846] Trial 27 finished with value: 0.5 and parameters: {'n_estimators': 68, 'max_depth': 7, 'learning_rate': 0.09353884120941976, 'subsample': 0.25615782634866097, 'colsample_bytree': 0.7980618028049963, 'reg_alpha': 17.949511587073868, 'reg_lambda': 68.71867180566123, 'min_child_weight': 6, 'gamma': 0.8570634689532316}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:35,545] Trial 28 finished with value: 0.5 and parameters: {'n_estimators': 132, 'max_depth': 8, 'learning_rate': 0.08093067277908157, 'subsample': 0.3114464566203801, 'colsample_bytree': 0.8274594911096137, 'reg_alpha': 44.35360933963883, 'reg_lambda': 55.443555059618504, 'min_child_weight': 8, 'gamma': 0.5159548805998221}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:36,377] Trial 29 finished with value: 0.7701388888888889 and parameters: {'n_estimators': 125, 'max_depth': 8, 'learning_rate': 0.07734371460437037, 'subsample': 0.36995489008099336, 'colsample_bytree': 0.8571544955452453, 'reg_alpha': 0.198344671852015, 'reg_lambda': 88.932782521382, 'min_child_weight': 9, 'gamma': 0.3548368065005788}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:37,111] Trial 30 finished with value: 0.6849206349206349 and parameters: {'n_estimators': 143, 'max_depth': 8, 'learning_rate': 0.07884882279816971, 'subsample': 0.3595849191581006, 'colsample_bytree': 0.8707512802279974, 'reg_alpha': 16.287038382883612, 'reg_lambda': 108.91890547426463, 'min_child_weight': 9, 'gamma': 0.41998198654539237}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:37,792] Trial 31 finished with value: 0.768154761904762 and parameters: {'n_estimators': 124, 'max_depth': 8, 'learning_rate': 0.09364429510614922, 'subsample': 0.33423557632521717, 'colsample_bytree': 0.8622142138280047, 'reg_alpha': 1.7044048064984927, 'reg_lambda': 89.75726967224196, 'min_child_weight': 9, 'gamma': 0.21164602700576451}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:38,498] Trial 32 finished with value: 0.5 and parameters: {'n_estimators': 118, 'max_depth': 7, 'learning_rate': 0.06799405067955812, 'subsample': 0.4285428039467068, 'colsample_bytree': 0.845686785408725, 'reg_alpha': 24.927348147181, 'reg_lambda': 79.9997617672665, 'min_child_weight': 7, 'gamma': 0.3093972815854337}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:39,154] Trial 33 finished with value: 0.5 and parameters: {'n_estimators': 128, 'max_depth': 7, 'learning_rate': 0.09213532842278205, 'subsample': 0.29732588342515376, 'colsample_bytree': 0.8085286423963672, 'reg_alpha': 20.8029840148337, 'reg_lambda': 68.90824304869055, 'min_child_weight': 8, 'gamma': 0.6044531592848033}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:39,899] Trial 34 finished with value: 0.6904431216931217 and parameters: {'n_estimators': 108, 'max_depth': 8, 'learning_rate': 0.0761268125701318, 'subsample': 0.3583843020634358, 'colsample_bytree': 0.7825361577690793, 'reg_alpha': 10.864761585532465, 'reg_lambda': 60.701193386888136, 'min_child_weight': 8, 'gamma': 1.0750320432309037}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:41,601] Trial 35 finished with value: 0.7692791005291005 and parameters: {'n_estimators': 139, 'max_depth': 6, 'learning_rate': 0.048821627646106515, 'subsample': 0.2448798581966228, 'colsample_bytree': 0.8860794173857823, 'reg_alpha': 1.0126308326139357, 'reg_lambda': 91.01211628059667, 'min_child_weight': 6, 'gamma': 0.140386624198233}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:42,172] Trial 36 finished with value: 0.5 and parameters: {'n_estimators': 115, 'max_depth': 7, 'learning_rate': 0.09706769916390674, 'subsample': 0.19979037113852535, 'colsample_bytree': 0.8324955855847788, 'reg_alpha': 15.640913155128441, 'reg_lambda': 107.16963145010405, 'min_child_weight': 9, 'gamma': 0.398538892773207}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:42,688] Trial 37 finished with value: 0.7646825396825397 and parameters: {'n_estimators': 93, 'max_depth': 8, 'learning_rate': 0.06103104665683848, 'subsample': 0.43388406635948806, 'colsample_bytree': 0.7503185214391948, 'reg_alpha': 6.745504224225602, 'reg_lambda': 13.409821786594897, 'min_child_weight': 10, 'gamma': 0.52010389926339}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:43,172] Trial 38 finished with value: 0.5 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.07170064239515786, 'subsample': 0.3329933226275724, 'colsample_bytree': 0.8555365588607062, 'reg_alpha': 39.63198915132802, 'reg_lambda': 54.25977118432151, 'min_child_weight': 4, 'gamma': 0.7609269779045128}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:43,622] Trial 39 finished with value: 0.5 and parameters: {'n_estimators': 105, 'max_depth': 3, 'learning_rate': 0.05357972571068971, 'subsample': 0.28426469135969556, 'colsample_bytree': 0.8874445449056134, 'reg_alpha': 21.836155399934963, 'reg_lambda': 76.52008080667817, 'min_child_weight': 7, 'gamma': 0.3355277839604067}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:44,414] Trial 40 finished with value: 0.5 and parameters: {'n_estimators': 120, 'max_depth': 8, 'learning_rate': 0.07683936792565757, 'subsample': 0.4548357868814748, 'colsample_bytree': 0.8015659748555057, 'reg_alpha': 54.43377863378497, 'reg_lambda': 65.64773869760246, 'min_child_weight': 5, 'gamma': 0.1244229839222924}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:45,012] Trial 41 finished with value: 0.7662367724867725 and parameters: {'n_estimators': 137, 'max_depth': 6, 'learning_rate': 0.045577337161415966, 'subsample': 0.2526850228802275, 'colsample_bytree': 0.8671379812574185, 'reg_alpha': 0.6831718636329391, 'reg_lambda': 92.85246912653257, 'min_child_weight': 6, 'gamma': 0.15497538711399422}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:45,630] Trial 42 finished with value: 0.7119047619047619 and parameters: {'n_estimators': 143, 'max_depth': 6, 'learning_rate': 0.08687424906480273, 'subsample': 0.24280346407675904, 'colsample_bytree': 0.8870330636461251, 'reg_alpha': 9.680468395353971, 'reg_lambda': 84.4420407944051, 'min_child_weight': 6, 'gamma': 0.4331829762921786}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:46,268] Trial 43 finished with value: 0.7599537037037039 and parameters: {'n_estimators': 146, 'max_depth': 7, 'learning_rate': 0.05312922619440533, 'subsample': 0.16118232521065096, 'colsample_bytree': 0.8477247943964527, 'reg_alpha': 6.907313392616203, 'reg_lambda': 103.45454626070845, 'min_child_weight': 8, 'gamma': 0.012251325056043677}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:46,771] Trial 44 finished with value: 0.6065145502645503 and parameters: {'n_estimators': 136, 'max_depth': 6, 'learning_rate': 0.04408086730856919, 'subsample': 0.1869183062444142, 'colsample_bytree': 0.886165572289926, 'reg_alpha': 12.572706918672978, 'reg_lambda': 92.32725458869531, 'min_child_weight': 3, 'gamma': 0.13397438869013206}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:47,262] Trial 45 finished with value: 0.5305555555555556 and parameters: {'n_estimators': 127, 'max_depth': 7, 'learning_rate': 0.027743321557800574, 'subsample': 0.1324722318639537, 'colsample_bytree': 0.8629665626947983, 'reg_alpha': 6.109097304430534, 'reg_lambda': 83.2162745691878, 'min_child_weight': 7, 'gamma': 0.502943733017889}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:47,825] Trial 46 finished with value: 0.7688492063492064 and parameters: {'n_estimators': 142, 'max_depth': 7, 'learning_rate': 0.061328226759344906, 'subsample': 0.3129882339202258, 'colsample_bytree': 0.8934365718415083, 'reg_alpha': 1.7164156870099476, 'reg_lambda': 75.25072546224972, 'min_child_weight': 10, 'gamma': 0.3341975707040414}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:48,353] Trial 47 finished with value: 0.5 and parameters: {'n_estimators': 150, 'max_depth': 6, 'learning_rate': 0.03177124134815963, 'subsample': 0.2069625662916083, 'colsample_bytree': 0.7215332938520478, 'reg_alpha': 25.9134843275007, 'reg_lambda': 111.2761014751924, 'min_child_weight': 5, 'gamma': 0.9927726442508529}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:48,785] Trial 48 finished with value: 0.5646825396825397 and parameters: {'n_estimators': 97, 'max_depth': 7, 'learning_rate': 0.06958353235953249, 'subsample': 0.3615050246529167, 'colsample_bytree': 0.8539591879305257, 'reg_alpha': 13.999767613100035, 'reg_lambda': 102.44966735790146, 'min_child_weight': 6, 'gamma': 1.1777574150936991}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:49,194] Trial 49 finished with value: 0.5 and parameters: {'n_estimators': 76, 'max_depth': 6, 'learning_rate': 0.043188043628866385, 'subsample': 0.2871389859752282, 'colsample_bytree': 0.8771631272212226, 'reg_alpha': 73.10143330070464, 'reg_lambda': 118.43871596938527, 'min_child_weight': 3, 'gamma': 0.1861506908237423}. Best is trial 14 with value: 0.7714947089947091.\n",
            "[I 2025-10-17 15:39:49,198] A new study created in memory with name: no-name-410c01a1-98eb-4c08-bb7d-10f94d33a8c4\n",
            "[I 2025-10-17 15:39:49,342] Trial 0 finished with value: 0.7014550264550264 and parameters: {'n_estimators': 106, 'max_depth': 10, 'learning_rate': 0.11247915185359669, 'subsample': 0.3394633936788146, 'colsample_bytree': 0.7312037280884873, 'reg_alpha': 19.583715589991712, 'reg_lambda': 7.354643159808113, 'min_child_samples': 45, 'min_split_gain': 0.6011150117432088}. Best is trial 0 with value: 0.7014550264550264.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ XGBoost optimizado en 31.9 segundos\n",
            "   🏆 Mejor CV Score: 0.7715\n",
            "   ⚙️ Mejores parámetros: {'n_estimators': 149, 'max_depth': 7, 'learning_rate': 0.04397484995849731, 'subsample': 0.49840679574448554, 'colsample_bytree': 0.7979409097155367, 'reg_alpha': 2.7567857408156784, 'reg_lambda': 75.31385949233461, 'min_child_weight': 6, 'gamma': 0.8014695857116751}\n",
            "\n",
            "🔥 Optimizando LightGBM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-17 15:39:49,513] Trial 1 finished with value: 0.6892857142857143 and parameters: {'n_estimators': 156, 'max_depth': 2, 'learning_rate': 0.1457873793026792, 'subsample': 0.4329770563201687, 'colsample_bytree': 0.7424678221356552, 'reg_alpha': 22.80993840416687, 'reg_lambda': 23.007223280693886, 'min_child_samples': 22, 'min_split_gain': 0.5247564316322378}. Best is trial 0 with value: 0.7014550264550264.\n",
            "[I 2025-10-17 15:39:49,648] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 115, 'max_depth': 4, 'learning_rate': 0.09565940526113312, 'subsample': 0.15579754426081674, 'colsample_bytree': 0.7584289297070436, 'reg_alpha': 45.8585942273821, 'reg_lambda': 57.06314102870779, 'min_child_samples': 42, 'min_split_gain': 0.19967378215835974}. Best is trial 0 with value: 0.7014550264550264.\n",
            "[I 2025-10-17 15:39:49,845] Trial 3 finished with value: 0.7518849206349207 and parameters: {'n_estimators': 127, 'max_depth': 7, 'learning_rate': 0.01650305778079968, 'subsample': 0.34301794076057535, 'colsample_bytree': 0.7341048247374583, 'reg_alpha': 8.224943963861412, 'reg_lambda': 118.61580360294133, 'min_child_samples': 49, 'min_split_gain': 0.8083973481164611}. Best is trial 3 with value: 0.7518849206349207.\n",
            "[I 2025-10-17 15:39:49,982] Trial 4 finished with value: 0.5 and parameters: {'n_estimators': 95, 'max_depth': 2, 'learning_rate': 0.10579262371170195, 'subsample': 0.27606099749584057, 'colsample_bytree': 0.7244076469689558, 'reg_alpha': 61.94759607289765, 'reg_lambda': 4.395126287290777, 'min_child_samples': 47, 'min_split_gain': 0.2587799816000169}. Best is trial 3 with value: 0.7518849206349207.\n",
            "[I 2025-10-17 15:39:50,139] Trial 5 finished with value: 0.5 and parameters: {'n_estimators': 150, 'max_depth': 4, 'learning_rate': 0.0828095229648935, 'subsample': 0.31868411173731187, 'colsample_bytree': 0.7369708911051054, 'reg_alpha': 121.20112000779336, 'reg_lambda': 96.9140896378032, 'min_child_samples': 48, 'min_split_gain': 0.8948273504276488}. Best is trial 3 with value: 0.7518849206349207.\n",
            "[I 2025-10-17 15:39:50,296] Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 140, 'max_depth': 10, 'learning_rate': 0.022388950287268727, 'subsample': 0.1783931449676581, 'colsample_bytree': 0.7090454577821076, 'reg_alpha': 40.73375831233172, 'reg_lambda': 48.645793482216305, 'min_child_samples': 21, 'min_split_gain': 0.8287375091519293}. Best is trial 3 with value: 0.7518849206349207.\n",
            "[I 2025-10-17 15:39:50,478] Trial 7 finished with value: 0.7688161375661376 and parameters: {'n_estimators': 103, 'max_depth': 4, 'learning_rate': 0.08597745164215477, 'subsample': 0.15636968998990508, 'colsample_bytree': 0.8604393961508079, 'reg_alpha': 9.411375395603375, 'reg_lambda': 123.3621783814046, 'min_child_samples': 41, 'min_split_gain': 0.1987156815341724}. Best is trial 7 with value: 0.7688161375661376.\n",
            "[I 2025-10-17 15:39:50,621] Trial 8 finished with value: 0.7640542328042328 and parameters: {'n_estimators': 50, 'max_depth': 9, 'learning_rate': 0.10896002813866638, 'subsample': 0.3916028672163949, 'colsample_bytree': 0.8542540693371892, 'reg_alpha': 9.348177001587887, 'reg_lambda': 44.872369495179655, 'min_child_samples': 14, 'min_split_gain': 0.8631034258755935}. Best is trial 7 with value: 0.7688161375661376.\n",
            "[I 2025-10-17 15:39:50,779] Trial 9 finished with value: 0.5 and parameters: {'n_estimators': 144, 'max_depth': 4, 'learning_rate': 0.01889816904004331, 'subsample': 0.2243929286862649, 'colsample_bytree': 0.7650366644053493, 'reg_alpha': 91.2278116744242, 'reg_lambda': 79.73092817226612, 'min_child_samples': 46, 'min_split_gain': 0.4722149251619493}. Best is trial 7 with value: 0.7688161375661376.\n",
            "[I 2025-10-17 15:39:51,029] Trial 10 finished with value: 0.5 and parameters: {'n_estimators': 192, 'max_depth': 6, 'learning_rate': 0.054281669391805114, 'subsample': 0.10718475024592794, 'colsample_bytree': 0.8962141652178608, 'reg_alpha': 86.31185948878624, 'reg_lambda': 121.63241632012613, 'min_child_samples': 35, 'min_split_gain': 0.0397996060770148}. Best is trial 7 with value: 0.7688161375661376.\n",
            "[I 2025-10-17 15:39:51,268] Trial 11 finished with value: 0.7811507936507937 and parameters: {'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.1317704252752519, 'subsample': 0.47323351944263115, 'colsample_bytree': 0.8574488745971842, 'reg_alpha': 2.683211185605666, 'reg_lambda': 37.31763787753863, 'min_child_samples': 13, 'min_split_gain': 0.9980525992325887}. Best is trial 11 with value: 0.7811507936507937.\n",
            "[I 2025-10-17 15:39:51,478] Trial 12 finished with value: 0.5638888888888889 and parameters: {'n_estimators': 51, 'max_depth': 7, 'learning_rate': 0.1400839024529601, 'subsample': 0.4921484768975404, 'colsample_bytree': 0.8311498440452599, 'reg_alpha': 34.38317316298189, 'reg_lambda': 78.49260386246817, 'min_child_samples': 33, 'min_split_gain': 0.3309605669285303}. Best is trial 11 with value: 0.7811507936507937.\n",
            "[I 2025-10-17 15:39:51,730] Trial 13 finished with value: 0.7802910052910053 and parameters: {'n_estimators': 76, 'max_depth': 8, 'learning_rate': 0.06411981054363017, 'subsample': 0.4997449754566207, 'colsample_bytree': 0.8749048825997123, 'reg_alpha': 3.291131901836877, 'reg_lambda': 30.270211129244466, 'min_child_samples': 26, 'min_split_gain': 0.998024633462006}. Best is trial 11 with value: 0.7811507936507937.\n",
            "[I 2025-10-17 15:39:52,002] Trial 14 finished with value: 0.7850198412698413 and parameters: {'n_estimators': 74, 'max_depth': 8, 'learning_rate': 0.04537051061598461, 'subsample': 0.49840679574448554, 'colsample_bytree': 0.8998375993934207, 'reg_alpha': 2.4827800326410725, 'reg_lambda': 34.313634716372164, 'min_child_samples': 12, 'min_split_gain': 0.9550788336373541}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:52,258] Trial 15 finished with value: 0.5 and parameters: {'n_estimators': 73, 'max_depth': 8, 'learning_rate': 0.04194056590002803, 'subsample': 0.4407328365449625, 'colsample_bytree': 0.818300219924282, 'reg_alpha': 67.68763777122705, 'reg_lambda': 31.93421404381624, 'min_child_samples': 10, 'min_split_gain': 0.6512900913402648}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:52,476] Trial 16 finished with value: 0.6892857142857143 and parameters: {'n_estimators': 75, 'max_depth': 6, 'learning_rate': 0.12753549772758185, 'subsample': 0.43442912591076105, 'colsample_bytree': 0.889898579028525, 'reg_alpha': 26.657532329995455, 'reg_lambda': 69.12871310407967, 'min_child_samples': 15, 'min_split_gain': 0.7321918525638057}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:52,770] Trial 17 finished with value: 0.5 and parameters: {'n_estimators': 64, 'max_depth': 8, 'learning_rate': 0.06552085598261642, 'subsample': 0.3781640052202573, 'colsample_bytree': 0.7940365532744825, 'reg_alpha': 54.56886921317782, 'reg_lambda': 18.906406570696888, 'min_child_samples': 17, 'min_split_gain': 0.9986226644565402}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:53,051] Trial 18 finished with value: 0.5 and parameters: {'n_estimators': 86, 'max_depth': 9, 'learning_rate': 0.03860997487068867, 'subsample': 0.4610628594861362, 'colsample_bytree': 0.8437544823736347, 'reg_alpha': 82.03987491924995, 'reg_lambda': 42.841187514881085, 'min_child_samples': 11, 'min_split_gain': 0.7273089243909263}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:53,321] Trial 19 finished with value: 0.5 and parameters: {'n_estimators': 177, 'max_depth': 7, 'learning_rate': 0.1282618071523506, 'subsample': 0.3902577738349137, 'colsample_bytree': 0.8790871049507756, 'reg_alpha': 122.45053845721563, 'reg_lambda': 59.971211856041336, 'min_child_samples': 20, 'min_split_gain': 0.9216308282819146}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:53,536] Trial 20 finished with value: 0.5 and parameters: {'n_estimators': 62, 'max_depth': 5, 'learning_rate': 0.06779666224537007, 'subsample': 0.27319810244193404, 'colsample_bytree': 0.8020180532220813, 'reg_alpha': 104.83952463156888, 'reg_lambda': 17.43236543488178, 'min_child_samples': 30, 'min_split_gain': 0.44639876282017127}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:53,822] Trial 21 finished with value: 0.7824735449735449 and parameters: {'n_estimators': 82, 'max_depth': 8, 'learning_rate': 0.044802148273611835, 'subsample': 0.4960831961151187, 'colsample_bytree': 0.8713688972118849, 'reg_alpha': 3.192656653569079, 'reg_lambda': 32.99731278484707, 'min_child_samples': 25, 'min_split_gain': 0.9961235061901988}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:54,211] Trial 22 finished with value: 0.7844907407407409 and parameters: {'n_estimators': 88, 'max_depth': 9, 'learning_rate': 0.035909477175449206, 'subsample': 0.4770871856119706, 'colsample_bytree': 0.8987376729511162, 'reg_alpha': 2.4101289464294395, 'reg_lambda': 36.52779290491098, 'min_child_samples': 24, 'min_split_gain': 0.9587619265918045}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:54,517] Trial 23 finished with value: 0.703670634920635 and parameters: {'n_estimators': 90, 'max_depth': 9, 'learning_rate': 0.03810309681003332, 'subsample': 0.40884918266744374, 'colsample_bytree': 0.8979747400043582, 'reg_alpha': 17.267523799470638, 'reg_lambda': 51.88251039870773, 'min_child_samples': 25, 'min_split_gain': 0.7597734115548298}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:54,822] Trial 24 finished with value: 0.6892857142857143 and parameters: {'n_estimators': 119, 'max_depth': 10, 'learning_rate': 0.02923459300356444, 'subsample': 0.462663719079335, 'colsample_bytree': 0.875998595835013, 'reg_alpha': 29.73241643850438, 'reg_lambda': 30.51331992923414, 'min_child_samples': 26, 'min_split_gain': 0.919603310407603}. Best is trial 14 with value: 0.7850198412698413.\n",
            "[I 2025-10-17 15:39:55,183] Trial 25 finished with value: 0.788260582010582 and parameters: {'n_estimators': 79, 'max_depth': 9, 'learning_rate': 0.054798927182801965, 'subsample': 0.48558118114172155, 'colsample_bytree': 0.8769283854522034, 'reg_alpha': 0.20654693057726847, 'reg_lambda': 13.06892973869958, 'min_child_samples': 29, 'min_split_gain': 0.6260840291849177}. Best is trial 25 with value: 0.788260582010582.\n",
            "[I 2025-10-17 15:39:55,479] Trial 26 finished with value: 0.7254960317460318 and parameters: {'n_estimators': 101, 'max_depth': 9, 'learning_rate': 0.05455073834599178, 'subsample': 0.4179858301054507, 'colsample_bytree': 0.8857973800123112, 'reg_alpha': 17.06474593104088, 'reg_lambda': 12.013732412418761, 'min_child_samples': 30, 'min_split_gain': 0.5963178535332743}. Best is trial 25 with value: 0.788260582010582.\n",
            "[I 2025-10-17 15:39:55,748] Trial 27 finished with value: 0.5 and parameters: {'n_estimators': 65, 'max_depth': 10, 'learning_rate': 0.053549119530452785, 'subsample': 0.4586425653241406, 'colsample_bytree': 0.8359079401488366, 'reg_alpha': 38.587049876662356, 'reg_lambda': 24.080451514305754, 'min_child_samples': 18, 'min_split_gain': 0.6619718219780059}. Best is trial 25 with value: 0.788260582010582.\n",
            "[I 2025-10-17 15:39:56,068] Trial 28 finished with value: 0.7570105820105821 and parameters: {'n_estimators': 129, 'max_depth': 9, 'learning_rate': 0.010325688904075016, 'subsample': 0.3670482123789033, 'colsample_bytree': 0.863595203610821, 'reg_alpha': 13.450288533973406, 'reg_lambda': 4.100999280521291, 'min_child_samples': 34, 'min_split_gain': 0.3824329530215292}. Best is trial 25 with value: 0.788260582010582.\n",
            "[I 2025-10-17 15:39:56,416] Trial 29 finished with value: 0.7912037037037037 and parameters: {'n_estimators': 110, 'max_depth': 10, 'learning_rate': 0.07409265653208359, 'subsample': 0.35376581331497314, 'colsample_bytree': 0.898273859191043, 'reg_alpha': 0.19489892822749993, 'reg_lambda': 0.9938694645855488, 'min_child_samples': 38, 'min_split_gain': 0.5753595623166196}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:56,681] Trial 30 finished with value: 0.6891203703703704 and parameters: {'n_estimators': 111, 'max_depth': 10, 'learning_rate': 0.07867536873728653, 'subsample': 0.35731846475739426, 'colsample_bytree': 0.8142742465562167, 'reg_alpha': 22.39129810512233, 'reg_lambda': 0.6790764871455792, 'min_child_samples': 38, 'min_split_gain': 0.5598612051343225}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:57,015] Trial 31 finished with value: 0.7845238095238095 and parameters: {'n_estimators': 99, 'max_depth': 10, 'learning_rate': 0.07272240182650724, 'subsample': 0.4742739242460068, 'colsample_bytree': 0.897791874055471, 'reg_alpha': 1.7599891282645566, 'reg_lambda': 12.27919111853383, 'min_child_samples': 29, 'min_split_gain': 0.6877973334033258}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:57,366] Trial 32 finished with value: 0.7886243386243387 and parameters: {'n_estimators': 101, 'max_depth': 10, 'learning_rate': 0.07348193942185823, 'subsample': 0.44204899241454154, 'colsample_bytree': 0.8858500409216865, 'reg_alpha': 0.6242629937892896, 'reg_lambda': 12.335902219673287, 'min_child_samples': 38, 'min_split_gain': 0.6527979696650192}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:57,648] Trial 33 finished with value: 0.7033068783068783 and parameters: {'n_estimators': 108, 'max_depth': 10, 'learning_rate': 0.09070320462625484, 'subsample': 0.4328876232582776, 'colsample_bytree': 0.880195388153635, 'reg_alpha': 18.778893847327037, 'reg_lambda': 10.28993217780025, 'min_child_samples': 43, 'min_split_gain': 0.5275344726707771}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:57,913] Trial 34 finished with value: 0.759292328042328 and parameters: {'n_estimators': 120, 'max_depth': 9, 'learning_rate': 0.05825193621224059, 'subsample': 0.3167207739175855, 'colsample_bytree': 0.845887159610641, 'reg_alpha': 10.520332442057205, 'reg_lambda': 23.597644416359017, 'min_child_samples': 39, 'min_split_gain': 0.6125868283743223}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:58,162] Trial 35 finished with value: 0.6892857142857143 and parameters: {'n_estimators': 94, 'max_depth': 7, 'learning_rate': 0.09967451267111849, 'subsample': 0.4148707854266387, 'colsample_bytree': 0.8678294741312595, 'reg_alpha': 28.016038667061284, 'reg_lambda': 16.375490500668526, 'min_child_samples': 37, 'min_split_gain': 0.44251574724866327}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:58,420] Trial 36 finished with value: 0.7361772486772487 and parameters: {'n_estimators': 163, 'max_depth': 10, 'learning_rate': 0.07246428881291446, 'subsample': 0.4457052001452615, 'colsample_bytree': 0.8860896670042208, 'reg_alpha': 15.812021353605807, 'reg_lambda': 0.6332220348002409, 'min_child_samples': 43, 'min_split_gain': 0.5695779410411511}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:58,656] Trial 37 finished with value: 0.5 and parameters: {'n_estimators': 135, 'max_depth': 8, 'learning_rate': 0.04636880010324612, 'subsample': 0.26808846198254777, 'colsample_bytree': 0.7685732674384602, 'reg_alpha': 49.102817335934596, 'reg_lambda': 6.014429471735166, 'min_child_samples': 50, 'min_split_gain': 0.7908216234214986}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:58,890] Trial 38 finished with value: 0.7737433862433863 and parameters: {'n_estimators': 79, 'max_depth': 9, 'learning_rate': 0.07880951740134179, 'subsample': 0.324796454976644, 'colsample_bytree': 0.8859890350284053, 'reg_alpha': 9.20662206514848, 'reg_lambda': 24.43331015611266, 'min_child_samples': 33, 'min_split_gain': 0.38574429721319203}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:59,194] Trial 39 finished with value: 0.7894841269841268 and parameters: {'n_estimators': 109, 'max_depth': 10, 'learning_rate': 0.02727960283882231, 'subsample': 0.2337653952040344, 'colsample_bytree': 0.8484656272682467, 'reg_alpha': 0.16621306812846937, 'reg_lambda': 9.23291292794965, 'min_child_samples': 36, 'min_split_gain': 0.5025983745604649}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:59,431] Trial 40 finished with value: 0.6891203703703704 and parameters: {'n_estimators': 114, 'max_depth': 3, 'learning_rate': 0.02635291380994111, 'subsample': 0.23485531968409268, 'colsample_bytree': 0.8522268828861442, 'reg_alpha': 22.27383651962026, 'reg_lambda': 7.212135524922375, 'min_child_samples': 40, 'min_split_gain': 0.5105747551928839}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:59,726] Trial 41 finished with value: 0.7882275132275132 and parameters: {'n_estimators': 107, 'max_depth': 10, 'learning_rate': 0.048650967557963706, 'subsample': 0.21185225980544445, 'colsample_bytree': 0.8665911057377311, 'reg_alpha': 0.6942426445540909, 'reg_lambda': 14.923357573381498, 'min_child_samples': 36, 'min_split_gain': 0.6257148271470532}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:39:59,998] Trial 42 finished with value: 0.7690145502645503 and parameters: {'n_estimators': 105, 'max_depth': 10, 'learning_rate': 0.05991676401831031, 'subsample': 0.1994304426258614, 'colsample_bytree': 0.867776476396216, 'reg_alpha': 9.262811087902705, 'reg_lambda': 14.48925729664379, 'min_child_samples': 37, 'min_split_gain': 0.627638177175579}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:00,346] Trial 43 finished with value: 0.7611772486772488 and parameters: {'n_estimators': 126, 'max_depth': 10, 'learning_rate': 0.031922625899502656, 'subsample': 0.24316460377153937, 'colsample_bytree': 0.8597878036566171, 'reg_alpha': 7.6578810129504005, 'reg_lambda': 113.48034693994244, 'min_child_samples': 36, 'min_split_gain': 0.6791718151145716}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:00,659] Trial 44 finished with value: 0.7893518518518519 and parameters: {'n_estimators': 95, 'max_depth': 10, 'learning_rate': 0.0894126292588403, 'subsample': 0.2024272345178432, 'colsample_bytree': 0.8346817528838969, 'reg_alpha': 1.0502206828924636, 'reg_lambda': 20.30867685207982, 'min_child_samples': 32, 'min_split_gain': 0.49832887049269603}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:00,894] Trial 45 finished with value: 0.7480820105820106 and parameters: {'n_estimators': 95, 'max_depth': 10, 'learning_rate': 0.1150106615687278, 'subsample': 0.16336069802522596, 'colsample_bytree': 0.8277721331191229, 'reg_alpha': 13.01767227401581, 'reg_lambda': 21.50977796268044, 'min_child_samples': 33, 'min_split_gain': 0.4848330426053632}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:01,214] Trial 46 finished with value: 0.7794642857142857 and parameters: {'n_estimators': 119, 'max_depth': 9, 'learning_rate': 0.08831878131433771, 'subsample': 0.1307465324548382, 'colsample_bytree': 0.8443120004840863, 'reg_alpha': 6.936546294062533, 'reg_lambda': 8.432959536597966, 'min_child_samples': 28, 'min_split_gain': 0.5562431580962377}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:01,492] Trial 47 finished with value: 0.6892857142857143 and parameters: {'n_estimators': 99, 'max_depth': 9, 'learning_rate': 0.09282106715644638, 'subsample': 0.2919448868466051, 'colsample_bytree': 0.8192388435266688, 'reg_alpha': 32.037177979337535, 'reg_lambda': 1.6662388663640222, 'min_child_samples': 32, 'min_split_gain': 0.4011434341089599}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:01,734] Trial 48 finished with value: 0.5 and parameters: {'n_estimators': 132, 'max_depth': 10, 'learning_rate': 0.10338689613335098, 'subsample': 0.19159234312409013, 'colsample_bytree': 0.8487353862662498, 'reg_alpha': 71.06629647633679, 'reg_lambda': 103.18327737781448, 'min_child_samples': 45, 'min_split_gain': 0.2969824850188918}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:01,956] Trial 49 finished with value: 0.5 and parameters: {'n_estimators': 93, 'max_depth': 9, 'learning_rate': 0.08153386955269303, 'subsample': 0.24991404680653295, 'colsample_bytree': 0.8367884605011304, 'reg_alpha': 112.02166025069332, 'reg_lambda': 26.655490348178816, 'min_child_samples': 41, 'min_split_gain': 0.21401625423883797}. Best is trial 29 with value: 0.7912037037037037.\n",
            "[I 2025-10-17 15:40:01,956] A new study created in memory with name: no-name-fbbbc82f-7375-46ba-a5f1-be4b7787f7e6\n",
            "[W 2025-10-17 15:40:02,005] Trial 0 failed with parameters: {'iterations': 125, 'depth': 6, 'learning_rate': 0.07587945476302646, 'l2_leaf_reg': 60.26718993550662, 'bootstrap_type': 'Bayesian', 'subsample': 0.7116167224336398, 'colsample_bylevel': 0.4464704583099741, 'min_data_in_leaf': 34} because of the following error: ValueError('\\nAll the 5 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n5 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"C:\\\\Users\\\\carlo\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 866, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"C:\\\\Users\\\\carlo\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\catboost\\\\core.py\", line 5245, in fit\\n    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\\n  File \"C:\\\\Users\\\\carlo\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\catboost\\\\core.py\", line 2395, in _fit\\n    train_params = self._prepare_train_params(\\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"C:\\\\Users\\\\carlo\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\catboost\\\\core.py\", line 2321, in _prepare_train_params\\n    _check_train_params(params)\\n  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\\n  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\\n_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:16: Error: bayesian bootstrap doesn\\'t support \\'subsample\\' option\\n').\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_30572\\3897334495.py\", line 97, in objective\n",
            "    cv_scores = cross_val_score(model, self.X_train, self.y_train,\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 684, in cross_val_score\n",
            "    cv_results = cross_validate(\n",
            "                 ^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 431, in cross_validate\n",
            "    _warn_or_raise_about_fit_failures(results, error_score)\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 517, in _warn_or_raise_about_fit_failures\n",
            "    raise ValueError(all_fits_failed_message)\n",
            "ValueError: \n",
            "All the 5 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
            "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 2395, in _fit\n",
            "    train_params = self._prepare_train_params(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 2321, in _prepare_train_params\n",
            "    _check_train_params(params)\n",
            "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
            "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
            "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:16: Error: bayesian bootstrap doesn't support 'subsample' option\n",
            "\n",
            "[W 2025-10-17 15:40:02,009] Trial 0 failed with value None.\n",
            "[I 2025-10-17 15:40:02,013] A new study created in memory with name: no-name-2cb31fcd-90db-45f3-8796-7addd573f687\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LightGBM optimizado en 12.8 segundos\n",
            "   🏆 Mejor CV Score: 0.7912\n",
            "   ⚙️ Mejores parámetros: {'n_estimators': 110, 'max_depth': 10, 'learning_rate': 0.07409265653208359, 'subsample': 0.35376581331497314, 'colsample_bytree': 0.898273859191043, 'reg_alpha': 0.19489892822749993, 'reg_lambda': 0.9938694645855488, 'min_child_samples': 38, 'min_split_gain': 0.5753595623166196}\n",
            "\n",
            "🔥 Optimizando CatBoost...\n",
            "❌ Error optimizando CatBoost: \n",
            "All the 5 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
            "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 2395, in _fit\n",
            "    train_params = self._prepare_train_params(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py\", line 2321, in _prepare_train_params\n",
            "    _check_train_params(params)\n",
            "  File \"_catboost.pyx\", line 6583, in _catboost._check_train_params\n",
            "  File \"_catboost.pyx\", line 6605, in _catboost._check_train_params\n",
            "_catboost.CatBoostError: catboost/private/libs/options/bootstrap_options.cpp:16: Error: bayesian bootstrap doesn't support 'subsample' option\n",
            "\n",
            "\n",
            "🔥 Optimizando RandomForest...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-17 15:40:03,846] Trial 0 finished with value: 0.8146164021164021 and parameters: {'n_estimators': 106, 'max_depth': 10, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_samples': 0.7116167224336398}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:06,770] Trial 1 finished with value: 0.8095899470899471 and parameters: {'n_estimators': 180, 'max_depth': 7, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_samples': 0.7424678221356552}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:08,625] Trial 2 finished with value: 0.8070767195767197 and parameters: {'n_estimators': 77, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'max_samples': 0.8223705789444758}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:10,082] Trial 3 finished with value: 0.8066137566137564 and parameters: {'n_estimators': 71, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'sqrt', 'max_samples': 0.8028468876827223}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:12,331] Trial 4 finished with value: 0.7986772486772487 and parameters: {'n_estimators': 139, 'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_samples': 0.8931264066149118}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:15,121] Trial 5 finished with value: 0.8072089947089947 and parameters: {'n_estimators': 172, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'max_samples': 0.799035382022254}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:16,052] Trial 6 finished with value: 0.8036375661375661 and parameters: {'n_estimators': 55, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_samples': 0.8093420558686559}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:17,349] Trial 7 finished with value: 0.8101190476190476 and parameters: {'n_estimators': 77, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 10, 'max_features': 'sqrt', 'max_samples': 0.8843748470046233}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:18,761] Trial 8 finished with value: 0.806547619047619 and parameters: {'n_estimators': 63, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_samples': 0.8657475018303858}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:20,756] Trial 9 finished with value: 0.8133597883597883 and parameters: {'n_estimators': 103, 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_samples': 0.8973773873201034}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:22,920] Trial 10 finished with value: 0.8055555555555556 and parameters: {'n_estimators': 130, 'max_depth': 8, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': 'log2', 'max_samples': 0.7077450399922366}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:24,717] Trial 11 finished with value: 0.8137566137566138 and parameters: {'n_estimators': 111, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_samples': 0.7475567594199607}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:26,493] Trial 12 finished with value: 0.8133597883597883 and parameters: {'n_estimators': 108, 'max_depth': 8, 'min_samples_split': 17, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_samples': 0.7435707167672675}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:29,483] Trial 13 finished with value: 0.807936507936508 and parameters: {'n_estimators': 147, 'max_depth': 9, 'min_samples_split': 20, 'min_samples_leaf': 8, 'max_features': 'sqrt', 'max_samples': 0.7057366506189365}. Best is trial 0 with value: 0.8146164021164021.\n",
            "[I 2025-10-17 15:40:31,345] Trial 14 finished with value: 0.8156084656084657 and parameters: {'n_estimators': 102, 'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7543072368572136}. Best is trial 14 with value: 0.8156084656084657.\n",
            "[I 2025-10-17 15:40:33,051] Trial 15 finished with value: 0.809457671957672 and parameters: {'n_estimators': 94, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 8, 'max_features': 'log2', 'max_samples': 0.7620074454211203}. Best is trial 14 with value: 0.8156084656084657.\n",
            "[I 2025-10-17 15:40:35,739] Trial 16 finished with value: 0.8196428571428571 and parameters: {'n_estimators': 160, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7753679382964325}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:38,212] Trial 17 finished with value: 0.816468253968254 and parameters: {'n_estimators': 157, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7770097536666538}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:40,806] Trial 18 finished with value: 0.8139550264550264 and parameters: {'n_estimators': 162, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7794609473123135}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:43,820] Trial 19 finished with value: 0.815542328042328 and parameters: {'n_estimators': 196, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.8391390051301513}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:46,663] Trial 20 finished with value: 0.8150793650793651 and parameters: {'n_estimators': 155, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_samples': 0.779408130836683}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:49,875] Trial 21 finished with value: 0.816931216931217 and parameters: {'n_estimators': 125, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7739045227239499}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:52,147] Trial 22 finished with value: 0.8126322751322752 and parameters: {'n_estimators': 130, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7731171102150268}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:55,699] Trial 23 finished with value: 0.8118386243386244 and parameters: {'n_estimators': 187, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.7909524065346867}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:40:58,680] Trial 24 finished with value: 0.8157407407407409 and parameters: {'n_estimators': 164, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'log2', 'max_samples': 0.7269649395161287}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:01,078] Trial 25 finished with value: 0.811441798941799 and parameters: {'n_estimators': 144, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_samples': 0.8280089418372203}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:03,478] Trial 26 finished with value: 0.8194444444444444 and parameters: {'n_estimators': 120, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7671879256550396}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:05,632] Trial 27 finished with value: 0.8171296296296295 and parameters: {'n_estimators': 120, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7274806134583092}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:07,725] Trial 28 finished with value: 0.818584656084656 and parameters: {'n_estimators': 117, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7256651482861207}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:09,283] Trial 29 finished with value: 0.8162037037037037 and parameters: {'n_estimators': 93, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_samples': 0.7251825519322062}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:11,565] Trial 30 finished with value: 0.8140211640211641 and parameters: {'n_estimators': 118, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.762612867529147}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:13,714] Trial 31 finished with value: 0.8143518518518519 and parameters: {'n_estimators': 119, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7289439110262834}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:15,948] Trial 32 finished with value: 0.8098544973544973 and parameters: {'n_estimators': 131, 'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_samples': 0.7351197321480644}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:17,320] Trial 33 finished with value: 0.8099206349206349 and parameters: {'n_estimators': 90, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.7193822350414272}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:19,856] Trial 34 finished with value: 0.8142195767195768 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7170847506546885}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:21,738] Trial 35 finished with value: 0.8150132275132276 and parameters: {'n_estimators': 116, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_samples': 0.7011040551906399}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:24,612] Trial 36 finished with value: 0.8111111111111111 and parameters: {'n_estimators': 175, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.7577492381125084}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:26,915] Trial 37 finished with value: 0.8093915343915346 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_samples': 0.7360248081343999}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:28,275] Trial 38 finished with value: 0.8119708994708995 and parameters: {'n_estimators': 83, 'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_samples': 0.8122541331127795}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:30,321] Trial 39 finished with value: 0.8140211640211641 and parameters: {'n_estimators': 134, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_samples': 0.7477414909421436}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:32,671] Trial 40 finished with value: 0.8189814814814815 and parameters: {'n_estimators': 122, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.796716095944518}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:34,585] Trial 41 finished with value: 0.8186507936507936 and parameters: {'n_estimators': 123, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7925082071390059}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:37,250] Trial 42 finished with value: 0.8147486772486774 and parameters: {'n_estimators': 139, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.7899664277375841}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:39,054] Trial 43 finished with value: 0.8192460317460316 and parameters: {'n_estimators': 111, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7964177746459714}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:40,767] Trial 44 finished with value: 0.8196428571428571 and parameters: {'n_estimators': 106, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.7985251157495628}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:42,334] Trial 45 finished with value: 0.8122354497354497 and parameters: {'n_estimators': 97, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'sqrt', 'max_samples': 0.8082917172710189}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:44,054] Trial 46 finished with value: 0.8009920634920633 and parameters: {'n_estimators': 111, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_samples': 0.823330944102179}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:45,801] Trial 47 finished with value: 0.8131613756613756 and parameters: {'n_estimators': 107, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.8019780334212069}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:47,234] Trial 48 finished with value: 0.8140211640211641 and parameters: {'n_estimators': 85, 'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_samples': 0.8435836054665443}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:48,834] Trial 49 finished with value: 0.8128306878306878 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 6, 'max_features': 'log2', 'max_samples': 0.7678220130015694}. Best is trial 16 with value: 0.8196428571428571.\n",
            "[I 2025-10-17 15:41:48,838] A new study created in memory with name: no-name-bcb64d72-26a1-41d0-aa1c-c1495721d431\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RandomForest optimizado en 106.8 segundos\n",
            "❌ Error optimizando RandomForest: 'randomforest'\n",
            "\n",
            "🔥 Optimizando LogisticRegression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-10-17 15:41:50,436] Trial 0 finished with value: 0.5261243386243386 and parameters: {'C': 0.13292918943162169, 'penalty': 'l1', 'l1_ratio': 0.22481491235394924}. Best is trial 0 with value: 0.5261243386243386.\n",
            "[I 2025-10-17 15:41:51,739] Trial 1 finished with value: 0.5263227513227513 and parameters: {'C': 0.029375384576328288, 'penalty': 'l2', 'l1_ratio': 0.6664580622368363}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:41:53,290] Trial 2 finished with value: 0.5188492063492063 and parameters: {'C': 0.011527987128232402, 'penalty': 'l1', 'l1_ratio': 0.24545997376568052}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:41:54,603] Trial 3 finished with value: 0.5263227513227513 and parameters: {'C': 0.03549878832196503, 'penalty': 'l2', 'l1_ratio': 0.3329833121584336}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:41:56,256] Trial 4 finished with value: 0.5263227513227513 and parameters: {'C': 0.6847920095574779, 'penalty': 'elasticnet', 'l1_ratio': 0.46485598737362877}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:41:57,926] Trial 5 finished with value: 0.5263227513227513 and parameters: {'C': 2.267398652378039, 'penalty': 'elasticnet', 'l1_ratio': 0.13716033017599819}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:41:59,592] Trial 6 finished with value: 0.5262566137566138 and parameters: {'C': 0.6647135865318028, 'penalty': 'elasticnet', 'l1_ratio': 0.8725056264596475}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:01,509] Trial 7 finished with value: 0.5263227513227513 and parameters: {'C': 2.6619018884890564, 'penalty': 'elasticnet', 'l1_ratio': 0.45212199499168104}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:03,121] Trial 8 finished with value: 0.526058201058201 and parameters: {'C': 0.023233503515390115, 'penalty': 'elasticnet', 'l1_ratio': 0.3070239852800135}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:05,057] Trial 9 finished with value: 0.5263227513227513 and parameters: {'C': 0.9717775305059632, 'penalty': 'elasticnet', 'l1_ratio': 0.24788356442042164}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:06,424] Trial 10 finished with value: 0.5263227513227513 and parameters: {'C': 0.11795939393640552, 'penalty': 'l2', 'l1_ratio': 0.7396121299403545}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:08,407] Trial 11 finished with value: 0.5263227513227513 and parameters: {'C': 0.048643296031797754, 'penalty': 'l2', 'l1_ratio': 0.641509177726393}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:11,802] Trial 12 finished with value: 0.5263227513227513 and parameters: {'C': 0.05838891112221528, 'penalty': 'l2', 'l1_ratio': 0.6015069159252542}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:13,410] Trial 13 finished with value: 0.5262566137566138 and parameters: {'C': 0.010535758678621911, 'penalty': 'l2', 'l1_ratio': 0.38487297866799497}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:14,730] Trial 14 finished with value: 0.5263227513227513 and parameters: {'C': 0.1792743083935294, 'penalty': 'l2', 'l1_ratio': 0.596462156415521}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:16,085] Trial 15 finished with value: 0.5263227513227513 and parameters: {'C': 0.036151333283231245, 'penalty': 'l2', 'l1_ratio': 0.8477649146326477}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:17,598] Trial 16 finished with value: 0.5262566137566138 and parameters: {'C': 0.02042244444660552, 'penalty': 'l2', 'l1_ratio': 0.7228552117727759}. Best is trial 1 with value: 0.5263227513227513.\n",
            "[I 2025-10-17 15:42:19,961] Trial 17 finished with value: 0.5263227513227514 and parameters: {'C': 0.3289097827655384, 'penalty': 'l1', 'l1_ratio': 0.36983024111903656}. Best is trial 17 with value: 0.5263227513227514.\n",
            "[I 2025-10-17 15:42:21,694] Trial 18 finished with value: 0.5263227513227513 and parameters: {'C': 5.698424265594236, 'penalty': 'l1', 'l1_ratio': 0.5136010781213356}. Best is trial 17 with value: 0.5263227513227514.\n",
            "[I 2025-10-17 15:42:23,276] Trial 19 finished with value: 0.5263888888888889 and parameters: {'C': 0.3124672248985641, 'penalty': 'l1', 'l1_ratio': 0.727434095713347}. Best is trial 19 with value: 0.5263888888888889.\n",
            "[I 2025-10-17 15:42:24,759] Trial 20 finished with value: 0.5262566137566138 and parameters: {'C': 0.39330693639946823, 'penalty': 'l1', 'l1_ratio': 0.5359127730493034}. Best is trial 19 with value: 0.5263888888888889.\n",
            "[I 2025-10-17 15:42:26,259] Trial 21 finished with value: 0.5263888888888889 and parameters: {'C': 0.28055263269872655, 'penalty': 'l1', 'l1_ratio': 0.7478924398897913}. Best is trial 19 with value: 0.5263888888888889.\n",
            "[I 2025-10-17 15:42:27,750] Trial 22 finished with value: 0.5264550264550264 and parameters: {'C': 0.2857518769502799, 'penalty': 'l1', 'l1_ratio': 0.7900905793405165}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:29,260] Trial 23 finished with value: 0.5263227513227513 and parameters: {'C': 0.21242129802055154, 'penalty': 'l1', 'l1_ratio': 0.8069546223208686}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:30,794] Trial 24 finished with value: 0.526058201058201 and parameters: {'C': 0.07572045504875334, 'penalty': 'l1', 'l1_ratio': 0.7571567793589762}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:32,355] Trial 25 finished with value: 0.5263227513227513 and parameters: {'C': 1.3128294870183799, 'penalty': 'l1', 'l1_ratio': 0.7742200222566037}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:33,961] Trial 26 finished with value: 0.5261904761904762 and parameters: {'C': 0.4476556292630487, 'penalty': 'l1', 'l1_ratio': 0.6825007459857451}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:35,479] Trial 27 finished with value: 0.5263888888888889 and parameters: {'C': 0.2468877195053605, 'penalty': 'l1', 'l1_ratio': 0.81677013563455}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:36,975] Trial 28 finished with value: 0.5259920634920635 and parameters: {'C': 0.09112084128938681, 'penalty': 'l1', 'l1_ratio': 0.8870161645817215}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:38,496] Trial 29 finished with value: 0.5262566137566137 and parameters: {'C': 0.13832801925474145, 'penalty': 'l1', 'l1_ratio': 0.7045364040410494}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:39,979] Trial 30 finished with value: 0.5262566137566138 and parameters: {'C': 0.6061372748886079, 'penalty': 'l1', 'l1_ratio': 0.5961191262276462}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:41,459] Trial 31 finished with value: 0.5262566137566138 and parameters: {'C': 0.23581794422148672, 'penalty': 'l1', 'l1_ratio': 0.8256131232422185}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:43,019] Trial 32 finished with value: 0.5264550264550264 and parameters: {'C': 0.2855234436435021, 'penalty': 'l1', 'l1_ratio': 0.7924815894498289}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:44,564] Trial 33 finished with value: 0.5263227513227513 and parameters: {'C': 1.1617238130717205, 'penalty': 'l1', 'l1_ratio': 0.897443067519333}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:46,179] Trial 34 finished with value: 0.5261904761904762 and parameters: {'C': 0.14497654743603186, 'penalty': 'l1', 'l1_ratio': 0.7752210521091049}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:47,829] Trial 35 finished with value: 0.5261904761904762 and parameters: {'C': 0.45373737774953327, 'penalty': 'l1', 'l1_ratio': 0.635062157993675}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:49,573] Trial 36 finished with value: 0.5263227513227514 and parameters: {'C': 0.3270668520659719, 'penalty': 'l1', 'l1_ratio': 0.7980328843877673}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:51,053] Trial 37 finished with value: 0.5262566137566138 and parameters: {'C': 1.9796536718765174, 'penalty': 'l1', 'l1_ratio': 0.6835509081365174}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:52,530] Trial 38 finished with value: 0.5261904761904762 and parameters: {'C': 0.6639711228389134, 'penalty': 'l1', 'l1_ratio': 0.8520219446407394}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:54,082] Trial 39 finished with value: 0.5263888888888889 and parameters: {'C': 0.26868637059853395, 'penalty': 'l1', 'l1_ratio': 0.7313829443798119}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:55,515] Trial 40 finished with value: 0.5260582010582011 and parameters: {'C': 0.11167200675136221, 'penalty': 'l1', 'l1_ratio': 0.648322031353402}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:56,967] Trial 41 finished with value: 0.5261904761904762 and parameters: {'C': 0.16625690046643957, 'penalty': 'l1', 'l1_ratio': 0.8228071215126476}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:58,438] Trial 42 finished with value: 0.5262566137566138 and parameters: {'C': 0.2332252554125754, 'penalty': 'l1', 'l1_ratio': 0.7664261923539729}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:42:59,910] Trial 43 finished with value: 0.5263227513227513 and parameters: {'C': 0.8919456131875128, 'penalty': 'elasticnet', 'l1_ratio': 0.8000558868703834}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:01,399] Trial 44 finished with value: 0.5261243386243387 and parameters: {'C': 0.5259987383095315, 'penalty': 'l1', 'l1_ratio': 0.8606508154190307}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:02,885] Trial 45 finished with value: 0.5263227513227514 and parameters: {'C': 0.325809551100651, 'penalty': 'l1', 'l1_ratio': 0.7089586567887852}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:04,701] Trial 46 finished with value: 0.5263227513227513 and parameters: {'C': 0.8654688364534009, 'penalty': 'elasticnet', 'l1_ratio': 0.5505479973599966}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:06,386] Trial 47 finished with value: 0.5262566137566138 and parameters: {'C': 0.19035737913167386, 'penalty': 'l1', 'l1_ratio': 0.7452958224801045}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:07,900] Trial 48 finished with value: 0.5259920634920635 and parameters: {'C': 0.08707399575367727, 'penalty': 'l1', 'l1_ratio': 0.15651449147364632}. Best is trial 22 with value: 0.5264550264550264.\n",
            "[I 2025-10-17 15:43:09,436] Trial 49 finished with value: 0.5263227513227513 and parameters: {'C': 1.6278777842464567, 'penalty': 'elasticnet', 'l1_ratio': 0.4706001850195148}. Best is trial 22 with value: 0.5264550264550264.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LogisticRegression optimizado en 80.6 segundos\n",
            "❌ Error optimizando LogisticRegression: 'logisticregression'\n",
            "\n",
            "✅ Optimización completada para todos los modelos\n"
          ]
        }
      ],
      "source": [
        "# Optimizar todos los modelos\n",
        "print(\"🔥 OPTIMIZANDO TODOS LOS MODELOS...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Lista de modelos a optimizar\n",
        "models_to_optimize = [\n",
        "    ('XGBoost', optimizer.optimize_xgboost),\n",
        "    ('LightGBM', optimizer.optimize_lightgbm),\n",
        "    ('CatBoost', optimizer.optimize_catboost),\n",
        "    ('RandomForest', optimizer.optimize_random_forest),\n",
        "    ('LogisticRegression', optimizer.optimize_logistic_regression)\n",
        "]\n",
        "\n",
        "# Optimizar cada modelo\n",
        "for model_name, optimize_func in models_to_optimize:\n",
        "    print(f\"\\n🔥 Optimizando {model_name}...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        best_params = optimize_func()\n",
        "        end_time = time.time()\n",
        "        \n",
        "        print(f\"✅ {model_name} optimizado en {end_time - start_time:.1f} segundos\")\n",
        "        print(f\"   🏆 Mejor CV Score: {optimizer.best_scores[model_name.lower().replace(' ', '_')]:.4f}\")\n",
        "        print(f\"   ⚙️ Mejores parámetros: {best_params}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error optimizando {model_name}: {e}\")\n",
        "\n",
        "print(f\"\\n✅ Optimización completada para todos los modelos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 RESUMEN DE OPTIMIZACIÓN\n",
            "==================================================\n",
            "XGBOOST: 0.7715\n",
            "LIGHTGBM: 0.7912\n",
            "RANDOM_FOREST: 0.8196\n",
            "LOGISTIC_REGRESSION: 0.5265\n",
            "\n",
            "🏆 MEJOR MODELO: RANDOM_FOREST\n",
            "📊 Mejor CV Score: 0.8196\n"
          ]
        }
      ],
      "source": [
        "# Resumen de optimización\n",
        "print(\"📊 RESUMEN DE OPTIMIZACIÓN\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for model_name, score in optimizer.best_scores.items():\n",
        "    print(f\"{model_name.upper()}: {score:.4f}\")\n",
        "\n",
        "# Encontrar el mejor modelo\n",
        "best_model_name = max(optimizer.best_scores, key=optimizer.best_scores.get)\n",
        "best_score = optimizer.best_scores[best_model_name]\n",
        "\n",
        "print(f\"\\n🏆 MEJOR MODELO: {best_model_name.upper()}\")\n",
        "print(f\"📊 Mejor CV Score: {best_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏋️ Entrenando modelos optimizados...\n",
            "   Entrenando XGBoost...\n",
            "   Entrenando LightGBM...\n",
            "   Entrenando RandomForest...\n",
            "✅ Todos los modelos entrenados\n"
          ]
        }
      ],
      "source": [
        "# Entrenar modelos optimizados y evaluar\n",
        "print(\"🏋️ Entrenando modelos optimizados...\")\n",
        "\n",
        "# Crear modelos con mejores parámetros\n",
        "models = {\n",
        "    'XGBoost': xgb.XGBClassifier(**optimizer.best_params['xgboost'], random_state=RANDOM_STATE),\n",
        "    'LightGBM': lgb.LGBMClassifier(**optimizer.best_params['lightgbm'], random_state=RANDOM_STATE, verbose=-1),\n",
        "   # 'CatBoost': cb.CatBoostClassifier(**optimizer.best_params['catboost'], random_seed=RANDOM_STATE, verbose=False),\n",
        "    'RandomForest': RandomForestClassifier(**optimizer.best_params['random_forest'], random_state=RANDOM_STATE),\n",
        "   # 'LogisticRegression': LogisticRegression(**optimizer.best_params['logistic_regression'], random_state=RANDOM_STATE)\n",
        "}\n",
        "\n",
        "# Entrenar todos los modelos\n",
        "trained_models = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"   Entrenando {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    trained_models[name] = model\n",
        "\n",
        "print(\"✅ Todos los modelos entrenados\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 EVALUANDO MODELOS EN TRAIN/TEST/HOLDOUT...\n",
            "============================================================\n",
            "\n",
            "🔍 Evaluando XGBoost...\n",
            "   📈 Train  - AUC: 0.8091, PSI: N/A, Green: 30.0%\n",
            "   🧪 Test   - AUC: 0.7139, PSI: 0.0557, Green: 30.0%\n",
            "   🔒 Holdout - AUC: 0.7779, PSI: 0.0083, Green: 10.0%\n",
            "\n",
            "🔍 Evaluando LightGBM...\n",
            "   📈 Train  - AUC: 0.9353, PSI: N/A, Green: 10.0%\n",
            "   🧪 Test   - AUC: 0.7455, PSI: inf, Green: 40.0%\n",
            "   🔒 Holdout - AUC: 0.7913, PSI: inf, Green: 40.0%\n",
            "\n",
            "🔍 Evaluando RandomForest...\n",
            "   📈 Train  - AUC: 0.9525, PSI: N/A, Green: 0.0%\n",
            "   🧪 Test   - AUC: 0.7469, PSI: 0.2022, Green: 40.0%\n",
            "   🔒 Holdout - AUC: 0.7963, PSI: 0.0751, Green: 40.0%\n"
          ]
        }
      ],
      "source": [
        "# Evaluar modelos en Train, Test y Holdout\n",
        "print(\"📊 EVALUANDO MODELOS EN TRAIN/TEST/HOLDOUT...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in trained_models.items():\n",
        "    print(f\"\\n🔍 Evaluando {model_name}...\")\n",
        "    \n",
        "    # Predicciones en cada conjunto\n",
        "    train_proba = model.predict_proba(X_train)[:, 1]\n",
        "    test_proba = model.predict_proba(X_test)[:, 1]\n",
        "    holdout_proba = model.predict_proba(X_holdout)[:, 1]\n",
        "    \n",
        "    # Evaluar en cada conjunto\n",
        "    train_metrics = CreditScoringMetrics.evaluate_model(y_train, train_proba)\n",
        "    test_metrics = CreditScoringMetrics.evaluate_model(y_test, test_proba, train_proba)\n",
        "    holdout_metrics = CreditScoringMetrics.evaluate_model(y_holdout, holdout_proba, train_proba)\n",
        "    \n",
        "    results[model_name] = {\n",
        "        'train': train_metrics,\n",
        "        'test': test_metrics,\n",
        "        'holdout': holdout_metrics\n",
        "    }\n",
        "    \n",
        "    # Mostrar resultados\n",
        "    print(f\"   📈 Train  - AUC: {train_metrics['auc_roc']:.4f}, PSI: N/A, Green: {train_metrics['traffic_light']['green_percentage']:.1f}%\")\n",
        "    print(f\"   🧪 Test   - AUC: {test_metrics['auc_roc']:.4f}, PSI: {test_metrics['psi']:.4f}, Green: {test_metrics['traffic_light']['green_percentage']:.1f}%\")\n",
        "    print(f\"   🔒 Holdout - AUC: {holdout_metrics['auc_roc']:.4f}, PSI: {holdout_metrics['psi']:.4f}, Green: {holdout_metrics['traffic_light']['green_percentage']:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "source code string cannot contain null bytes (<string>)",
          "output_type": "error",
          "traceback": [
            "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
            "  File \u001b[92m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3546\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexec(open('simple_exec.py').read())\u001b[39m\n",
            "  \u001b[36mFile \u001b[39m\u001b[32m<string>\u001b[39m\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m source code string cannot contain null bytes\n"
          ]
        }
      ],
      "source": [
        "exec(open('simple_exec.py').read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "source code string cannot contain null bytes (<string>)",
          "output_type": "error",
          "traceback": [
            "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
            "  File \u001b[92m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3546\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexec(open('complete_traffic_light.py').read())\u001b[39m\n",
            "  \u001b[36mFile \u001b[39m\u001b[32m<string>\u001b[39m\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m source code string cannot contain null bytes\n"
          ]
        }
      ],
      "source": [
        "exec(open('complete_traffic_light.py').read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistical Traffic Light functions loaded successfully\n",
            "Evaluating models with statistical Traffic Light...\n",
            "Evaluating XGBoost with statistical Traffic Light...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'scipy.stats' has no attribute 'binom_test'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Evaluate models with statistical Traffic Light\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mEvaluating models with statistical Traffic Light...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results_statistical = \u001b[43mevaluate_models_statistical\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrained_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_holdout\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mStatistical evaluation completed\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:93\u001b[39m, in \u001b[36mevaluate_models_statistical\u001b[39m\u001b[34m(models, X_train, y_train, X_test, y_test, X_holdout, y_holdout)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:32\u001b[39m, in \u001b[36mcalculate_traffic_light_statistical\u001b[39m\u001b[34m(y_true, y_pred_proba, n_groups, alpha)\u001b[39m\n",
            "\u001b[31mAttributeError\u001b[39m: module 'scipy.stats' has no attribute 'binom_test'"
          ]
        }
      ],
      "source": [
        "exec(open('traffic_light_fix.py').read())\n",
        "\n",
        "# Evaluate models with statistical Traffic Light\n",
        "print('Evaluating models with statistical Traffic Light...')\n",
        "results_statistical = evaluate_models_statistical(\n",
        "    trained_models, X_train, y_train, X_test, y_test, X_holdout, y_holdout\n",
        ")\n",
        "\n",
        "print('Statistical evaluation completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "source code string cannot contain null bytes (<string>)",
          "output_type": "error",
          "traceback": [
            "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
            "  File \u001b[92m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3546\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mexec(open('simple_exec.py').read())\u001b[39m\n",
            "  \u001b[36mFile \u001b[39m\u001b[32m<string>\u001b[39m\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m source code string cannot contain null bytes\n"
          ]
        }
      ],
      "source": [
        "exec(open('simple_exec.py').read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistical Traffic Light functions loaded successfully\n",
            "Evaluating models with statistical Traffic Light...\n",
            "Evaluating XGBoost with statistical Traffic Light...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'scipy.stats' has no attribute 'binom_test'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m exec(\u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mtraffic_light_fix.py\u001b[39m\u001b[33m'\u001b[39m).read())\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mEvaluating models with statistical Traffic Light...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results_statistical = \u001b[43mevaluate_models_statistical\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrained_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_holdout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_holdout\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mStatistical evaluation completed\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:93\u001b[39m, in \u001b[36mevaluate_models_statistical\u001b[39m\u001b[34m(models, X_train, y_train, X_test, y_test, X_holdout, y_holdout)\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<string>:32\u001b[39m, in \u001b[36mcalculate_traffic_light_statistical\u001b[39m\u001b[34m(y_true, y_pred_proba, n_groups, alpha)\u001b[39m\n",
            "\u001b[31mAttributeError\u001b[39m: module 'scipy.stats' has no attribute 'binom_test'"
          ]
        }
      ],
      "source": [
        "# Traffic Light Statistical Analysis\n",
        "exec(open('traffic_light_fix.py').read())\n",
        "\n",
        "print('Evaluating models with statistical Traffic Light...')\n",
        "results_statistical = evaluate_models_statistical(\n",
        "    trained_models, X_train, y_train, X_test, y_test, X_holdout, y_holdout\n",
        ")\n",
        "\n",
        "print('Statistical evaluation completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Statistical Traffic Light functions loaded successfully\n",
            "Evaluating models with statistical Traffic Light...\n",
            "Evaluating XGBoost with statistical Traffic Light...\n",
            "   Train  - Green: 50.0%, Yellow: 0.0%, Red: 50.0%\n",
            "   Test   - Green: 90.0%, Yellow: 10.0%, Red: 0.0%\n",
            "   Holdout - Green: 90.0%, Yellow: 0.0%, Red: 10.0%\n",
            "Evaluating LightGBM with statistical Traffic Light...\n",
            "   Train  - Green: 60.0%, Yellow: 10.0%, Red: 30.0%\n",
            "   Test   - Green: 100.0%, Yellow: 0.0%, Red: 0.0%\n",
            "   Holdout - Green: 100.0%, Yellow: 0.0%, Red: 0.0%\n",
            "Evaluating RandomForest with statistical Traffic Light...\n",
            "   Train  - Green: 50.0%, Yellow: 0.0%, Red: 50.0%\n",
            "   Test   - Green: 100.0%, Yellow: 0.0%, Red: 0.0%\n",
            "   Holdout - Green: 100.0%, Yellow: 0.0%, Red: 0.0%\n",
            "Statistical evaluation completed\n"
          ]
        }
      ],
      "source": [
        "# Traffic Light Statistical Analysis\n",
        "exec(open('traffic_light_fix.py').read())\n",
        "\n",
        "print('Evaluating models with statistical Traffic Light...')\n",
        "results_statistical = evaluate_models_statistical(\n",
        "    trained_models, X_train, y_train, X_test, y_test, X_holdout, y_holdout\n",
        ")\n",
        "\n",
        "print('Statistical evaluation completed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "ename": "UnicodeDecodeError",
          "evalue": "'charmap' codec can't decode byte 0x81 in position 747: character maps to <undefined>",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m exec(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexecute_basel_traffic_light.py\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py:23\u001b[39m, in \u001b[36mIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs.charmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m.errors,decoding_table)[\u001b[32m0\u001b[39m]\n",
            "\u001b[31mUnicodeDecodeError\u001b[39m: 'charmap' codec can't decode byte 0x81 in position 747: character maps to <undefined>"
          ]
        }
      ],
      "source": [
        "exec(open('execute_basel_traffic_light.py').read())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
