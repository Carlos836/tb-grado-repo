{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🏦 Experimentación Controlada con German Credit Dataset\n",
        "\n",
        "## 📋 Objetivos del Notebook\n",
        "\n",
        "Este notebook implementa una **experimentación controlada** enfocada en:\n",
        "\n",
        "1. **German Credit Dataset** específicamente\n",
        "2. **Optimización con Optuna** para cada modelo\n",
        "3. **Métricas detalladas**: AUC, PSI, Traffic Light\n",
        "4. **Comparación entre**: Train, Test, Holdout\n",
        "5. **Análisis por algoritmo** individual\n",
        "\n",
        "## 🎯 Métricas de Evaluación\n",
        "\n",
        "### Métricas Principales:\n",
        "- **AUC-ROC**: Capacidad discriminante del modelo\n",
        "- **PSI (Population Stability Index)**: Estabilidad de distribución entre muestras\n",
        "- **Traffic Light**: Precisión en grupos de riesgo para rating bancario\n",
        "\n",
        "### Traffic Light Methodology:\n",
        "- **Verde**: Modelo predice correctamente la probabilidad de default\n",
        "- **Amarillo**: Subestimación o sobrestimación leve\n",
        "- **Rojo**: Subestimación o sobrestimación significativa\n",
        "\n",
        "## 🚀 Modelos a Optimizar\n",
        "\n",
        "1. **XGBoost** - Gradient Boosting optimizado\n",
        "2. **CatBoost** - Gradient Boosting con manejo de categóricas\n",
        "3. **LightGBM** - Gradient Boosting eficiente\n",
        "4. **RandomForest** - Ensemble de árboles\n",
        "5. **LogisticRegression** - Modelo lineal baseline\n",
        "\n",
        "## 📊 Estructura de Evaluación\n",
        "\n",
        "Para cada modelo optimizado:\n",
        "- **Train Performance**: Métricas en datos de entrenamiento\n",
        "- **Test Performance**: Métricas en datos de prueba\n",
        "- **Holdout Performance**: Métricas en datos de validación\n",
        "- **Comparación**: Análisis de estabilidad y generalización\n",
        "\n",
        "---\n",
        "\n",
        "**¡Empecemos con la experimentación controlada!** 🎯\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Librerías importadas correctamente\n"
          ]
        }
      ],
      "source": [
        "# Importación de librerías\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import MedianPruner\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, auc\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Modelos específicos\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "\n",
        "# UCI Repository\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Configuración\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"✅ Librerías importadas correctamente\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📁 Directorio del proyecto: c:\\Users\\carlo\\OneDrive\\Documentos\\repos\\tb-grado-repo\\notebooks\\..\n",
            "📊 Número de trials Optuna: 50\n",
            "🔄 Folds de CV: 5\n"
          ]
        }
      ],
      "source": [
        "# Configuración del proyecto\n",
        "PROJECT_ROOT = Path('..')\n",
        "DATA_DIR = PROJECT_ROOT / 'data'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
        "CONFIGS_DIR = PROJECT_ROOT / 'configs'\n",
        "\n",
        "# Crear directorios si no existen\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Configuración de experimento\n",
        "RANDOM_STATE = 42\n",
        "N_TRIALS = 50  # Número de trials para Optuna\n",
        "CV_FOLDS = 5   # Folds para cross-validation\n",
        "\n",
        "print(f\"📁 Directorio del proyecto: {PROJECT_ROOT.absolute()}\")\n",
        "print(f\"📊 Número de trials Optuna: {N_TRIALS}\")\n",
        "print(f\"🔄 Folds de CV: {CV_FOLDS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📥 Cargando German Credit Dataset...\n",
            "✅ Dataset cargado exitosamente\n",
            "   📊 Forma de X: (1000, 20)\n",
            "   📊 Forma de y: (1000, 1)\n",
            "   🎯 Variable objetivo: class\n",
            "\n",
            "📋 Información del dataset:\n",
            "   Features: ['Attribute1', 'Attribute2', 'Attribute3', 'Attribute4', 'Attribute5', 'Attribute6', 'Attribute7', 'Attribute8', 'Attribute9', 'Attribute10', 'Attribute11', 'Attribute12', 'Attribute13', 'Attribute14', 'Attribute15', 'Attribute16', 'Attribute17', 'Attribute18', 'Attribute19', 'Attribute20']\n",
            "   Tipos de datos: {dtype('O'): 13, dtype('int64'): 7}\n",
            "   Valores únicos en target: {1: 700, 2: 300}\n"
          ]
        }
      ],
      "source": [
        "# Cargar German Credit Dataset\n",
        "print(\"📥 Cargando German Credit Dataset...\")\n",
        "\n",
        "try:\n",
        "    # Cargar dataset desde UCI Repository\n",
        "    german_credit = fetch_ucirepo(id=144)\n",
        "    \n",
        "    # Obtener datos\n",
        "    X = german_credit.data.features\n",
        "    y = german_credit.data.targets\n",
        "    \n",
        "    print(f\"✅ Dataset cargado exitosamente\")\n",
        "    print(f\"   📊 Forma de X: {X.shape}\")\n",
        "    print(f\"   📊 Forma de y: {y.shape}\")\n",
        "    print(f\"   🎯 Variable objetivo: {y.columns[0]}\")\n",
        "    \n",
        "    # Mostrar información del dataset\n",
        "    print(f\"\\n📋 Información del dataset:\")\n",
        "    print(f\"   Features: {list(X.columns)}\")\n",
        "    print(f\"   Tipos de datos: {X.dtypes.value_counts().to_dict()}\")\n",
        "    print(f\"   Valores únicos en target: {y.iloc[:, 0].value_counts().to_dict()}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error cargando dataset: {e}\")\n",
        "    print(\"🔄 Intentando cargar desde archivo local...\")\n",
        "    \n",
        "    # Intentar cargar desde archivo local si existe\n",
        "    local_file = DATA_DIR / 'german_credit.csv'\n",
        "    if local_file.exists():\n",
        "        df = pd.read_csv(local_file)\n",
        "        X = df.drop('target', axis=1)\n",
        "        y = df[['target']]\n",
        "        print(f\"✅ Dataset cargado desde archivo local\")\n",
        "    else:\n",
        "        print(f\"❌ No se pudo cargar el dataset\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔧 Preprocesando datos...\n",
            "📊 Distribución del target:\n",
            "   Good Credit (0): 700 (70.0%)\n",
            "   Bad Credit (1): 300 (30.0%)\n",
            "\n",
            "📋 Tipos de variables:\n",
            "   Categóricas: 13 - ['Attribute1', 'Attribute3', 'Attribute4', 'Attribute6', 'Attribute7', 'Attribute9', 'Attribute10', 'Attribute12', 'Attribute14', 'Attribute15', 'Attribute17', 'Attribute19', 'Attribute20']\n",
            "   Numéricas: 7 - ['Attribute2', 'Attribute5', 'Attribute8', 'Attribute11', 'Attribute13', 'Attribute16', 'Attribute18']\n",
            "✅ Variables categóricas codificadas\n",
            "📊 Forma final: (1000, 20)\n"
          ]
        }
      ],
      "source": [
        "# Preprocesamiento de datos\n",
        "print(\"🔧 Preprocesando datos...\")\n",
        "\n",
        "# Convertir target a binario (1 = bad credit, 0 = good credit)\n",
        "y_binary = (y.iloc[:, 0] == 2).astype(int)  # 2 = bad credit en German dataset\n",
        "\n",
        "print(f\"📊 Distribución del target:\")\n",
        "print(f\"   Good Credit (0): {(y_binary == 0).sum()} ({(y_binary == 0).mean()*100:.1f}%)\")\n",
        "print(f\"   Bad Credit (1): {(y_binary == 1).sum()} ({(y_binary == 1).mean()*100:.1f}%)\")\n",
        "\n",
        "# Identificar variables categóricas y numéricas\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"\\n📋 Tipos de variables:\")\n",
        "print(f\"   Categóricas: {len(categorical_cols)} - {categorical_cols}\")\n",
        "print(f\"   Numéricas: {len(numerical_cols)} - {numerical_cols}\")\n",
        "\n",
        "# Codificar variables categóricas\n",
        "X_encoded = X.copy()\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X_encoded[col] = le.fit_transform(X[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(f\"✅ Variables categóricas codificadas\")\n",
        "print(f\"📊 Forma final: {X_encoded.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Dividiendo datos en Train/Test/Holdout...\n",
            "✅ División de datos completada:\n",
            "   🏋️ Train: 600 muestras (60%)\n",
            "   🧪 Test: 200 muestras (20%)\n",
            "   🔒 Holdout: 200 muestras (20%)\n",
            "\n",
            "📊 Distribución del target por conjunto:\n",
            "   Train: 0.300 (180/600)\n",
            "   Test: 0.300 (60/200)\n",
            "   Holdout: 0.300 (60/200)\n"
          ]
        }
      ],
      "source": [
        "# División de datos: Train (60%) / Test (20%) / Holdout (20%)\n",
        "print(\"📊 Dividiendo datos en Train/Test/Holdout...\")\n",
        "\n",
        "# Primera división: Train+Test (80%) / Holdout (20%)\n",
        "X_temp, X_holdout, y_temp, y_holdout = train_test_split(\n",
        "    X_encoded, y_binary, \n",
        "    test_size=0.2, \n",
        "    random_state=RANDOM_STATE, \n",
        "    stratify=y_binary\n",
        ")\n",
        "\n",
        "# Segunda división: Train (60%) / Test (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_temp, y_temp, \n",
        "    test_size=0.25,  # 0.25 de 0.8 = 0.2 del total\n",
        "    random_state=RANDOM_STATE, \n",
        "    stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"✅ División de datos completada:\")\n",
        "print(f\"   🏋️ Train: {X_train.shape[0]} muestras (60%)\")\n",
        "print(f\"   🧪 Test: {X_test.shape[0]} muestras (20%)\")\n",
        "print(f\"   🔒 Holdout: {X_holdout.shape[0]} muestras (20%)\")\n",
        "\n",
        "# Verificar distribución del target en cada conjunto\n",
        "print(f\"\\n📊 Distribución del target por conjunto:\")\n",
        "for name, y_set in [('Train', y_train), ('Test', y_test), ('Holdout', y_holdout)]:\n",
        "    bad_rate = y_set.mean()\n",
        "    print(f\"   {name}: {bad_rate:.3f} ({y_set.sum()}/{len(y_set)})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Clase de métricas creada\n"
          ]
        }
      ],
      "source": [
        "# Clase para métricas de evaluación\n",
        "class CreditScoringMetrics:\n",
        "    \"\"\"\n",
        "    Clase para calcular métricas específicas de scoring crediticio\n",
        "    \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_auc_roc(y_true, y_pred_proba):\n",
        "        \"\"\"\n",
        "        Calcula AUC-ROC\n",
        "        \"\"\"\n",
        "        return roc_auc_score(y_true, y_pred_proba)\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_psi(expected, actual, bins=10):\n",
        "        \"\"\"\n",
        "        Calcula Population Stability Index (PSI)\n",
        "        \n",
        "        Args:\n",
        "            expected: Distribución esperada (train)\n",
        "            actual: Distribución actual (test/holdout)\n",
        "            bins: Número de bins para discretizar\n",
        "        \n",
        "        Returns:\n",
        "            PSI value\n",
        "        \"\"\"\n",
        "        # Crear bins basados en la distribución esperada\n",
        "        breakpoints = np.linspace(0, 1, bins + 1)\n",
        "        breakpoints[0] = -np.inf\n",
        "        breakpoints[-1] = np.inf\n",
        "        \n",
        "        # Discretizar ambas distribuciones\n",
        "        expected_binned = pd.cut(expected, bins=breakpoints, labels=False)\n",
        "        actual_binned = pd.cut(actual, bins=breakpoints, labels=False)\n",
        "        \n",
        "        # Calcular frecuencias\n",
        "        expected_freq = pd.Series(expected_binned).value_counts(normalize=True, sort=False)\n",
        "        actual_freq = pd.Series(actual_binned).value_counts(normalize=True, sort=False)\n",
        "        \n",
        "        # Asegurar que ambos tengan los mismos bins\n",
        "        for i in range(bins):\n",
        "            if i not in expected_freq.index:\n",
        "                expected_freq[i] = 0\n",
        "            if i not in actual_freq.index:\n",
        "                actual_freq[i] = 0\n",
        "        \n",
        "        expected_freq = expected_freq.sort_index()\n",
        "        actual_freq = actual_freq.sort_index()\n",
        "        \n",
        "        # Calcular PSI\n",
        "        psi = 0\n",
        "        for i in range(bins):\n",
        "            if expected_freq.iloc[i] > 0:\n",
        "                psi += (actual_freq.iloc[i] - expected_freq.iloc[i]) * \\\n",
        "                       np.log(actual_freq.iloc[i] / expected_freq.iloc[i])\n",
        "        \n",
        "        return psi\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_traffic_light(y_true, y_pred_proba, n_groups=10):\n",
        "        \"\"\"\n",
        "        Calcula Traffic Light para grupos de riesgo\n",
        "        \n",
        "        Args:\n",
        "            y_true: Valores reales\n",
        "            y_pred_proba: Probabilidades predichas\n",
        "            n_groups: Número de grupos de riesgo\n",
        "        \n",
        "        Returns:\n",
        "            Dict con estadísticas de Traffic Light\n",
        "        \"\"\"\n",
        "        # Crear grupos de riesgo basados en probabilidades predichas\n",
        "        df = pd.DataFrame({\n",
        "            'actual': y_true,\n",
        "            'predicted': y_pred_proba\n",
        "        })\n",
        "        \n",
        "        # Ordenar por probabilidad predicha (descendente)\n",
        "        df = df.sort_values('predicted', ascending=False).reset_index(drop=True)\n",
        "        \n",
        "        # Crear grupos de riesgo\n",
        "        group_size = len(df) // n_groups\n",
        "        df['group'] = 0\n",
        "        \n",
        "        for i in range(n_groups):\n",
        "            start_idx = i * group_size\n",
        "            if i == n_groups - 1:  # Último grupo incluye el resto\n",
        "                end_idx = len(df)\n",
        "            else:\n",
        "                end_idx = (i + 1) * group_size\n",
        "            \n",
        "            df.loc[start_idx:end_idx-1, 'group'] = i + 1\n",
        "        \n",
        "        # Calcular métricas por grupo\n",
        "        group_stats = []\n",
        "        for group in range(1, n_groups + 1):\n",
        "            group_data = df[df['group'] == group]\n",
        "            if len(group_data) > 0:\n",
        "                actual_rate = group_data['actual'].mean()\n",
        "                predicted_rate = group_data['predicted'].mean()\n",
        "                \n",
        "                # Determinar color del semáforo\n",
        "                diff = abs(actual_rate - predicted_rate)\n",
        "                if diff <= 0.05:  # 5% de tolerancia\n",
        "                    color = 'green'\n",
        "                elif diff <= 0.10:  # 10% de tolerancia\n",
        "                    color = 'yellow'\n",
        "                else:\n",
        "                    color = 'red'\n",
        "                \n",
        "                group_stats.append({\n",
        "                    'group': group,\n",
        "                    'actual_rate': actual_rate,\n",
        "                    'predicted_rate': predicted_rate,\n",
        "                    'difference': diff,\n",
        "                    'color': color,\n",
        "                    'size': len(group_data)\n",
        "                })\n",
        "        \n",
        "        # Calcular estadísticas generales\n",
        "        colors = [stat['color'] for stat in group_stats]\n",
        "        green_pct = colors.count('green') / len(colors) * 100\n",
        "        yellow_pct = colors.count('yellow') / len(colors) * 100\n",
        "        red_pct = colors.count('red') / len(colors) * 100\n",
        "        \n",
        "        return {\n",
        "            'group_stats': group_stats,\n",
        "            'green_percentage': green_pct,\n",
        "            'yellow_percentage': yellow_pct,\n",
        "            'red_percentage': red_pct,\n",
        "            'total_groups': len(group_stats)\n",
        "        }\n",
        "    \n",
        "    @classmethod\n",
        "    def evaluate_model(cls, y_true, y_pred_proba, y_train_proba=None):\n",
        "        \"\"\"\n",
        "        Evalúa un modelo con todas las métricas\n",
        "        \n",
        "        Args:\n",
        "            y_true: Valores reales\n",
        "            y_pred_proba: Probabilidades predichas\n",
        "            y_train_proba: Probabilidades en train (para PSI)\n",
        "        \n",
        "        Returns:\n",
        "            Dict con todas las métricas\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "        \n",
        "        # AUC-ROC\n",
        "        results['auc_roc'] = cls.calculate_auc_roc(y_true, y_pred_proba)\n",
        "        \n",
        "        # PSI (si se proporcionan datos de train)\n",
        "        if y_train_proba is not None:\n",
        "            results['psi'] = cls.calculate_psi(y_train_proba, y_pred_proba)\n",
        "        \n",
        "        # Traffic Light\n",
        "        traffic_light = cls.calculate_traffic_light(y_true, y_pred_proba)\n",
        "        results['traffic_light'] = traffic_light\n",
        "        \n",
        "        return results\n",
        "\n",
        "print(\"✅ Clase de métricas creada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Clase de optimización creada\n"
          ]
        }
      ],
      "source": [
        "# Clase para optimización con Optuna\n",
        "class OptunaOptimizer:\n",
        "    \"\"\"\n",
        "    Clase para optimizar modelos con Optuna\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, X_train, y_train, cv_folds=5, n_trials=50):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.cv_folds = cv_folds\n",
        "        self.n_trials = n_trials\n",
        "        self.best_params = {}\n",
        "        self.best_scores = {}\n",
        "        \n",
        "    def optimize_xgboost(self):\n",
        "        \"\"\"\n",
        "        Optimiza XGBoost con Optuna\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
        "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = xgb.XGBClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['xgboost'] = study.best_params\n",
        "        self.best_scores['xgboost'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_lightgbm(self):\n",
        "        \"\"\"\n",
        "        Optimiza LightGBM con Optuna\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
        "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
        "                'random_state': RANDOM_STATE,\n",
        "                'verbose': -1\n",
        "            }\n",
        "            \n",
        "            model = lgb.LGBMClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['lightgbm'] = study.best_params\n",
        "        self.best_scores['lightgbm'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_catboost(self):\n",
        "        \"\"\"\n",
        "        Optimiza CatBoost con Optuna\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'iterations': trial.suggest_int('iterations', 100, 1000),\n",
        "                'depth': trial.suggest_int('depth', 3, 10),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
        "                'random_seed': RANDOM_STATE,\n",
        "                'verbose': False\n",
        "            }\n",
        "            \n",
        "            model = cb.CatBoostClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['catboost'] = study.best_params\n",
        "        self.best_scores['catboost'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_random_forest(self):\n",
        "        \"\"\"\n",
        "        Optimiza Random Forest con Optuna\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
        "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = RandomForestClassifier(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['random_forest'] = study.best_params\n",
        "        self.best_scores['random_forest'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "    \n",
        "    def optimize_logistic_regression(self):\n",
        "        \"\"\"\n",
        "        Optimiza Logistic Regression con Optuna\n",
        "        \"\"\"\n",
        "        def objective(trial):\n",
        "            params = {\n",
        "                'C': trial.suggest_float('C', 0.01, 100, log=True),\n",
        "                'penalty': trial.suggest_categorical('penalty', ['l1', 'l2']),\n",
        "                'solver': 'liblinear',  # Compatible con l1 y l2\n",
        "                'random_state': RANDOM_STATE\n",
        "            }\n",
        "            \n",
        "            model = LogisticRegression(**params)\n",
        "            cv_scores = cross_val_score(model, self.X_train, self.y_train, \n",
        "                                      cv=self.cv_folds, scoring='roc_auc')\n",
        "            return cv_scores.mean()\n",
        "        \n",
        "        study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=RANDOM_STATE))\n",
        "        study.optimize(objective, n_trials=self.n_trials)\n",
        "        \n",
        "        self.best_params['logistic_regression'] = study.best_params\n",
        "        self.best_scores['logistic_regression'] = study.best_value\n",
        "        \n",
        "        return study.best_params\n",
        "\n",
        "print(\"✅ Clase de optimización creada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Optimizador inicializado\n",
            "   📊 Datos de entrenamiento: (600, 20)\n",
            "   🔄 Folds de CV: 5\n",
            "   🎯 Trials por modelo: 50\n"
          ]
        }
      ],
      "source": [
        "# Inicializar optimizador\n",
        "optimizer = OptunaOptimizer(X_train, y_train, cv_folds=CV_FOLDS, n_trials=N_TRIALS)\n",
        "\n",
        "print(f\"🚀 Optimizador inicializado\")\n",
        "print(f\"   📊 Datos de entrenamiento: {X_train.shape}\")\n",
        "print(f\"   🔄 Folds de CV: {CV_FOLDS}\")\n",
        "print(f\"   🎯 Trials por modelo: {N_TRIALS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimizar todos los modelos\n",
        "print(\"🔥 OPTIMIZANDO TODOS LOS MODELOS...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Lista de modelos a optimizar\n",
        "models_to_optimize = [\n",
        "    ('XGBoost', optimizer.optimize_xgboost),\n",
        "    ('LightGBM', optimizer.optimize_lightgbm),\n",
        "    ('CatBoost', optimizer.optimize_catboost),\n",
        "    ('RandomForest', optimizer.optimize_random_forest),\n",
        "    ('LogisticRegression', optimizer.optimize_logistic_regression)\n",
        "]\n",
        "\n",
        "# Optimizar cada modelo\n",
        "for model_name, optimize_func in models_to_optimize:\n",
        "    print(f\"\\n🔥 Optimizando {model_name}...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        best_params = optimize_func()\n",
        "        end_time = time.time()\n",
        "        \n",
        "        print(f\"✅ {model_name} optimizado en {end_time - start_time:.1f} segundos\")\n",
        "        print(f\"   🏆 Mejor CV Score: {optimizer.best_scores[model_name.lower().replace(' ', '_')]:.4f}\")\n",
        "        print(f\"   ⚙️ Mejores parámetros: {best_params}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error optimizando {model_name}: {e}\")\n",
        "\n",
        "print(f\"\\n✅ Optimización completada para todos los modelos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen de optimización\n",
        "print(\"📊 RESUMEN DE OPTIMIZACIÓN\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for model_name, score in optimizer.best_scores.items():\n",
        "    print(f\"{model_name.upper()}: {score:.4f}\")\n",
        "\n",
        "# Encontrar el mejor modelo\n",
        "best_model_name = max(optimizer.best_scores, key=optimizer.best_scores.get)\n",
        "best_score = optimizer.best_scores[best_model_name]\n",
        "\n",
        "print(f\"\\n🏆 MEJOR MODELO: {best_model_name.upper()}\")\n",
        "print(f\"📊 Mejor CV Score: {best_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar modelos optimizados y evaluar\n",
        "print(\"🏋️ Entrenando modelos optimizados...\")\n",
        "\n",
        "# Crear modelos con mejores parámetros\n",
        "models = {\n",
        "    'XGBoost': xgb.XGBClassifier(**optimizer.best_params['xgboost'], random_state=RANDOM_STATE),\n",
        "    'LightGBM': lgb.LGBMClassifier(**optimizer.best_params['lightgbm'], random_state=RANDOM_STATE, verbose=-1),\n",
        "    'CatBoost': cb.CatBoostClassifier(**optimizer.best_params['catboost'], random_seed=RANDOM_STATE, verbose=False),\n",
        "    'RandomForest': RandomForestClassifier(**optimizer.best_params['random_forest'], random_state=RANDOM_STATE),\n",
        "    'LogisticRegression': LogisticRegression(**optimizer.best_params['logistic_regression'], random_state=RANDOM_STATE)\n",
        "}\n",
        "\n",
        "# Entrenar todos los modelos\n",
        "trained_models = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"   Entrenando {name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    trained_models[name] = model\n",
        "\n",
        "print(\"✅ Todos los modelos entrenados\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluar modelos en Train, Test y Holdout\n",
        "print(\"📊 EVALUANDO MODELOS EN TRAIN/TEST/HOLDOUT...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for model_name, model in trained_models.items():\n",
        "    print(f\"\\n🔍 Evaluando {model_name}...\")\n",
        "    \n",
        "    # Predicciones en cada conjunto\n",
        "    train_proba = model.predict_proba(X_train)[:, 1]\n",
        "    test_proba = model.predict_proba(X_test)[:, 1]\n",
        "    holdout_proba = model.predict_proba(X_holdout)[:, 1]\n",
        "    \n",
        "    # Evaluar en cada conjunto\n",
        "    train_metrics = CreditScoringMetrics.evaluate_model(y_train, train_proba)\n",
        "    test_metrics = CreditScoringMetrics.evaluate_model(y_test, test_proba, train_proba)\n",
        "    holdout_metrics = CreditScoringMetrics.evaluate_model(y_holdout, holdout_proba, train_proba)\n",
        "    \n",
        "    results[model_name] = {\n",
        "        'train': train_metrics,\n",
        "        'test': test_metrics,\n",
        "        'holdout': holdout_metrics\n",
        "    }\n",
        "    \n",
        "    # Mostrar resultados\n",
        "    print(f\"   📈 Train  - AUC: {train_metrics['auc_roc']:.4f}, PSI: N/A, Green: {train_metrics['traffic_light']['green_percentage']:.1f}%\")\n",
        "    print(f\"   🧪 Test   - AUC: {test_metrics['auc_roc']:.4f}, PSI: {test_metrics['psi']:.4f}, Green: {test_metrics['traffic_light']['green_percentage']:.1f}%\")\n",
        "    print(f\"   🔒 Holdout - AUC: {holdout_metrics['auc_roc']:.4f}, PSI: {holdout_metrics['psi']:.4f}, Green: {holdout_metrics['traffic_light']['green_percentage']:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear tabla comparativa\n",
        "print(\"📋 TABLA COMPARATIVA DE RESULTADOS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Crear DataFrame con resultados\n",
        "comparison_data = []\n",
        "\n",
        "for model_name, model_results in results.items():\n",
        "    for dataset in ['train', 'test', 'holdout']:\n",
        "        metrics = model_results[dataset]\n",
        "        \n",
        "        row = {\n",
        "            'Modelo': model_name,\n",
        "            'Dataset': dataset.capitalize(),\n",
        "            'AUC-ROC': metrics['auc_roc'],\n",
        "            'PSI': metrics.get('psi', np.nan),\n",
        "            'Traffic_Light_Green_%': metrics['traffic_light']['green_percentage'],\n",
        "            'Traffic_Light_Yellow_%': metrics['traffic_light']['yellow_percentage'],\n",
        "            'Traffic_Light_Red_%': metrics['traffic_light']['red_percentage']\n",
        "        }\n",
        "        comparison_data.append(row)\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "# Mostrar tabla\n",
        "display(comparison_df.round(4))\n",
        "\n",
        "# Guardar resultados\n",
        "comparison_df.to_csv(RESULTS_DIR / 'model_comparison_results.csv', index=False)\n",
        "print(f\"\\n💾 Resultados guardados en: {RESULTS_DIR / 'model_comparison_results.csv'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizaciones\n",
        "print(\"📊 CREANDO VISUALIZACIONES...\")\n",
        "\n",
        "# Configurar subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Comparación de Modelos por Dataset', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. AUC-ROC por dataset\n",
        "ax1 = axes[0, 0]\n",
        "pivot_auc = comparison_df.pivot(index='Modelo', columns='Dataset', values='AUC-ROC')\n",
        "pivot_auc.plot(kind='bar', ax=ax1, width=0.8)\n",
        "ax1.set_title('AUC-ROC por Dataset')\n",
        "ax1.set_ylabel('AUC-ROC')\n",
        "ax1.legend(title='Dataset')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.axhline(y=0.65, color='red', linestyle='--', alpha=0.7, label='Umbral (0.65)')\n",
        "\n",
        "# 2. PSI por dataset (solo test y holdout)\n",
        "ax2 = axes[0, 1]\n",
        "psi_data = comparison_df[comparison_df['Dataset'].isin(['Test', 'Holdout'])]\n",
        "pivot_psi = psi_data.pivot(index='Modelo', columns='Dataset', values='PSI')\n",
        "pivot_psi.plot(kind='bar', ax=ax2, width=0.8)\n",
        "ax2.set_title('PSI por Dataset')\n",
        "ax2.set_ylabel('PSI')\n",
        "ax2.legend(title='Dataset')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.axhline(y=0.10, color='red', linestyle='--', alpha=0.7, label='Umbral (0.10)')\n",
        "\n",
        "# 3. Traffic Light Green % por dataset\n",
        "ax3 = axes[1, 0]\n",
        "pivot_green = comparison_df.pivot(index='Modelo', columns='Dataset', values='Traffic_Light_Green_%')\n",
        "pivot_green.plot(kind='bar', ax=ax3, width=0.8)\n",
        "ax3.set_title('Traffic Light Green % por Dataset')\n",
        "ax3.set_ylabel('Green %')\n",
        "ax3.legend(title='Dataset')\n",
        "ax3.tick_params(axis='x', rotation=45)\n",
        "ax3.axhline(y=80, color='red', linestyle='--', alpha=0.7, label='Umbral (80%)')\n",
        "\n",
        "# 4. Comparación de estabilidad (AUC Test vs Holdout)\n",
        "ax4 = axes[1, 1]\n",
        "test_auc = comparison_df[comparison_df['Dataset'] == 'Test']['AUC-ROC'].values\n",
        "holdout_auc = comparison_df[comparison_df['Dataset'] == 'Holdout']['AUC-ROC'].values\n",
        "models_list = comparison_df[comparison_df['Dataset'] == 'Test']['Modelo'].values\n",
        "\n",
        "x = np.arange(len(models_list))\n",
        "width = 0.35\n",
        "\n",
        "ax4.bar(x - width/2, test_auc, width, label='Test', alpha=0.8)\n",
        "ax4.bar(x + width/2, holdout_auc, width, label='Holdout', alpha=0.8)\n",
        "\n",
        "ax4.set_title('Estabilidad: Test vs Holdout AUC')\n",
        "ax4.set_ylabel('AUC-ROC')\n",
        "ax4.set_xticks(x)\n",
        "ax4.set_xticklabels(models_list, rotation=45)\n",
        "ax4.legend()\n",
        "ax4.axhline(y=0.65, color='red', linestyle='--', alpha=0.7, label='Umbral (0.65)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ Visualizaciones completadas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análisis detallado del mejor modelo\n",
        "print(\"🏆 ANÁLISIS DEL MEJOR MODELO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Encontrar el mejor modelo basado en AUC en holdout\n",
        "holdout_results = comparison_df[comparison_df['Dataset'] == 'Holdout']\n",
        "best_model_name = holdout_results.loc[holdout_results['AUC-ROC'].idxmax(), 'Modelo']\n",
        "best_model_auc = holdout_results['AUC-ROC'].max()\n",
        "\n",
        "print(f\"🥇 Mejor modelo: {best_model_name}\")\n",
        "print(f\"📊 Mejor AUC en Holdout: {best_model_auc:.4f}\")\n",
        "\n",
        "# Mostrar métricas detalladas del mejor modelo\n",
        "best_model_results = results[best_model_name]\n",
        "\n",
        "print(f\"\\n📈 MÉTRICAS DETALLADAS DE {best_model_name.upper()}:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for dataset, metrics in best_model_results.items():\n",
        "    print(f\"\\n{dataset.upper()}:\")\n",
        "    print(f\"   AUC-ROC: {metrics['auc_roc']:.4f}\")\n",
        "    if 'psi' in metrics:\n",
        "        print(f\"   PSI: {metrics['psi']:.4f}\")\n",
        "    print(f\"   Traffic Light:\")\n",
        "    print(f\"      Verde: {metrics['traffic_light']['green_percentage']:.1f}%\")\n",
        "    print(f\"      Amarillo: {metrics['traffic_light']['yellow_percentage']:.1f}%\")\n",
        "    print(f\"      Rojo: {metrics['traffic_light']['red_percentage']:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen ejecutivo\n",
        "print(\"📋 RESUMEN EJECUTIVO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Estadísticas generales\n",
        "print(f\"\\n📊 ESTADÍSTICAS GENERALES:\")\n",
        "print(f\"   Total de modelos evaluados: {len(trained_models)}\")\n",
        "print(f\"   Mejor AUC en Holdout: {best_model_auc:.4f}\")\n",
        "print(f\"   Modelos que superan umbral AUC (0.65): {len(holdout_results[holdout_results['AUC-ROC'] >= 0.65])}\")\n",
        "\n",
        "# Análisis de estabilidad\n",
        "print(f\"\\n🔄 ANÁLISIS DE ESTABILIDAD:\")\n",
        "for model_name in trained_models.keys():\n",
        "    test_auc = comparison_df[(comparison_df['Modelo'] == model_name) & (comparison_df['Dataset'] == 'Test')]['AUC-ROC'].iloc[0]\n",
        "    holdout_auc = comparison_df[(comparison_df['Modelo'] == model_name) & (comparison_df['Dataset'] == 'Holdout')]['AUC-ROC'].iloc[0]\n",
        "    stability = abs(test_auc - holdout_auc)\n",
        "    \n",
        "    print(f\"   {model_name}: {stability:.4f} ({'✅ Estable' if stability < 0.05 else '⚠️ Inestable'})\")\n",
        "\n",
        "# Recomendaciones\n",
        "print(f\"\\n💡 RECOMENDACIONES:\")\n",
        "print(f\"   1. Modelo recomendado: {best_model_name}\")\n",
        "print(f\"   2. AUC en Holdout: {best_model_auc:.4f} ({'✅ Cumple' if best_model_auc >= 0.65 else '❌ No cumple'} umbral)\")\n",
        "\n",
        "if best_model_auc < 0.65:\n",
        "    print(f\"   3. ⚠️ Ningún modelo alcanza el umbral mínimo de AUC (0.65)\")\n",
        "    print(f\"      Considerar: Feature engineering, más datos, o modelos más complejos\")\n",
        "\n",
        "print(f\"\\n✅ Análisis completo finalizado\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
