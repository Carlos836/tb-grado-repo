{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# An√°lisis de Scoring Crediticio - Proyecto de Grado\n",
        "## Framework de RL para Optimizaci√≥n de Datos Sint√©ticos y Modelos ML\n",
        "\n",
        "**T√≠tulo:** Sintetizando datos tabulares: Un Framework de Aprendizaje por Refuerzo para el Benchmark de Datos Sint√©ticos y su Impacto en problemas de Clasificaci√≥n\n",
        "\n",
        "**Autor:** Carlos Andres Cortez Ballen\n",
        "\n",
        "### Objetivos del Proyecto:\n",
        "- Implementar y comparar generadores de datos sint√©ticos (GANs vs m√©todos tradicionales)\n",
        "- Construir framework de RL para selecci√≥n √≥ptima de generadores y modelos ML\n",
        "- Evaluar rendimiento en scoring crediticio para segmento D (baja transaccionalidad)\n",
        "- Desarrollar m√©tricas de calidad para datos sint√©ticos\n",
        "- Realizar benchmarking cruzado entre estrategias\n",
        "\n",
        "### Objetivos de este Notebook:\n",
        "- Explorar datos del segmento D (5K muestras vs 200K del segmento A)\n",
        "- Analizar caracter√≠sticas del scoring crediticio de corto plazo\n",
        "- Identificar patrones y distribuciones en datos financieros\n",
        "- Preparar datos para generaci√≥n sint√©tica\n",
        "- Establecer baseline de performance\n",
        "\n",
        "### Contenido:\n",
        "1. Configuraci√≥n del entorno y librer√≠as\n",
        "2. Carga de datos (UCI + datos internos)\n",
        "3. An√°lisis exploratorio del segmento D\n",
        "4. Comparaci√≥n con segmento A (referencia)\n",
        "5. An√°lisis de variables de scoring crediticio\n",
        "6. Preparaci√≥n para generaci√≥n de datos sint√©ticos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Librer√≠as importadas correctamente\n",
            "üìä Pandas version: 2.2.3\n",
            "üî¢ NumPy version: 1.26.4\n",
            "üìà Matplotlib version: 3.10.1\n",
            "üé® Seaborn version: 0.13.2\n",
            "‚öôÔ∏è Configuraci√≥n cargada: 8 secciones\n"
          ]
        }
      ],
      "source": [
        "# Importaci√≥n de librer√≠as y configuraci√≥n\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import logging\n",
        "\n",
        "# Configuraci√≥n de visualizaciones\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuraci√≥n de pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Configuraci√≥n de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Cargar configuraci√≥n\n",
        "with open('../configs/config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
        "print(f\"üìä Pandas version: {pd.__version__}\")\n",
        "print(f\"üî¢ NumPy version: {np.__version__}\")\n",
        "print(f\"üìà Matplotlib version: {plt.matplotlib.__version__}\")\n",
        "print(f\"üé® Seaborn version: {sns.__version__}\")\n",
        "print(f\"‚öôÔ∏è Configuraci√≥n cargada: {len(config)} secciones\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:25:21,585 - INFO - DataSplitter inicializado:\n",
            "2025-10-17 13:25:21,585 - INFO -   Train: 0.6, Validation: 0.2, Test: 0.2\n",
            "2025-10-17 13:25:21,585 - INFO -   Synthetic validation: 0.15\n",
            "2025-10-17 13:25:21,585 - INFO -   CV folds: 5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ M√≥dulos del proyecto importados correctamente\n",
            "üìÅ DataLoader inicializado\n",
            "üîß DataPreprocessor inicializado\n",
            "‚úÇÔ∏è DataSplitter inicializado\n",
            "‚úÖ DataValidator inicializado\n"
          ]
        }
      ],
      "source": [
        "# Importar m√≥dulos del proyecto\n",
        "from src.data.data_loader import DataLoader\n",
        "from src.data.data_preprocessor import DataPreprocessor\n",
        "from src.data.data_splitter import DataSplitter\n",
        "from src.data.data_validator import DataValidator\n",
        "\n",
        "# Inicializar componentes\n",
        "data_loader = DataLoader(config)\n",
        "data_preprocessor = DataPreprocessor(config)\n",
        "data_splitter = DataSplitter(config)\n",
        "data_validator = DataValidator(config)\n",
        "\n",
        "print(\"‚úÖ M√≥dulos del proyecto importados correctamente\")\n",
        "print(\"üìÅ DataLoader inicializado\")\n",
        "print(\"üîß DataPreprocessor inicializado\")\n",
        "print(\"‚úÇÔ∏è DataSplitter inicializado\")\n",
        "print(\"‚úÖ DataValidator inicializado\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Carga de Datos de Cr√©dito\n",
        "\n",
        "Vamos a cargar datasets de cr√©dito desde UCI Repository para simular el an√°lisis del segmento D. Estos datasets nos permitir√°n:\n",
        "\n",
        "1. **German Credit Data**: Dataset cl√°sico de scoring crediticio\n",
        "2. **Australian Credit Approval**: Datos de aprobaci√≥n de cr√©dito\n",
        "3. **Credit Card Default**: Datos de default de tarjetas de cr√©dito\n",
        "\n",
        "Estos datasets nos servir√°n como proxy para entender las caracter√≠sticas del segmento D.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:25:40,397 - INFO - Cargando dataset UCI ID: 144\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Cargando datasets de cr√©dito desde UCI Repository...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:25:42,265 - INFO - Dataset cargado: 1000 filas, 20 features\n",
            "2025-10-17 13:25:42,265 - INFO - Target shape: (1000, 1)\n",
            "2025-10-17 13:25:42,287 - INFO - Cargando dataset UCI ID: 45\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ German Credit Data cargado: (1000, 21)\n",
            "   Features: 20\n",
            "   Target distribution: {1: 700, 2: 300}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:25:43,867 - INFO - Dataset cargado: 303 filas, 13 features\n",
            "2025-10-17 13:25:43,871 - INFO - Target shape: (303, 1)\n",
            "2025-10-17 13:25:43,873 - INFO - Cargando dataset UCI ID: 300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Australian Credit Data cargado: (303, 14)\n",
            "   Features: 13\n",
            "   Target distribution: {0: 164, 1: 55, 2: 36, 3: 35, 4: 13}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:25:45,799 - INFO - Dataset cargado: 943 filas, 42 features\n",
            "2025-10-17 13:25:45,799 - INFO - Target shape: (943, 1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Credit Card Default Data cargado: (943, 43)\n",
            "   Features: 42\n",
            "   Target distribution: {0: 478, 1: 465}\n",
            "\n",
            "üìä Resumen de datasets cargados:\n",
            "   German Credit: (1000, 21)\n",
            "   Australian Credit: (303, 14)\n",
            "   Credit Card Default: (943, 43)\n"
          ]
        }
      ],
      "source": [
        "# Cargar datasets de cr√©dito desde UCI\n",
        "print(\"üîÑ Cargando datasets de cr√©dito desde UCI Repository...\")\n",
        "\n",
        "# Cargar German Credit Data (ID: 144)\n",
        "try:\n",
        "    german_features, german_targets = data_loader.load_uci_dataset(144, \"german_credit\")\n",
        "    german_data = pd.concat([german_features, german_targets], axis=1)\n",
        "    print(f\"‚úÖ German Credit Data cargado: {german_data.shape}\")\n",
        "    print(f\"   Features: {german_features.shape[1]}\")\n",
        "    print(f\"   Target distribution: {german_targets.iloc[:, 0].value_counts().to_dict()}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error cargando German Credit: {e}\")\n",
        "    german_data = None\n",
        "\n",
        "# Cargar Australian Credit Approval (ID: 45)\n",
        "try:\n",
        "    australian_features, australian_targets = data_loader.load_uci_dataset(45, \"australian_credit\")\n",
        "    australian_data = pd.concat([australian_features, australian_targets], axis=1)\n",
        "    print(f\"‚úÖ Australian Credit Data cargado: {australian_data.shape}\")\n",
        "    print(f\"   Features: {australian_features.shape[1]}\")\n",
        "    print(f\"   Target distribution: {australian_targets.iloc[:, 0].value_counts().to_dict()}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error cargando Australian Credit: {e}\")\n",
        "    australian_data = None\n",
        "\n",
        "# Cargar Credit Card Default (ID: 300)\n",
        "try:\n",
        "    default_features, default_targets = data_loader.load_uci_dataset(300, \"credit_card_default\")\n",
        "    default_data = pd.concat([default_features, default_targets], axis=1)\n",
        "    print(f\"‚úÖ Credit Card Default Data cargado: {default_data.shape}\")\n",
        "    print(f\"   Features: {default_features.shape[1]}\")\n",
        "    print(f\"   Target distribution: {default_targets.iloc[:, 0].value_counts().to_dict()}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error cargando Credit Card Default: {e}\")\n",
        "    default_data = None\n",
        "\n",
        "print(\"\\nüìä Resumen de datasets cargados:\")\n",
        "datasets_info = {\n",
        "    'German Credit': german_data.shape if german_data is not None else \"No disponible\",\n",
        "    'Australian Credit': australian_data.shape if australian_data is not None else \"No disponible\", \n",
        "    'Credit Card Default': default_data.shape if default_data is not None else \"No disponible\"\n",
        "}\n",
        "\n",
        "for name, shape in datasets_info.items():\n",
        "    print(f\"   {name}: {shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Usando German Credit Data como proxy del Segmento D\n",
            "   Tama√±o: 1000 muestras\n",
            "   Features: 20\n",
            "   Target: class\n",
            "\n",
            "üìñ Primeras 5 filas del dataset:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Attribute1</th>\n",
              "      <th>Attribute2</th>\n",
              "      <th>Attribute3</th>\n",
              "      <th>Attribute4</th>\n",
              "      <th>Attribute5</th>\n",
              "      <th>Attribute6</th>\n",
              "      <th>Attribute7</th>\n",
              "      <th>Attribute8</th>\n",
              "      <th>Attribute9</th>\n",
              "      <th>Attribute10</th>\n",
              "      <th>Attribute11</th>\n",
              "      <th>Attribute12</th>\n",
              "      <th>Attribute13</th>\n",
              "      <th>Attribute14</th>\n",
              "      <th>Attribute15</th>\n",
              "      <th>Attribute16</th>\n",
              "      <th>Attribute17</th>\n",
              "      <th>Attribute18</th>\n",
              "      <th>Attribute19</th>\n",
              "      <th>Attribute20</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A11</td>\n",
              "      <td>6</td>\n",
              "      <td>A34</td>\n",
              "      <td>A43</td>\n",
              "      <td>1169</td>\n",
              "      <td>A65</td>\n",
              "      <td>A75</td>\n",
              "      <td>4</td>\n",
              "      <td>A93</td>\n",
              "      <td>A101</td>\n",
              "      <td>4</td>\n",
              "      <td>A121</td>\n",
              "      <td>67</td>\n",
              "      <td>A143</td>\n",
              "      <td>A152</td>\n",
              "      <td>2</td>\n",
              "      <td>A173</td>\n",
              "      <td>1</td>\n",
              "      <td>A192</td>\n",
              "      <td>A201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A12</td>\n",
              "      <td>48</td>\n",
              "      <td>A32</td>\n",
              "      <td>A43</td>\n",
              "      <td>5951</td>\n",
              "      <td>A61</td>\n",
              "      <td>A73</td>\n",
              "      <td>2</td>\n",
              "      <td>A92</td>\n",
              "      <td>A101</td>\n",
              "      <td>2</td>\n",
              "      <td>A121</td>\n",
              "      <td>22</td>\n",
              "      <td>A143</td>\n",
              "      <td>A152</td>\n",
              "      <td>1</td>\n",
              "      <td>A173</td>\n",
              "      <td>1</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A14</td>\n",
              "      <td>12</td>\n",
              "      <td>A34</td>\n",
              "      <td>A46</td>\n",
              "      <td>2096</td>\n",
              "      <td>A61</td>\n",
              "      <td>A74</td>\n",
              "      <td>2</td>\n",
              "      <td>A93</td>\n",
              "      <td>A101</td>\n",
              "      <td>3</td>\n",
              "      <td>A121</td>\n",
              "      <td>49</td>\n",
              "      <td>A143</td>\n",
              "      <td>A152</td>\n",
              "      <td>1</td>\n",
              "      <td>A172</td>\n",
              "      <td>2</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A11</td>\n",
              "      <td>42</td>\n",
              "      <td>A32</td>\n",
              "      <td>A42</td>\n",
              "      <td>7882</td>\n",
              "      <td>A61</td>\n",
              "      <td>A74</td>\n",
              "      <td>2</td>\n",
              "      <td>A93</td>\n",
              "      <td>A103</td>\n",
              "      <td>4</td>\n",
              "      <td>A122</td>\n",
              "      <td>45</td>\n",
              "      <td>A143</td>\n",
              "      <td>A153</td>\n",
              "      <td>1</td>\n",
              "      <td>A173</td>\n",
              "      <td>2</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A11</td>\n",
              "      <td>24</td>\n",
              "      <td>A33</td>\n",
              "      <td>A40</td>\n",
              "      <td>4870</td>\n",
              "      <td>A61</td>\n",
              "      <td>A73</td>\n",
              "      <td>3</td>\n",
              "      <td>A93</td>\n",
              "      <td>A101</td>\n",
              "      <td>4</td>\n",
              "      <td>A124</td>\n",
              "      <td>53</td>\n",
              "      <td>A143</td>\n",
              "      <td>A153</td>\n",
              "      <td>2</td>\n",
              "      <td>A173</td>\n",
              "      <td>2</td>\n",
              "      <td>A191</td>\n",
              "      <td>A201</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Attribute1  Attribute2 Attribute3 Attribute4  Attribute5 Attribute6  \\\n",
              "0        A11           6        A34        A43        1169        A65   \n",
              "1        A12          48        A32        A43        5951        A61   \n",
              "2        A14          12        A34        A46        2096        A61   \n",
              "3        A11          42        A32        A42        7882        A61   \n",
              "4        A11          24        A33        A40        4870        A61   \n",
              "\n",
              "  Attribute7  Attribute8 Attribute9 Attribute10  Attribute11 Attribute12  \\\n",
              "0        A75           4        A93        A101            4        A121   \n",
              "1        A73           2        A92        A101            2        A121   \n",
              "2        A74           2        A93        A101            3        A121   \n",
              "3        A74           2        A93        A103            4        A122   \n",
              "4        A73           3        A93        A101            4        A124   \n",
              "\n",
              "   Attribute13 Attribute14 Attribute15  Attribute16 Attribute17  Attribute18  \\\n",
              "0           67        A143        A152            2        A173            1   \n",
              "1           22        A143        A152            1        A173            1   \n",
              "2           49        A143        A152            1        A172            2   \n",
              "3           45        A143        A153            1        A173            2   \n",
              "4           53        A143        A153            2        A173            2   \n",
              "\n",
              "  Attribute19 Attribute20  class  \n",
              "0        A192        A201      1  \n",
              "1        A191        A201      2  \n",
              "2        A191        A201      1  \n",
              "3        A191        A201      1  \n",
              "4        A191        A201      2  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä Informaci√≥n del dataset:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 21 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Attribute1   1000 non-null   object\n",
            " 1   Attribute2   1000 non-null   int64 \n",
            " 2   Attribute3   1000 non-null   object\n",
            " 3   Attribute4   1000 non-null   object\n",
            " 4   Attribute5   1000 non-null   int64 \n",
            " 5   Attribute6   1000 non-null   object\n",
            " 6   Attribute7   1000 non-null   object\n",
            " 7   Attribute8   1000 non-null   int64 \n",
            " 8   Attribute9   1000 non-null   object\n",
            " 9   Attribute10  1000 non-null   object\n",
            " 10  Attribute11  1000 non-null   int64 \n",
            " 11  Attribute12  1000 non-null   object\n",
            " 12  Attribute13  1000 non-null   int64 \n",
            " 13  Attribute14  1000 non-null   object\n",
            " 14  Attribute15  1000 non-null   object\n",
            " 15  Attribute16  1000 non-null   int64 \n",
            " 16  Attribute17  1000 non-null   object\n",
            " 17  Attribute18  1000 non-null   int64 \n",
            " 18  Attribute19  1000 non-null   object\n",
            " 19  Attribute20  1000 non-null   object\n",
            " 20  class        1000 non-null   int64 \n",
            "dtypes: int64(8), object(13)\n",
            "memory usage: 164.2+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Seleccionar dataset principal para an√°lisis (German Credit como proxy del segmento D)\n",
        "if german_data is not None:\n",
        "    # Usar German Credit como dataset principal\n",
        "    segment_d_data = german_data.copy()\n",
        "    segment_d_features = german_features.copy()\n",
        "    segment_d_targets = german_targets.copy()\n",
        "    \n",
        "    print(\"üéØ Usando German Credit Data como proxy del Segmento D\")\n",
        "    print(f\"   Tama√±o: {segment_d_data.shape[0]} muestras\")\n",
        "    print(f\"   Features: {segment_d_data.shape[1] - 1}\")\n",
        "    print(f\"   Target: {segment_d_targets.columns[0]}\")\n",
        "    \n",
        "    # Mostrar primeras filas\n",
        "    print(\"\\nüìñ Primeras 5 filas del dataset:\")\n",
        "    display(segment_d_data.head())\n",
        "    \n",
        "    # Informaci√≥n b√°sica del dataset\n",
        "    print(\"\\nüìä Informaci√≥n del dataset:\")\n",
        "    print(segment_d_data.info())\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No se pudo cargar el dataset principal\")\n",
        "    segment_d_data = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. An√°lisis Exploratorio del Segmento D\n",
        "\n",
        "Ahora vamos a realizar un an√°lisis exploratorio completo del dataset que simula el segmento D. Este an√°lisis incluir√°:\n",
        "\n",
        "1. **An√°lisis de calidad de datos**\n",
        "2. **Estad√≠sticas descriptivas**\n",
        "3. **An√°lisis de distribuciones**\n",
        "4. **An√°lisis de correlaciones**\n",
        "5. **Identificaci√≥n de patrones**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:26:09,233 - INFO - Validando calidad de datos\n",
            "2025-10-17 13:26:09,247 - INFO -   Shape: (1000, 21)\n",
            "2025-10-17 13:26:09,247 - INFO -   Memory usage: 0.81 MB\n",
            "2025-10-17 13:26:09,258 - INFO -   Missing values: 0 (0.00%)\n",
            "2025-10-17 13:26:09,264 - INFO -   Duplicates: 0 (0.00%)\n",
            "2025-10-17 13:26:09,271 - INFO -   Data types checked for 21 columns\n",
            "2025-10-17 13:26:09,292 - INFO -   Outliers checked for 8 numeric columns\n",
            "2025-10-17 13:26:09,314 - INFO -   Correlations checked\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç AN√ÅLISIS DE CALIDAD DE DATOS - SEGMENTO D\n",
            "============================================================\n",
            "\n",
            "üìä RESUMEN DE CALIDAD:\n",
            "   Shape: (1000, 21)\n",
            "   Memory usage: 0.81 MB\n",
            "   Missing values: 0 (0.00%)\n",
            "   Duplicates: 0 (0.00%)\n",
            "   Numeric columns: 8\n",
            "   Categorical columns: 13\n",
            "\n",
            "‚úÖ An√°lisis de calidad completado\n"
          ]
        }
      ],
      "source": [
        "# An√°lisis de calidad de datos\n",
        "if segment_d_data is not None:\n",
        "    print(\"üîç AN√ÅLISIS DE CALIDAD DE DATOS - SEGMENTO D\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Validar calidad de datos\n",
        "    quality_results = data_validator.validate_data_quality(segment_d_data, target_col='class')\n",
        "    \n",
        "    # Mostrar resumen de calidad\n",
        "    print(\"\\nüìä RESUMEN DE CALIDAD:\")\n",
        "    print(f\"   Shape: {quality_results['basic_info']['shape']}\")\n",
        "    print(f\"   Memory usage: {quality_results['basic_info']['memory_usage'] / 1024**2:.2f} MB\")\n",
        "    \n",
        "    # Valores faltantes\n",
        "    missing_summary = quality_results['missing_values']['summary']\n",
        "    print(f\"   Missing values: {missing_summary['total_missing']} ({missing_summary['total_percentage']:.2f}%)\")\n",
        "    \n",
        "    # Duplicados\n",
        "    duplicates = quality_results['duplicates']\n",
        "    print(f\"   Duplicates: {duplicates['count']} ({duplicates['percentage']:.2f}%)\")\n",
        "    \n",
        "    # Tipos de datos\n",
        "    data_types = quality_results['data_types']\n",
        "    numeric_cols = [col for col, info in data_types.items() if 'int' in info['dtype'] or 'float' in info['dtype']]\n",
        "    categorical_cols = [col for col, info in data_types.items() if 'object' in info['dtype']]\n",
        "    \n",
        "    print(f\"   Numeric columns: {len(numeric_cols)}\")\n",
        "    print(f\"   Categorical columns: {len(categorical_cols)}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ An√°lisis de calidad completado\")\n",
        "else:\n",
        "    print(\"‚ùå No hay datos disponibles para an√°lisis de calidad\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
