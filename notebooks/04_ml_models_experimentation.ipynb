{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experimentaci√≥n con Modelos ML - Proyecto de Grado\n",
        "## Framework de RL para Optimizaci√≥n de Datos Sint√©ticos y Modelos ML\n",
        "\n",
        "**T√≠tulo:** Sintetizando datos tabulares: Un Framework de Aprendizaje por Refuerzo para el Benchmark de Datos Sint√©ticos y su Impacto en problemas de Clasificaci√≥n\n",
        "\n",
        "**Autor:** Carlos Andres Cortez Ballen\n",
        "\n",
        "### Objetivos de este Notebook:\n",
        "- Implementar y entrenar modelos de scoring crediticio (XGBoost, CatBoost, LightGBM, etc.)\n",
        "- Evaluar modelos con m√©tricas espec√≠ficas del dominio (AUC, PSI, Traffic Light)\n",
        "- Comparar performance entre modelos entrenados con datos reales vs sint√©ticos\n",
        "- Establecer baseline de performance para el segmento D\n",
        "- Preparar datos para el framework de RL\n",
        "\n",
        "### Metodolog√≠a:\n",
        "1. **Modelos ML**: XGBoost, CatBoost, LightGBM, HistGradientBoosting, RandomForest, LogisticRegression\n",
        "2. **M√©tricas de Evaluaci√≥n**: AUC-ROC, PSI, Traffic Light, Gini Coefficient, Population Stability\n",
        "3. **Validaci√≥n**: Cross-validation y evaluaci√≥n en datos de prueba\n",
        "4. **Comparaci√≥n**: Datos reales vs datos sint√©ticos\n",
        "\n",
        "### Contenido:\n",
        "1. Configuraci√≥n y carga de datos\n",
        "2. Divisi√≥n de datos (train/validation/test)\n",
        "3. Entrenamiento de modelos con datos reales\n",
        "4. Evaluaci√≥n y comparaci√≥n de modelos\n",
        "5. An√°lisis de importancia de features\n",
        "6. Preparaci√≥n para experimentos con datos sint√©ticos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Librer√≠as importadas correctamente\n",
            "üìä Pandas version: 2.2.3\n",
            "üî¢ NumPy version: 1.26.4\n",
            "üìà Matplotlib version: 3.10.1\n",
            "üé® Seaborn version: 0.13.2\n",
            "‚öôÔ∏è Configuraci√≥n cargada: 8 secciones\n"
          ]
        }
      ],
      "source": [
        "# Importaci√≥n de librer√≠as y configuraci√≥n\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Configuraci√≥n de visualizaciones\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuraci√≥n de pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Configuraci√≥n de logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Cargar configuraci√≥n\n",
        "with open('../configs/config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
        "print(f\"üìä Pandas version: {pd.__version__}\")\n",
        "print(f\"üî¢ NumPy version: {np.__version__}\")\n",
        "print(f\"üìà Matplotlib version: {plt.matplotlib.__version__}\")\n",
        "print(f\"üé® Seaborn version: {sns.__version__}\")\n",
        "print(f\"‚öôÔ∏è Configuraci√≥n cargada: {len(config)} secciones\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:47:13,937 - INFO - DataSplitter inicializado:\n",
            "2025-10-17 13:47:13,939 - INFO -   Train: 0.6, Validation: 0.2, Test: 0.2\n",
            "2025-10-17 13:47:13,941 - INFO -   Synthetic validation: 0.15\n",
            "2025-10-17 13:47:13,942 - INFO -   CV folds: 5\n",
            "2025-10-17 13:47:13,944 - INFO - ModelFactory inicializado\n",
            "2025-10-17 13:47:13,945 - INFO -   Active models: ['XGBoost', 'CatBoost', 'LightGBM', 'HistGradientBoosting', 'RandomForest', 'LogisticRegression']\n",
            "2025-10-17 13:47:13,948 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ M√≥dulos del proyecto importados correctamente\n",
            "üìÅ DataLoader inicializado\n",
            "üîß DataPreprocessor inicializado\n",
            "‚úÇÔ∏è DataSplitter inicializado\n",
            "ü§ñ ModelFactory inicializado\n",
            "üìä CreditModelEvaluator inicializado\n"
          ]
        }
      ],
      "source": [
        "# Importar m√≥dulos del proyecto\n",
        "from src.data.data_loader import DataLoader\n",
        "from src.data.data_preprocessor import DataPreprocessor\n",
        "from src.data.data_splitter import DataSplitter\n",
        "from src.models.model_factory import ModelFactory\n",
        "from src.models.model_evaluator import CreditModelEvaluator\n",
        "\n",
        "# Inicializar componentes\n",
        "data_loader = DataLoader(config)\n",
        "data_preprocessor = DataPreprocessor(config)\n",
        "data_splitter = DataSplitter(config)\n",
        "model_factory = ModelFactory(config)\n",
        "credit_evaluator = CreditModelEvaluator(config)\n",
        "\n",
        "print(\"‚úÖ M√≥dulos del proyecto importados correctamente\")\n",
        "print(\"üìÅ DataLoader inicializado\")\n",
        "print(\"üîß DataPreprocessor inicializado\")\n",
        "print(\"‚úÇÔ∏è DataSplitter inicializado\")\n",
        "print(\"ü§ñ ModelFactory inicializado\")\n",
        "print(\"üìä CreditModelEvaluator inicializado\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:47:18,353 - INFO - Cargando dataset UCI ID: 144\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Cargando y preparando datos del segmento D...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:47:20,183 - INFO - Dataset cargado: 1000 filas, 20 features\n",
            "2025-10-17 13:47:20,186 - INFO - Target shape: (1000, 1)\n",
            "2025-10-17 13:47:20,187 - INFO - Iniciando preprocesamiento completo de datos\n",
            "2025-10-17 13:47:20,187 - INFO - Manejando valores faltantes con estrategia: median\n",
            "2025-10-17 13:47:20,196 - INFO - No se encontraron valores faltantes\n",
            "2025-10-17 13:47:20,196 - INFO - Codificando variables categ√≥ricas\n",
            "2025-10-17 13:47:20,210 - INFO - Tipos de datos detectados:\n",
            "2025-10-17 13:47:20,210 - INFO -   numeric: 6 columnas\n",
            "2025-10-17 13:47:20,210 - INFO -   categorical: 13 columnas\n",
            "2025-10-17 13:47:20,210 - INFO -   binary: 2 columnas\n",
            "2025-10-17 13:47:20,219 - INFO -   datetime: 0 columnas\n",
            "2025-10-17 13:47:20,225 - INFO -   Attribute1: 4 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,227 - INFO -   Attribute3: 5 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,227 - INFO -   Attribute4: 10 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,235 - INFO -   Attribute6: 5 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,240 - INFO -   Attribute7: 5 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,243 - INFO -   Attribute9: 4 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,243 - INFO -   Attribute10: 3 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,243 - INFO -   Attribute12: 4 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,253 - INFO -   Attribute14: 3 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,253 - INFO -   Attribute15: 3 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,260 - INFO -   Attribute17: 4 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,260 - INFO -   Attribute19: 2 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,260 - INFO -   Attribute20: 2 categor√≠as codificadas\n",
            "2025-10-17 13:47:20,260 - INFO - Escalando variables num√©ricas\n",
            "2025-10-17 13:47:20,277 - INFO - Tipos de datos detectados:\n",
            "2025-10-17 13:47:20,277 - INFO -   numeric: 17 columnas\n",
            "2025-10-17 13:47:20,285 - INFO -   categorical: 0 columnas\n",
            "2025-10-17 13:47:20,287 - INFO -   binary: 4 columnas\n",
            "2025-10-17 13:47:20,289 - INFO -   datetime: 0 columnas\n",
            "2025-10-17 13:47:20,303 - INFO - Scaler ajustado para 17 variables num√©ricas\n",
            "2025-10-17 13:47:20,306 - INFO - Creando features de ingenier√≠a\n",
            "2025-10-17 13:47:20,310 - INFO - Feature de interacci√≥n creada: Attribute1_x_Attribute2\n",
            "2025-10-17 13:47:20,310 - INFO - Feature polin√≥mica creada: Attribute1_squared\n",
            "2025-10-17 13:47:20,310 - INFO - Features de ingenier√≠a creadas. Nuevo shape: (1000, 23)\n",
            "2025-10-17 13:47:20,310 - INFO - Preprocesamiento completado. Shape final: (1000, 23)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Datos del segmento D cargados: (1000, 21)\n",
            "   Features: 20\n",
            "   Target distribution: {1: 700, 2: 300}\n",
            "\n",
            "üîß Preprocesando datos...\n",
            "‚úÖ Datos preprocesados: (1000, 23)\n",
            "   Feature names: 22\n",
            "\n",
            "üìä Datos preparados:\n",
            "   Features (X): (1000, 22)\n",
            "   Target (y): (1000,)\n",
            "   Target distribution: {1: 700, 2: 300}\n"
          ]
        }
      ],
      "source": [
        "# Cargar y preparar datos del segmento D\n",
        "print(\"üîÑ Cargando y preparando datos del segmento D...\")\n",
        "\n",
        "try:\n",
        "    # Cargar German Credit Data como proxy del segmento D\n",
        "    german_features, german_targets = data_loader.load_uci_dataset(144, \"german_credit\")\n",
        "    segment_d_data = pd.concat([german_features, german_targets], axis=1)\n",
        "    \n",
        "    print(f\"‚úÖ Datos del segmento D cargados: {segment_d_data.shape}\")\n",
        "    print(f\"   Features: {german_features.shape[1]}\")\n",
        "    print(f\"   Target distribution: {german_targets.iloc[:, 0].value_counts().to_dict()}\")\n",
        "    \n",
        "    # Preprocesar datos\n",
        "    print(\"\\nüîß Preprocesando datos...\")\n",
        "    processed_data = data_preprocessor.preprocess_data(segment_d_data, target_col='class', fit=True)\n",
        "    \n",
        "    print(f\"‚úÖ Datos preprocesados: {processed_data.shape}\")\n",
        "    print(f\"   Feature names: {len(data_preprocessor.get_feature_names())}\")\n",
        "    \n",
        "    # Separar features y target\n",
        "    target_col = 'class'\n",
        "    X = processed_data.drop(columns=[target_col])\n",
        "    y = processed_data[target_col]\n",
        "    \n",
        "    print(f\"\\nüìä Datos preparados:\")\n",
        "    print(f\"   Features (X): {X.shape}\")\n",
        "    print(f\"   Target (y): {y.shape}\")\n",
        "    print(f\"   Target distribution: {y.value_counts().to_dict()}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error cargando datos: {e}\")\n",
        "    X, y = None, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:47:27,065 - INFO - Dividiendo datos en train/validation/test\n",
            "2025-10-17 13:47:27,089 - INFO -   train: 600 muestras\n",
            "2025-10-17 13:47:27,089 - INFO -     Clase 1: 420 (70.0%)\n",
            "2025-10-17 13:47:27,089 - INFO -     Clase 2: 180 (30.0%)\n",
            "2025-10-17 13:47:27,095 - INFO -   validation: 200 muestras\n",
            "2025-10-17 13:47:27,095 - INFO -     Clase 1: 140 (70.0%)\n",
            "2025-10-17 13:47:27,095 - INFO -     Clase 2: 60 (30.0%)\n",
            "2025-10-17 13:47:27,095 - INFO -   test: 200 muestras\n",
            "2025-10-17 13:47:27,095 - INFO -     Clase 1: 140 (70.0%)\n",
            "2025-10-17 13:47:27,104 - INFO -     Clase 2: 60 (30.0%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÇÔ∏è Dividiendo datos en train/validation/test...\n",
            "‚úÖ Datos divididos:\n",
            "   Train: 600 muestras\n",
            "   Validation: 200 muestras\n",
            "   Test: 200 muestras\n",
            "\n",
            "üìä Distribuci√≥n del target:\n",
            "   train: {1: 420, 2: 180}\n",
            "   validation: {1: 140, 2: 60}\n",
            "   test: {1: 140, 2: 60}\n",
            "\n",
            "üìã Informaci√≥n de splits:\n",
            "   train: 600 muestras, 22 features\n",
            "   validation: 200 muestras, 22 features\n",
            "   test: 200 muestras, 22 features\n"
          ]
        }
      ],
      "source": [
        "# Divisi√≥n de datos para entrenamiento y evaluaci√≥n\n",
        "if X is not None and y is not None:\n",
        "    print(\"‚úÇÔ∏è Dividiendo datos en train/validation/test...\")\n",
        "    \n",
        "    # Dividir datos\n",
        "    splits = data_splitter.split_data(X, y, stratify=True)\n",
        "    \n",
        "    X_train, y_train = splits['train']\n",
        "    X_val, y_val = splits['validation']\n",
        "    X_test, y_test = splits['test']\n",
        "    \n",
        "    print(f\"‚úÖ Datos divididos:\")\n",
        "    print(f\"   Train: {X_train.shape[0]} muestras\")\n",
        "    print(f\"   Validation: {X_val.shape[0]} muestras\")\n",
        "    print(f\"   Test: {X_test.shape[0]} muestras\")\n",
        "    \n",
        "    # Mostrar distribuci√≥n del target en cada split\n",
        "    print(f\"\\nüìä Distribuci√≥n del target:\")\n",
        "    for split_name, (X_split, y_split) in splits.items():\n",
        "        print(f\"   {split_name}: {y_split.value_counts().to_dict()}\")\n",
        "    \n",
        "    # Informaci√≥n de los splits\n",
        "    split_info = data_splitter.get_data_info(splits)\n",
        "    print(f\"\\nüìã Informaci√≥n de splits:\")\n",
        "    for split_name, info in split_info.items():\n",
        "        print(f\"   {split_name}: {info['n_samples']} muestras, {info['n_features']} features\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No hay datos disponibles para dividir\")\n",
        "    splits = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear y entrenar todos los modelos\n",
        "if splits is not None:\n",
        "    print(\"ü§ñ Creando y entrenando modelos de scoring crediticio...\")\n",
        "    \n",
        "    # Crear todos los modelos\n",
        "    models = model_factory.create_all_models()\n",
        "    print(f\"‚úÖ {len(models)} modelos creados: {list(models.keys())}\")\n",
        "    \n",
        "    # Entrenar todos los modelos\n",
        "    print(\"\\nüèãÔ∏è Entrenando modelos...\")\n",
        "    trained_models = model_factory.train_all_models(X_train, y_train)\n",
        "    \n",
        "    print(f\"‚úÖ {len(trained_models)} modelos entrenados exitosamente\")\n",
        "    \n",
        "    # Mostrar resumen de entrenamiento\n",
        "    training_summary = model_factory.get_training_summary()\n",
        "    print(f\"\\nüìä Resumen de entrenamiento:\")\n",
        "    print(f\"   Total modelos: {training_summary['total_models']}\")\n",
        "    print(f\"   Modelos entrenados: {training_summary['trained_models']}\")\n",
        "    print(f\"   Tipos de modelos: {list(training_summary['model_types'].keys())}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No hay datos disponibles para entrenar modelos\")\n",
        "    models = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluar todos los modelos\n",
        "if models is not None:\n",
        "    print(\"üìä Evaluando todos los modelos...\")\n",
        "    \n",
        "    # Evaluar todos los modelos\n",
        "    results = model_factory.evaluate_all_models(X_test, y_test, X_train, y_train)\n",
        "    \n",
        "    print(f\"‚úÖ {len(results)} modelos evaluados exitosamente\")\n",
        "    \n",
        "    # Mostrar resultados m√©trica por m√©trica\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìà COMPARACI√ìN M√âTRICA A M√âTRICA DE TODOS LOS MODELOS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Crear DataFrame con todas las m√©tricas\n",
        "    metrics_data = []\n",
        "    \n",
        "    for model_name, model_results in results.items():\n",
        "        row = {'Modelo': model_name}\n",
        "        \n",
        "        # M√©tricas b√°sicas\n",
        "        if 'basic_metrics' in model_results and 'error' not in model_results['basic_metrics']:\n",
        "            basic = model_results['basic_metrics']\n",
        "            row.update({\n",
        "                'AUC-ROC': basic.get('auc_roc', 0),\n",
        "                'AUC-PR': basic.get('auc_pr', 0),\n",
        "                'Precision': basic.get('precision', 0),\n",
        "                'Recall': basic.get('recall', 0),\n",
        "                'F1-Score': basic.get('f1_score', 0)\n",
        "            })\n",
        "        \n",
        "        # M√©tricas de cr√©dito\n",
        "        if 'credit_metrics' in model_results and 'error' not in model_results['credit_metrics']:\n",
        "            credit = model_results['credit_metrics']\n",
        "            row.update({\n",
        "                'Gini': credit.get('gini_coefficient', 0),\n",
        "                'PSI': credit.get('psi', 0)\n",
        "            })\n",
        "            \n",
        "            # Traffic Light\n",
        "            if 'traffic_light' in credit and 'error' not in credit['traffic_light']:\n",
        "                row['Traffic_Light_Green_%'] = credit['traffic_light'].get('green_percentage', 0)\n",
        "            else:\n",
        "                row['Traffic_Light_Green_%'] = 0\n",
        "        \n",
        "        # Score general\n",
        "        row['Overall_Score'] = model_results.get('overall_score', 0)\n",
        "        \n",
        "        metrics_data.append(row)\n",
        "    \n",
        "    # Crear DataFrame\n",
        "    metrics_df = pd.DataFrame(metrics_data)\n",
        "    \n",
        "    # Mostrar tabla completa\n",
        "    print(\"\\nüìã TABLA COMPLETA DE M√âTRICAS:\")\n",
        "    print(\"-\" * 80)\n",
        "    display(metrics_df.round(4))\n",
        "    \n",
        "    # Mostrar m√©tricas una por una con ranking\n",
        "    print(\"\\nüèÜ RANKING POR M√âTRICA:\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # Lista de m√©tricas para ranking\n",
        "    ranking_metrics = ['AUC-ROC', 'AUC-PR', 'Precision', 'Recall', 'F1-Score', \n",
        "                      'Gini', 'Traffic_Light_Green_%', 'Overall_Score']\n",
        "    \n",
        "    for metric in ranking_metrics:\n",
        "        if metric in metrics_df.columns:\n",
        "            print(f\"\\nü•á {metric.upper()}:\")\n",
        "            sorted_models = metrics_df.sort_values(metric, ascending=False)\n",
        "            for i, (_, row) in enumerate(sorted_models.iterrows(), 1):\n",
        "                print(f\"   {i}. {row['Modelo']}: {row[metric]:.4f}\")\n",
        "    \n",
        "    # Guardar resultados\n",
        "    print(f\"\\nüíæ Resultados guardados en memoria para an√°lisis posterior\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No hay modelos disponibles para evaluar\")\n",
        "    results = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizaci√≥n de m√©tricas\n",
        "if 'metrics_df' in locals() and metrics_df is not None:\n",
        "    print(\"üìä CREANDO VISUALIZACIONES DE M√âTRICAS...\")\n",
        "    \n",
        "    # Configurar el tama√±o de las figuras\n",
        "    plt.rcParams['figure.figsize'] = (15, 10)\n",
        "    \n",
        "    # Crear subplots\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(20, 12))\n",
        "    fig.suptitle('Comparaci√≥n de M√©tricas por Modelo', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # M√©tricas a visualizar\n",
        "    metrics_to_plot = ['AUC-ROC', 'AUC-PR', 'Precision', 'Recall', \n",
        "                      'F1-Score', 'Gini', 'Traffic_Light_Green_%', 'Overall_Score']\n",
        "    \n",
        "    # Colores para cada modelo\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(metrics_df)))\n",
        "    \n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        if metric in metrics_df.columns:\n",
        "            row = i // 4\n",
        "            col = i % 4\n",
        "            ax = axes[row, col]\n",
        "            \n",
        "            # Crear gr√°fico de barras\n",
        "            bars = ax.bar(metrics_df['Modelo'], metrics_df[metric], color=colors)\n",
        "            ax.set_title(f'{metric}', fontweight='bold')\n",
        "            ax.set_ylabel('Score')\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "            \n",
        "            # Agregar valores en las barras\n",
        "            for bar, value in zip(bars, metrics_df[metric]):\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                       f'{value:.3f}', ha='center', va='bottom', fontsize=8)\n",
        "            \n",
        "            # L√≠nea de referencia para m√©tricas importantes\n",
        "            if metric in ['AUC-ROC', 'Overall_Score']:\n",
        "                ax.axhline(y=0.65, color='red', linestyle='--', alpha=0.7, label='Umbral (0.65)')\n",
        "                ax.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Crear heatmap de correlaci√≥n entre m√©tricas\n",
        "    print(\"\\nüî• HEATMAP DE CORRELACI√ìN ENTRE M√âTRICAS:\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Seleccionar solo las columnas num√©ricas\n",
        "    numeric_metrics = metrics_df.select_dtypes(include=[np.number])\n",
        "    \n",
        "    if len(numeric_metrics.columns) > 1:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        correlation_matrix = numeric_metrics.corr()\n",
        "        \n",
        "        # Crear heatmap\n",
        "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "                   square=True, fmt='.3f', cbar_kws={'shrink': 0.8})\n",
        "        plt.title('Correlaci√≥n entre M√©tricas de Modelos', fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Mostrar correlaciones m√°s altas\n",
        "        print(\"\\nüìà CORRELACIONES M√ÅS ALTAS:\")\n",
        "        # Obtener pares de correlaci√≥n (sin duplicados)\n",
        "        corr_pairs = []\n",
        "        for i in range(len(correlation_matrix.columns)):\n",
        "            for j in range(i+1, len(correlation_matrix.columns)):\n",
        "                corr_pairs.append({\n",
        "                    'M√©trica 1': correlation_matrix.columns[i],\n",
        "                    'M√©trica 2': correlation_matrix.columns[j],\n",
        "                    'Correlaci√≥n': correlation_matrix.iloc[i, j]\n",
        "                })\n",
        "        \n",
        "        corr_df = pd.DataFrame(corr_pairs)\n",
        "        corr_df = corr_df.sort_values('Correlaci√≥n', key=abs, ascending=False)\n",
        "        \n",
        "        print(corr_df.head(10).to_string(index=False))\n",
        "    \n",
        "    print(\"\\n‚úÖ Visualizaciones completadas\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No hay datos de m√©tricas disponibles para visualizar\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lisis detallado del mejor modelo\n",
        "if 'metrics_df' in locals() and metrics_df is not None:\n",
        "    print(\"üèÜ AN√ÅLISIS DEL MEJOR MODELO...\")\n",
        "    \n",
        "    # Obtener el mejor modelo por Overall Score\n",
        "    best_model_name = metrics_df.loc[metrics_df['Overall_Score'].idxmax(), 'Modelo']\n",
        "    best_model_score = metrics_df.loc[metrics_df['Overall_Score'].idxmax(), 'Overall_Score']\n",
        "    \n",
        "    print(f\"ü•á Mejor modelo: {best_model_name}\")\n",
        "    print(f\"üìä Overall Score: {best_model_score:.4f}\")\n",
        "    \n",
        "    # Obtener el modelo del factory\n",
        "    best_model = model_factory.models[best_model_name]\n",
        "    \n",
        "    # Mostrar m√©tricas detalladas del mejor modelo\n",
        "    print(f\"\\nüìà M√âTRICAS DETALLADAS DE {best_model_name.upper()}:\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    best_model_metrics = metrics_df[metrics_df['Modelo'] == best_model_name].iloc[0]\n",
        "    \n",
        "    for metric, value in best_model_metrics.items():\n",
        "        if metric != 'Modelo':\n",
        "            print(f\"   {metric}: {value:.4f}\")\n",
        "    \n",
        "    # An√°lisis de importancia de features\n",
        "    print(f\"\\nüîç AN√ÅLISIS DE IMPORTANCIA DE FEATURES:\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    try:\n",
        "        feature_importance = best_model.get_feature_importance()\n",
        "        \n",
        "        if feature_importance is not None:\n",
        "            print(f\"   Top 10 features m√°s importantes:\")\n",
        "            for i, (feature, importance) in enumerate(feature_importance.head(10).items(), 1):\n",
        "                print(f\"   {i:2d}. {feature}: {importance:.4f}\")\n",
        "            \n",
        "            # Visualizar importancia de features\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            top_features = feature_importance.head(15)\n",
        "            \n",
        "            bars = plt.barh(range(len(top_features)), top_features.values)\n",
        "            plt.yticks(range(len(top_features)), top_features.index)\n",
        "            plt.xlabel('Importancia')\n",
        "            plt.title(f'Top 15 Features m√°s Importantes - {best_model_name}', fontweight='bold')\n",
        "            plt.gca().invert_yaxis()\n",
        "            \n",
        "            # Agregar valores en las barras\n",
        "            for i, (bar, value) in enumerate(zip(bars, top_features.values)):\n",
        "                plt.text(value + 0.001, i, f'{value:.3f}', \n",
        "                        va='center', ha='left', fontsize=9)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è El modelo {best_model_name} no soporta an√°lisis de importancia de features\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error obteniendo importancia de features: {e}\")\n",
        "    \n",
        "    # Cross-validation del mejor modelo\n",
        "    print(f\"\\nüîÑ VALIDACI√ìN CRUZADA DE {best_model_name.upper()}:\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    try:\n",
        "        cv_results = model_factory.cross_validate_model(best_model, X_train, y_train, 'roc_auc')\n",
        "        \n",
        "        print(f\"   CV Score (AUC-ROC): {cv_results['mean_score']:.4f} ¬± {cv_results['std_score']:.4f}\")\n",
        "        print(f\"   Folds: {cv_results['cv_folds']}\")\n",
        "        print(f\"   Scores por fold: {[f'{score:.4f}' for score in cv_results['cv_scores']]}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Error en validaci√≥n cruzada: {e}\")\n",
        "    \n",
        "    # Comparaci√≥n con umbrales del proyecto\n",
        "    print(f\"\\nüéØ EVALUACI√ìN CONTRA UMBRALES DEL PROYECTO:\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    # Umbrales definidos en el proyecto\n",
        "    thresholds = {\n",
        "        'AUC-ROC': {'minimum': 0.65, 'target': 0.75},\n",
        "        'PSI': {'maximum': 0.10, 'warning': 0.05},\n",
        "        'Traffic_Light_Green_%': {'minimum_green': 0.8}\n",
        "    }\n",
        "    \n",
        "    for metric, threshold_info in thresholds.items():\n",
        "        if metric in best_model_metrics:\n",
        "            value = best_model_metrics[metric]\n",
        "            \n",
        "            if metric == 'AUC-ROC':\n",
        "                if value >= threshold_info['target']:\n",
        "                    status = \"‚úÖ EXCELENTE\"\n",
        "                elif value >= threshold_info['minimum']:\n",
        "                    status = \"‚úÖ ACEPTABLE\"\n",
        "                else:\n",
        "                    status = \"‚ùå INSUFICIENTE\"\n",
        "                print(f\"   {metric}: {value:.4f} (Umbral: {threshold_info['minimum']}) - {status}\")\n",
        "                \n",
        "            elif metric == 'PSI':\n",
        "                if value <= threshold_info['warning']:\n",
        "                    status = \"‚úÖ ESTABLE\"\n",
        "                elif value <= threshold_info['maximum']:\n",
        "                    status = \"‚ö†Ô∏è ADVERTENCIA\"\n",
        "                else:\n",
        "                    status = \"‚ùå INESTABLE\"\n",
        "                print(f\"   {metric}: {value:.4f} (M√°ximo: {threshold_info['maximum']}) - {status}\")\n",
        "                \n",
        "            elif metric == 'Traffic_Light_Green_%':\n",
        "                if value >= threshold_info['minimum_green']:\n",
        "                    status = \"‚úÖ BUENO\"\n",
        "                else:\n",
        "                    status = \"‚ùå NECESITA MEJORA\"\n",
        "                print(f\"   {metric}: {value:.4f} (M√≠nimo: {threshold_info['minimum_green']}) - {status}\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ An√°lisis del mejor modelo completado\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No hay datos de m√©tricas disponibles para an√°lisis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen ejecutivo y conclusiones\n",
        "if 'metrics_df' in locals() and metrics_df is not None:\n",
        "    print(\"üìã RESUMEN EJECUTIVO Y CONCLUSIONES\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Estad√≠sticas generales\n",
        "    print(\"\\nüìä ESTAD√çSTICAS GENERALES:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"   Total de modelos evaluados: {len(metrics_df)}\")\n",
        "    print(f\"   Mejor Overall Score: {metrics_df['Overall_Score'].max():.4f}\")\n",
        "    print(f\"   Peor Overall Score: {metrics_df['Overall_Score'].min():.4f}\")\n",
        "    print(f\"   Promedio Overall Score: {metrics_df['Overall_Score'].mean():.4f}\")\n",
        "    print(f\"   Desviaci√≥n est√°ndar: {metrics_df['Overall_Score'].std():.4f}\")\n",
        "    \n",
        "    # Top 3 modelos\n",
        "    print(f\"\\nüèÜ TOP 3 MODELOS:\")\n",
        "    print(\"-\" * 40)\n",
        "    top_3 = metrics_df.nlargest(3, 'Overall_Score')\n",
        "    for i, (_, row) in enumerate(top_3.iterrows(), 1):\n",
        "        print(f\"   {i}. {row['Modelo']}: {row['Overall_Score']:.4f}\")\n",
        "    \n",
        "    # An√°lisis por tipo de modelo\n",
        "    print(f\"\\nüîç AN√ÅLISIS POR TIPO DE MODELO:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Clasificar modelos por tipo\n",
        "    model_types = {\n",
        "        'Gradient Boosting': ['XGBoost', 'CatBoost', 'LightGBM', 'HistGradientBoosting'],\n",
        "        'Tree-based': ['RandomForest'],\n",
        "        'Linear': ['LogisticRegression']\n",
        "    }\n",
        "    \n",
        "    for model_type, model_names in model_types.items():\n",
        "        type_models = metrics_df[metrics_df['Modelo'].isin(model_names)]\n",
        "        if len(type_models) > 0:\n",
        "            avg_score = type_models['Overall_Score'].mean()\n",
        "            best_in_type = type_models.loc[type_models['Overall_Score'].idxmax(), 'Modelo']\n",
        "            print(f\"   {model_type}:\")\n",
        "            print(f\"      Promedio: {avg_score:.4f}\")\n",
        "            print(f\"      Mejor: {best_in_type} ({type_models['Overall_Score'].max():.4f})\")\n",
        "            print(f\"      Modelos: {len(type_models)}\")\n",
        "    \n",
        "    # Cumplimiento de umbrales\n",
        "    print(f\"\\nüéØ CUMPLIMIENTO DE UMBRALES:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Contar modelos que cumplen umbrales\n",
        "    auc_threshold = 0.65\n",
        "    psi_threshold = 0.10\n",
        "    \n",
        "    models_above_auc = len(metrics_df[metrics_df['AUC-ROC'] >= auc_threshold])\n",
        "    models_below_psi = len(metrics_df[metrics_df['PSI'] <= psi_threshold])\n",
        "    \n",
        "    print(f\"   Modelos con AUC ‚â• {auc_threshold}: {models_above_auc}/{len(metrics_df)} ({models_above_auc/len(metrics_df)*100:.1f}%)\")\n",
        "    print(f\"   Modelos con PSI ‚â§ {psi_threshold}: {models_below_psi}/{len(metrics_df)} ({models_below_psi/len(metrics_df)*100:.1f}%)\")\n",
        "    \n",
        "    # Modelos que cumplen ambos umbrales\n",
        "    both_thresholds = metrics_df[\n",
        "        (metrics_df['AUC-ROC'] >= auc_threshold) & \n",
        "        (metrics_df['PSI'] <= psi_threshold)\n",
        "    ]\n",
        "    print(f\"   Modelos que cumplen ambos umbrales: {len(both_thresholds)}/{len(metrics_df)} ({len(both_thresholds)/len(metrics_df)*100:.1f}%)\")\n",
        "    \n",
        "    # Recomendaciones\n",
        "    print(f\"\\nüí° RECOMENDACIONES:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    best_model_name = metrics_df.loc[metrics_df['Overall_Score'].idxmax(), 'Modelo']\n",
        "    best_auc = metrics_df['AUC-ROC'].max()\n",
        "    best_psi = metrics_df['PSI'].min()\n",
        "    \n",
        "    print(f\"   1. Modelo recomendado: {best_model_name}\")\n",
        "    print(f\"   2. Mejor AUC-ROC: {best_auc:.4f} ({'‚úÖ Cumple' if best_auc >= 0.65 else '‚ùå No cumple'} umbral)\")\n",
        "    print(f\"   3. Mejor PSI: {best_psi:.4f} ({'‚úÖ Estable' if best_psi <= 0.10 else '‚ùå Inestable'})\")\n",
        "    \n",
        "    if best_auc < 0.65:\n",
        "        print(f\"   4. ‚ö†Ô∏è Ning√∫n modelo alcanza el umbral m√≠nimo de AUC (0.65)\")\n",
        "        print(f\"      Considerar: Feature engineering, m√°s datos, o modelos m√°s complejos\")\n",
        "    \n",
        "    if best_psi > 0.10:\n",
        "        print(f\"   5. ‚ö†Ô∏è Algunos modelos muestran inestabilidad (PSI > 0.10)\")\n",
        "        print(f\"      Considerar: Regularizaci√≥n, validaci√≥n cruzada m√°s robusta\")\n",
        "    \n",
        "    # Pr√≥ximos pasos\n",
        "    print(f\"\\nüöÄ PR√ìXIMOS PASOS SUGERIDOS:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"   1. Implementar el mejor modelo ({best_model_name}) en producci√≥n\")\n",
        "    print(f\"   2. Realizar validaci√≥n con datos fuera de tiempo (OOT)\")\n",
        "    print(f\"   3. Implementar monitoreo de estabilidad (PSI)\")\n",
        "    print(f\"   4. Considerar ensemble de los top 3 modelos\")\n",
        "    print(f\"   5. Experimentar con datos sint√©ticos para mejorar performance\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ An√°lisis completo finalizado\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No hay datos disponibles para resumen ejecutivo\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Pr√≥ximos Pasos: Integraci√≥n con Datos Sint√©ticos\n",
        "\n",
        "Ahora que hemos establecido una l√≠nea base s√≥lida con los modelos de ML, el siguiente paso es integrar los datos sint√©ticos generados en la Fase 2 para mejorar el performance de los modelos.\n",
        "\n",
        "### üìã Plan de Integraci√≥n:\n",
        "\n",
        "1. **Cargar datos sint√©ticos generados** desde la Fase 2\n",
        "2. **Combinar datos reales y sint√©ticos** para entrenamiento\n",
        "3. **Re-entrenar modelos** con datos combinados\n",
        "4. **Comparar performance** entre modelos entrenados solo con datos reales vs. datos combinados\n",
        "5. **Evaluar calidad de datos sint√©ticos** usando m√©tricas espec√≠ficas\n",
        "6. **Implementar estrategias de Domain Generalization**\n",
        "\n",
        "### üîÑ Estrategias de Combinaci√≥n:\n",
        "\n",
        "- **Estrategia 1**: 70% datos reales + 30% datos sint√©ticos\n",
        "- **Estrategia 2**: 50% datos reales + 50% datos sint√©ticos  \n",
        "- **Estrategia 3**: 30% datos reales + 70% datos sint√©ticos\n",
        "- **Estrategia 4**: Solo datos sint√©ticos (validaci√≥n extrema)\n",
        "\n",
        "### üìä M√©tricas de Evaluaci√≥n Adicionales:\n",
        "\n",
        "- **Kolmogorov-Smirnov Complement** para comparar distribuciones\n",
        "- **Chi-Squared test** para independencia\n",
        "- **Kullback-Leibler Divergence** para similitud\n",
        "- **Cosine Similarity** para correlaci√≥n\n",
        "- **Jensen-Shannon Entropy** para diversidad\n",
        "\n",
        "¬øEst√°s listo para proceder con la integraci√≥n de datos sint√©ticos? üöÄ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:47:43,073 - INFO - Modelo XGBoost inicializado\n",
            "2025-10-17 13:47:43,077 - INFO - XGBoost configurado\n",
            "2025-10-17 13:47:43,078 - INFO - Modelo creado: XGBoost\n",
            "2025-10-17 13:47:43,079 - INFO - Modelo XGBoost creado exitosamente\n",
            "2025-10-17 13:47:43,081 - INFO - Modelo CatBoost inicializado\n",
            "2025-10-17 13:47:43,083 - INFO - CatBoost configurado\n",
            "2025-10-17 13:47:43,084 - INFO - Modelo creado: CatBoost\n",
            "2025-10-17 13:47:43,085 - INFO - Modelo CatBoost creado exitosamente\n",
            "2025-10-17 13:47:43,085 - INFO - Modelo LightGBM inicializado\n",
            "2025-10-17 13:47:43,088 - INFO - LightGBM configurado\n",
            "2025-10-17 13:47:43,091 - INFO - Modelo creado: LightGBM\n",
            "2025-10-17 13:47:43,091 - INFO - Modelo LightGBM creado exitosamente\n",
            "2025-10-17 13:47:43,095 - INFO - Modelo HistGradientBoosting inicializado\n",
            "2025-10-17 13:47:43,095 - INFO - HistGradientBoosting configurado\n",
            "2025-10-17 13:47:43,097 - INFO - Modelo creado: HistGradientBoosting\n",
            "2025-10-17 13:47:43,099 - INFO - Modelo HistGradientBoosting creado exitosamente\n",
            "2025-10-17 13:47:43,099 - INFO - Modelo RandomForest inicializado\n",
            "2025-10-17 13:47:43,102 - INFO - RandomForest configurado\n",
            "2025-10-17 13:47:43,102 - INFO - Modelo creado: RandomForest\n",
            "2025-10-17 13:47:43,104 - INFO - Modelo RandomForest creado exitosamente\n",
            "2025-10-17 13:47:43,104 - INFO - Modelo LogisticRegression inicializado\n",
            "2025-10-17 13:47:43,104 - INFO - LogisticRegression configurado\n",
            "2025-10-17 13:47:43,106 - INFO - Modelo creado: LogisticRegression\n",
            "2025-10-17 13:47:43,108 - INFO - Modelo LogisticRegression creado exitosamente\n",
            "2025-10-17 13:47:43,108 - INFO - Total de modelos creados: 6\n",
            "2025-10-17 13:47:43,108 - INFO - Iniciando entrenamiento de todos los modelos\n",
            "2025-10-17 13:47:43,108 - INFO - Entrenando XGBoost...\n",
            "2025-10-17 13:47:43,113 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:47:43,115 - INFO - Entrenando modelo XGBoost\n",
            "2025-10-17 13:47:50,775 - ERROR - Error entrenando modelo XGBoost: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
            "2025-10-17 13:47:50,775 - ERROR - ‚ùå Error entrenando XGBoost: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
            "2025-10-17 13:47:50,775 - INFO - Entrenando CatBoost...\n",
            "2025-10-17 13:47:50,775 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:47:50,775 - INFO - Entrenando modelo CatBoost\n",
            "2025-10-17 13:48:01,601 - INFO - Modelo CatBoost entrenado exitosamente\n",
            "2025-10-17 13:48:01,601 - INFO - ‚úÖ CatBoost entrenado exitosamente\n",
            "2025-10-17 13:48:01,601 - INFO - Entrenando LightGBM...\n",
            "2025-10-17 13:48:01,607 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:48:01,607 - INFO - Entrenando modelo LightGBM\n",
            "2025-10-17 13:48:03,938 - INFO - Modelo LightGBM entrenado exitosamente\n",
            "2025-10-17 13:48:03,938 - INFO - ‚úÖ LightGBM entrenado exitosamente\n",
            "2025-10-17 13:48:03,938 - INFO - Entrenando HistGradientBoosting...\n",
            "2025-10-17 13:48:03,938 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:48:03,946 - INFO - Entrenando modelo HistGradientBoosting\n",
            "2025-10-17 13:48:14,271 - INFO - Modelo HistGradientBoosting entrenado exitosamente\n",
            "2025-10-17 13:48:14,271 - INFO - ‚úÖ HistGradientBoosting entrenado exitosamente\n",
            "2025-10-17 13:48:14,273 - INFO - Entrenando RandomForest...\n",
            "2025-10-17 13:48:14,274 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:48:14,274 - INFO - Entrenando modelo RandomForest\n",
            "2025-10-17 13:48:14,607 - INFO - Modelo RandomForest entrenado exitosamente\n",
            "2025-10-17 13:48:14,611 - INFO - ‚úÖ RandomForest entrenado exitosamente\n",
            "2025-10-17 13:48:14,613 - INFO - Entrenando LogisticRegression...\n",
            "2025-10-17 13:48:14,616 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:48:14,617 - INFO - Entrenando modelo LogisticRegression\n",
            "2025-10-17 13:48:14,619 - INFO - Modelo LogisticRegression entrenado exitosamente\n",
            "2025-10-17 13:48:14,627 - INFO - ‚úÖ LogisticRegression entrenado exitosamente\n",
            "2025-10-17 13:48:14,627 - INFO - Entrenamiento completado: 5/6 modelos exitosos\n"
          ]
        }
      ],
      "source": [
        "# Crear todos los modelos\n",
        "models = model_factory.create_all_models()\n",
        "\n",
        "# Entrenar todos los modelos\n",
        "trained_models = model_factory.train_all_models(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:48:30,111 - INFO - Evaluando todos los modelos\n",
            "2025-10-17 13:48:30,118 - WARNING - Modelo XGBoost no est√° entrenado\n",
            "2025-10-17 13:48:30,118 - INFO - Evaluando CatBoost...\n",
            "2025-10-17 13:48:30,120 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n",
            "2025-10-17 13:48:30,123 - INFO - Iniciando evaluaci√≥n de modelo de scoring crediticio\n",
            "2025-10-17 13:48:30,152 - WARNING - Error calculando AUC-PR: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n",
            "2025-10-17 13:48:30,156 - INFO - M√©tricas b√°sicas calculadas: AUC-ROC = 0.785\n",
            "2025-10-17 13:48:30,167 - INFO - PSI calculado: 0.4856\n",
            "2025-10-17 13:48:30,175 - INFO - Traffic Light calculado: 0.0% grupos verdes\n",
            "2025-10-17 13:48:30,186 - INFO - Estabilidad de poblaci√≥n calculada: score = 0.848\n",
            "2025-10-17 13:48:30,186 - INFO - M√©tricas de cr√©dito calculadas: 4 m√©tricas\n",
            "2025-10-17 13:48:30,186 - INFO - Evaluaci√≥n completada. Score general: 0.572\n",
            "2025-10-17 13:48:30,192 - INFO - Modelo CatBoost evaluado exitosamente\n",
            "2025-10-17 13:48:30,192 - INFO - ‚úÖ CatBoost evaluado exitosamente\n",
            "2025-10-17 13:48:30,192 - INFO - Evaluando LightGBM...\n",
            "2025-10-17 13:48:30,192 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n",
            "2025-10-17 13:48:30,192 - INFO - Iniciando evaluaci√≥n de modelo de scoring crediticio\n",
            "2025-10-17 13:48:30,224 - WARNING - Error calculando AUC-PR: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n",
            "2025-10-17 13:48:30,232 - INFO - M√©tricas b√°sicas calculadas: AUC-ROC = 0.729\n",
            "2025-10-17 13:48:30,252 - INFO - PSI calculado: 0.3366\n",
            "2025-10-17 13:48:30,256 - INFO - Traffic Light calculado: 0.0% grupos verdes\n",
            "2025-10-17 13:48:30,273 - INFO - Estabilidad de poblaci√≥n calculada: score = 0.888\n",
            "2025-10-17 13:48:30,277 - INFO - M√©tricas de cr√©dito calculadas: 4 m√©tricas\n",
            "2025-10-17 13:48:30,279 - INFO - Evaluaci√≥n completada. Score general: 0.542\n",
            "2025-10-17 13:48:30,279 - INFO - Modelo LightGBM evaluado exitosamente\n",
            "2025-10-17 13:48:30,280 - INFO - ‚úÖ LightGBM evaluado exitosamente\n",
            "2025-10-17 13:48:30,282 - INFO - Evaluando HistGradientBoosting...\n",
            "2025-10-17 13:48:30,282 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n",
            "2025-10-17 13:48:30,284 - INFO - Iniciando evaluaci√≥n de modelo de scoring crediticio\n",
            "2025-10-17 13:48:30,326 - WARNING - Error calculando AUC-PR: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n",
            "2025-10-17 13:48:30,330 - INFO - M√©tricas b√°sicas calculadas: AUC-ROC = 0.744\n",
            "2025-10-17 13:48:30,359 - INFO - PSI calculado: 0.2420\n",
            "2025-10-17 13:48:30,367 - INFO - Traffic Light calculado: 0.0% grupos verdes\n",
            "2025-10-17 13:48:30,393 - INFO - Estabilidad de poblaci√≥n calculada: score = 0.902\n",
            "2025-10-17 13:48:30,395 - INFO - M√©tricas de cr√©dito calculadas: 4 m√©tricas\n",
            "2025-10-17 13:48:30,397 - INFO - Evaluaci√≥n completada. Score general: 0.554\n",
            "2025-10-17 13:48:30,397 - INFO - Modelo HistGradientBoosting evaluado exitosamente\n",
            "2025-10-17 13:48:30,399 - INFO - ‚úÖ HistGradientBoosting evaluado exitosamente\n",
            "2025-10-17 13:48:30,401 - INFO - Evaluando RandomForest...\n",
            "2025-10-17 13:48:30,403 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n",
            "2025-10-17 13:48:30,405 - INFO - Iniciando evaluaci√≥n de modelo de scoring crediticio\n",
            "2025-10-17 13:48:30,568 - WARNING - Error calculando AUC-PR: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n",
            "2025-10-17 13:48:30,568 - INFO - M√©tricas b√°sicas calculadas: AUC-ROC = 0.776\n",
            "2025-10-17 13:48:30,760 - INFO - PSI calculado: 1.3859\n",
            "2025-10-17 13:48:30,762 - INFO - Traffic Light calculado: 0.0% grupos verdes\n",
            "2025-10-17 13:48:30,871 - INFO - Estabilidad de poblaci√≥n calculada: score = 0.745\n",
            "2025-10-17 13:48:30,871 - INFO - M√©tricas de cr√©dito calculadas: 4 m√©tricas\n",
            "2025-10-17 13:48:30,871 - INFO - Evaluaci√≥n completada. Score general: 0.572\n",
            "2025-10-17 13:48:30,871 - INFO - Modelo RandomForest evaluado exitosamente\n",
            "2025-10-17 13:48:30,871 - INFO - ‚úÖ RandomForest evaluado exitosamente\n",
            "2025-10-17 13:48:30,871 - INFO - Evaluando LogisticRegression...\n",
            "2025-10-17 13:48:30,871 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n",
            "2025-10-17 13:48:30,871 - INFO - Iniciando evaluaci√≥n de modelo de scoring crediticio\n",
            "2025-10-17 13:48:30,918 - WARNING - Error calculando AUC-PR: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n",
            "2025-10-17 13:48:30,918 - INFO - M√©tricas b√°sicas calculadas: AUC-ROC = 0.757\n",
            "2025-10-17 13:48:30,929 - INFO - PSI calculado: 0.1063\n",
            "2025-10-17 13:48:30,936 - INFO - Traffic Light calculado: 0.0% grupos verdes\n",
            "2025-10-17 13:48:30,944 - INFO - Estabilidad de poblaci√≥n calculada: score = 0.932\n",
            "2025-10-17 13:48:30,944 - INFO - M√©tricas de cr√©dito calculadas: 4 m√©tricas\n",
            "2025-10-17 13:48:30,944 - INFO - Evaluaci√≥n completada. Score general: 0.567\n",
            "2025-10-17 13:48:30,944 - INFO - Modelo LogisticRegression evaluado exitosamente\n",
            "2025-10-17 13:48:30,944 - INFO - ‚úÖ LogisticRegression evaluado exitosamente\n",
            "2025-10-17 13:48:30,944 - INFO - Evaluaci√≥n completada: 5 modelos evaluados\n",
            "2025-10-17 13:48:30,951 - INFO - Ranking generado para m√©trica overall_score: 5 modelos\n"
          ]
        }
      ],
      "source": [
        "# Evaluar todos los modelos\n",
        "results = model_factory.evaluate_all_models(X_test, y_test, X_train, y_train)\n",
        "\n",
        "# Obtener ranking de modelos\n",
        "ranking = model_factory.get_model_ranking('overall_score')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:49:05,235 - INFO - Mejor modelo: RandomForest (score: 0.572)\n"
          ]
        }
      ],
      "source": [
        "# Obtener el mejor modelo\n",
        "best_model = model_factory.get_best_model('overall_score')\n",
        "\n",
        "# An√°lisis de importancia de features\n",
        "feature_importance = best_model.get_feature_importance()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:51:02,703 - INFO - Modelo XGBoost inicializado\n",
            "2025-10-17 13:51:02,704 - INFO - XGBoost configurado\n",
            "2025-10-17 13:51:02,706 - INFO - Modelo creado: XGBoost\n",
            "2025-10-17 13:51:02,708 - INFO - Modelo XGBoost creado exitosamente\n",
            "2025-10-17 13:51:02,708 - INFO - Modelo CatBoost inicializado\n",
            "2025-10-17 13:51:02,710 - INFO - CatBoost configurado\n",
            "2025-10-17 13:51:02,712 - INFO - Modelo creado: CatBoost\n",
            "2025-10-17 13:51:02,712 - INFO - Modelo CatBoost creado exitosamente\n",
            "2025-10-17 13:51:02,712 - INFO - Modelo LightGBM inicializado\n",
            "2025-10-17 13:51:02,712 - INFO - LightGBM configurado\n",
            "2025-10-17 13:51:02,720 - INFO - Modelo creado: LightGBM\n",
            "2025-10-17 13:51:02,721 - INFO - Modelo LightGBM creado exitosamente\n",
            "2025-10-17 13:51:02,721 - INFO - Modelo HistGradientBoosting inicializado\n",
            "2025-10-17 13:51:02,721 - INFO - HistGradientBoosting configurado\n",
            "2025-10-17 13:51:02,721 - INFO - Modelo creado: HistGradientBoosting\n",
            "2025-10-17 13:51:02,721 - INFO - Modelo HistGradientBoosting creado exitosamente\n",
            "2025-10-17 13:51:02,728 - INFO - Modelo RandomForest inicializado\n",
            "2025-10-17 13:51:02,729 - INFO - RandomForest configurado\n",
            "2025-10-17 13:51:02,729 - INFO - Modelo creado: RandomForest\n",
            "2025-10-17 13:51:02,729 - INFO - Modelo RandomForest creado exitosamente\n",
            "2025-10-17 13:51:02,736 - INFO - Modelo LogisticRegression inicializado\n",
            "2025-10-17 13:51:02,738 - INFO - LogisticRegression configurado\n",
            "2025-10-17 13:51:02,740 - INFO - Modelo creado: LogisticRegression\n",
            "2025-10-17 13:51:02,741 - INFO - Modelo LogisticRegression creado exitosamente\n",
            "2025-10-17 13:51:02,742 - INFO - Total de modelos creados: 6\n",
            "2025-10-17 13:51:02,742 - INFO - Iniciando entrenamiento de todos los modelos\n",
            "2025-10-17 13:51:02,742 - INFO - Entrenando XGBoost...\n",
            "2025-10-17 13:51:02,742 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:51:02,742 - INFO - Entrenando modelo XGBoost\n",
            "2025-10-17 13:51:02,754 - ERROR - Error entrenando modelo XGBoost: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
            "2025-10-17 13:51:02,757 - ERROR - ‚ùå Error entrenando XGBoost: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1 2]\n",
            "2025-10-17 13:51:02,757 - INFO - Entrenando CatBoost...\n",
            "2025-10-17 13:51:02,760 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:51:02,760 - INFO - Entrenando modelo CatBoost\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Creando y entrenando modelos de scoring crediticio...\n",
            "‚úÖ 6 modelos creados: ['XGBoost', 'CatBoost', 'LightGBM', 'HistGradientBoosting', 'RandomForest', 'LogisticRegression']\n",
            "\n",
            "üèãÔ∏è Entrenando modelos...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:51:03,289 - INFO - Modelo CatBoost entrenado exitosamente\n",
            "2025-10-17 13:51:03,305 - INFO - ‚úÖ CatBoost entrenado exitosamente\n",
            "2025-10-17 13:51:03,305 - INFO - Entrenando LightGBM...\n",
            "2025-10-17 13:51:03,305 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:51:03,305 - INFO - Entrenando modelo LightGBM\n",
            "2025-10-17 13:51:03,374 - INFO - Modelo LightGBM entrenado exitosamente\n",
            "2025-10-17 13:51:03,378 - INFO - ‚úÖ LightGBM entrenado exitosamente\n",
            "2025-10-17 13:51:03,378 - INFO - Entrenando HistGradientBoosting...\n",
            "2025-10-17 13:51:03,378 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:51:03,378 - INFO - Entrenando modelo HistGradientBoosting\n",
            "2025-10-17 13:51:03,708 - INFO - Modelo HistGradientBoosting entrenado exitosamente\n",
            "2025-10-17 13:51:03,708 - INFO - ‚úÖ HistGradientBoosting entrenado exitosamente\n",
            "2025-10-17 13:51:03,713 - INFO - Entrenando RandomForest...\n",
            "2025-10-17 13:51:03,715 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:51:03,715 - INFO - Entrenando modelo RandomForest\n",
            "2025-10-17 13:51:04,122 - INFO - Modelo RandomForest entrenado exitosamente\n",
            "2025-10-17 13:51:04,126 - INFO - ‚úÖ RandomForest entrenado exitosamente\n",
            "2025-10-17 13:51:04,126 - INFO - Entrenando LogisticRegression...\n",
            "2025-10-17 13:51:04,126 - INFO - Datos validados: 600 filas, 22 features\n",
            "2025-10-17 13:51:04,126 - INFO - Entrenando modelo LogisticRegression\n",
            "2025-10-17 13:51:04,142 - INFO - Modelo LogisticRegression entrenado exitosamente\n",
            "2025-10-17 13:51:04,142 - INFO - ‚úÖ LogisticRegression entrenado exitosamente\n",
            "2025-10-17 13:51:04,144 - INFO - Entrenamiento completado: 5/6 modelos exitosos\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ 5 modelos entrenados exitosamente\n",
            "\n",
            "üìä Resumen de entrenamiento:\n",
            "   Total modelos: 6\n",
            "   Modelos entrenados: 5\n",
            "   Tipos de modelos: ['CreditScoring']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Crear y entrenar todos los modelos\n",
        "if splits is not None:\n",
        "    print(\"ü§ñ Creando y entrenando modelos de scoring crediticio...\")\n",
        "    \n",
        "    # Crear todos los modelos\n",
        "    models = model_factory.create_all_models()\n",
        "    print(f\"‚úÖ {len(models)} modelos creados: {list(models.keys())}\")\n",
        "    \n",
        "    # Entrenar todos los modelos\n",
        "    print(\"\\nüèãÔ∏è Entrenando modelos...\")\n",
        "    trained_models = model_factory.train_all_models(X_train, y_train)\n",
        "    \n",
        "    print(f\"‚úÖ {len(trained_models)} modelos entrenados exitosamente\")\n",
        "    \n",
        "    # Mostrar resumen de entrenamiento\n",
        "    training_summary = model_factory.get_training_summary()\n",
        "    print(f\"\\nüìä Resumen de entrenamiento:\")\n",
        "    print(f\"   Total modelos: {training_summary['total_models']}\")\n",
        "    print(f\"   Modelos entrenados: {training_summary['trained_models']}\")\n",
        "    print(f\"   Tipos de modelos: {list(training_summary['model_types'].keys())}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No hay datos disponibles para entrenar modelos\")\n",
        "    models = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:51:18,944 - INFO - Evaluando todos los modelos\n",
            "2025-10-17 13:51:18,944 - WARNING - Modelo XGBoost no est√° entrenado\n",
            "2025-10-17 13:51:18,944 - INFO - Evaluando CatBoost...\n",
            "2025-10-17 13:51:18,944 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n",
            "2025-10-17 13:51:18,944 - INFO - Iniciando evaluaci√≥n de modelo de scoring crediticio\n",
            "2025-10-17 13:51:18,980 - WARNING - Error calculando AUC-PR: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n",
            "2025-10-17 13:51:18,980 - INFO - M√©tricas b√°sicas calculadas: AUC-ROC = 0.785\n",
            "2025-10-17 13:51:18,992 - INFO - PSI calculado: 0.4856\n",
            "2025-10-17 13:51:19,000 - INFO - Traffic Light calculado: 0.0% grupos verdes\n",
            "2025-10-17 13:51:19,008 - INFO - Estabilidad de poblaci√≥n calculada: score = 0.848\n",
            "2025-10-17 13:51:19,008 - INFO - M√©tricas de cr√©dito calculadas: 4 m√©tricas\n",
            "2025-10-17 13:51:19,008 - INFO - Evaluaci√≥n completada. Score general: 0.572\n",
            "2025-10-17 13:51:19,016 - INFO - Modelo CatBoost evaluado exitosamente\n",
            "2025-10-17 13:51:19,016 - INFO - ‚úÖ CatBoost evaluado exitosamente\n",
            "2025-10-17 13:51:19,018 - INFO - Evaluando LightGBM...\n",
            "2025-10-17 13:51:19,018 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n",
            "2025-10-17 13:51:19,023 - INFO - Iniciando evaluaci√≥n de modelo de scoring crediticio\n",
            "2025-10-17 13:51:19,060 - WARNING - Error calculando AUC-PR: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n",
            "2025-10-17 13:51:19,060 - INFO - M√©tricas b√°sicas calculadas: AUC-ROC = 0.729\n",
            "2025-10-17 13:51:19,080 - INFO - PSI calculado: 0.3366\n",
            "2025-10-17 13:51:19,086 - INFO - Traffic Light calculado: 0.0% grupos verdes\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Evaluando todos los modelos...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-17 13:51:19,159 - INFO - Estabilidad de poblaci√≥n calculada: score = 0.888\n",
            "2025-10-17 13:51:19,195 - INFO - M√©tricas de cr√©dito calculadas: 4 m√©tricas\n",
            "2025-10-17 13:51:19,199 - INFO - Evaluaci√≥n completada. Score general: 0.542\n",
            "2025-10-17 13:51:19,201 - INFO - Modelo LightGBM evaluado exitosamente\n",
            "2025-10-17 13:51:19,203 - INFO - ‚úÖ LightGBM evaluado exitosamente\n",
            "2025-10-17 13:51:19,212 - INFO - Evaluando HistGradientBoosting...\n",
            "2025-10-17 13:51:19,214 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n",
            "2025-10-17 13:51:19,216 - INFO - Iniciando evaluaci√≥n de modelo de scoring crediticio\n",
            "2025-10-17 13:51:19,508 - WARNING - Error calculando AUC-PR: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n",
            "2025-10-17 13:51:19,508 - INFO - M√©tricas b√°sicas calculadas: AUC-ROC = 0.744\n",
            "2025-10-17 13:51:19,537 - INFO - PSI calculado: 0.2420\n",
            "2025-10-17 13:51:19,542 - INFO - Traffic Light calculado: 0.0% grupos verdes\n",
            "2025-10-17 13:51:19,561 - INFO - Estabilidad de poblaci√≥n calculada: score = 0.902\n",
            "2025-10-17 13:51:19,563 - INFO - M√©tricas de cr√©dito calculadas: 4 m√©tricas\n",
            "2025-10-17 13:51:19,565 - INFO - Evaluaci√≥n completada. Score general: 0.554\n",
            "2025-10-17 13:51:19,565 - INFO - Modelo HistGradientBoosting evaluado exitosamente\n",
            "2025-10-17 13:51:19,565 - INFO - ‚úÖ HistGradientBoosting evaluado exitosamente\n",
            "2025-10-17 13:51:19,570 - INFO - Evaluando RandomForest...\n",
            "2025-10-17 13:51:19,580 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n",
            "2025-10-17 13:51:19,613 - INFO - Iniciando evaluaci√≥n de modelo de scoring crediticio\n",
            "2025-10-17 13:51:19,775 - WARNING - Error calculando AUC-PR: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n",
            "2025-10-17 13:51:19,777 - INFO - M√©tricas b√°sicas calculadas: AUC-ROC = 0.776\n",
            "2025-10-17 13:51:19,948 - INFO - PSI calculado: 1.3859\n",
            "2025-10-17 13:51:19,953 - INFO - Traffic Light calculado: 0.0% grupos verdes\n",
            "2025-10-17 13:51:20,077 - INFO - Estabilidad de poblaci√≥n calculada: score = 0.745\n",
            "2025-10-17 13:51:20,079 - INFO - M√©tricas de cr√©dito calculadas: 4 m√©tricas\n",
            "2025-10-17 13:51:20,079 - INFO - Evaluaci√≥n completada. Score general: 0.572\n",
            "2025-10-17 13:51:20,079 - INFO - Modelo RandomForest evaluado exitosamente\n",
            "2025-10-17 13:51:20,079 - INFO - ‚úÖ RandomForest evaluado exitosamente\n",
            "2025-10-17 13:51:20,079 - INFO - Evaluando LogisticRegression...\n",
            "2025-10-17 13:51:20,079 - INFO - CreditModelEvaluator inicializado con 5 m√©tricas\n",
            "2025-10-17 13:51:20,087 - INFO - Iniciando evaluaci√≥n de modelo de scoring crediticio\n",
            "2025-10-17 13:51:20,109 - WARNING - Error calculando AUC-PR: y_true takes value in {1, 2} and pos_label is not specified: either make y_true take value in {0, 1} or {-1, 1} or pass pos_label explicitly.\n",
            "2025-10-17 13:51:20,109 - INFO - M√©tricas b√°sicas calculadas: AUC-ROC = 0.757\n",
            "2025-10-17 13:51:20,131 - INFO - PSI calculado: 0.1063\n",
            "2025-10-17 13:51:20,134 - INFO - Traffic Light calculado: 0.0% grupos verdes\n",
            "2025-10-17 13:51:20,144 - INFO - Estabilidad de poblaci√≥n calculada: score = 0.932\n",
            "2025-10-17 13:51:20,144 - INFO - M√©tricas de cr√©dito calculadas: 4 m√©tricas\n",
            "2025-10-17 13:51:20,144 - INFO - Evaluaci√≥n completada. Score general: 0.567\n",
            "2025-10-17 13:51:20,144 - INFO - Modelo LogisticRegression evaluado exitosamente\n",
            "2025-10-17 13:51:20,144 - INFO - ‚úÖ LogisticRegression evaluado exitosamente\n",
            "2025-10-17 13:51:20,144 - INFO - Evaluaci√≥n completada: 5 modelos evaluados\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ 5 modelos evaluados exitosamente\n",
            "\n",
            "================================================================================\n",
            "üìà COMPARACI√ìN M√âTRICA A M√âTRICA DE TODOS LOS MODELOS\n",
            "================================================================================\n",
            "\n",
            "üìã TABLA COMPLETA DE M√âTRICAS:\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Modelo</th>\n",
              "      <th>AUC-ROC</th>\n",
              "      <th>AUC-PR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Gini</th>\n",
              "      <th>PSI</th>\n",
              "      <th>Traffic_Light_Green_%</th>\n",
              "      <th>Overall_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CatBoost</td>\n",
              "      <td>0.7850</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7134</td>\n",
              "      <td>0.730</td>\n",
              "      <td>0.7165</td>\n",
              "      <td>0.5700</td>\n",
              "      <td>0.4856</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LightGBM</td>\n",
              "      <td>0.7294</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7069</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.7102</td>\n",
              "      <td>0.4588</td>\n",
              "      <td>0.3366</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HistGradientBoosting</td>\n",
              "      <td>0.7438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7247</td>\n",
              "      <td>0.740</td>\n",
              "      <td>0.7270</td>\n",
              "      <td>0.4876</td>\n",
              "      <td>0.2420</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.7757</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7401</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.7376</td>\n",
              "      <td>0.5514</td>\n",
              "      <td>1.3859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.7567</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7507</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.7532</td>\n",
              "      <td>0.5133</td>\n",
              "      <td>0.1063</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Modelo  AUC-ROC  AUC-PR  Precision  Recall  F1-Score    Gini  \\\n",
              "0              CatBoost   0.7850     0.0     0.7134   0.730    0.7165  0.5700   \n",
              "1              LightGBM   0.7294     0.0     0.7069   0.725    0.7102  0.4588   \n",
              "2  HistGradientBoosting   0.7438     0.0     0.7247   0.740    0.7270  0.4876   \n",
              "3          RandomForest   0.7757     0.0     0.7401   0.755    0.7376  0.5514   \n",
              "4    LogisticRegression   0.7567     0.0     0.7507   0.760    0.7532  0.5133   \n",
              "\n",
              "      PSI  Traffic_Light_Green_%  Overall_Score  \n",
              "0  0.4856                    0.0         0.5716  \n",
              "1  0.3366                    0.0         0.5422  \n",
              "2  0.2420                    0.0         0.5537  \n",
              "3  1.3859                    0.0         0.5722  \n",
              "4  0.1063                    0.0         0.5666  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÜ RANKING POR M√âTRICA:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ü•á AUC-ROC:\n",
            "   1. CatBoost: 0.7850\n",
            "   2. RandomForest: 0.7757\n",
            "   3. LogisticRegression: 0.7567\n",
            "   4. HistGradientBoosting: 0.7438\n",
            "   5. LightGBM: 0.7294\n",
            "\n",
            "ü•á AUC-PR:\n",
            "   1. CatBoost: 0.0000\n",
            "   2. LightGBM: 0.0000\n",
            "   3. HistGradientBoosting: 0.0000\n",
            "   4. RandomForest: 0.0000\n",
            "   5. LogisticRegression: 0.0000\n",
            "\n",
            "ü•á PRECISION:\n",
            "   1. LogisticRegression: 0.7507\n",
            "   2. RandomForest: 0.7401\n",
            "   3. HistGradientBoosting: 0.7247\n",
            "   4. CatBoost: 0.7134\n",
            "   5. LightGBM: 0.7069\n",
            "\n",
            "ü•á RECALL:\n",
            "   1. LogisticRegression: 0.7600\n",
            "   2. RandomForest: 0.7550\n",
            "   3. HistGradientBoosting: 0.7400\n",
            "   4. CatBoost: 0.7300\n",
            "   5. LightGBM: 0.7250\n",
            "\n",
            "ü•á F1-SCORE:\n",
            "   1. LogisticRegression: 0.7532\n",
            "   2. RandomForest: 0.7376\n",
            "   3. HistGradientBoosting: 0.7270\n",
            "   4. CatBoost: 0.7165\n",
            "   5. LightGBM: 0.7102\n",
            "\n",
            "ü•á GINI:\n",
            "   1. CatBoost: 0.5700\n",
            "   2. RandomForest: 0.5514\n",
            "   3. LogisticRegression: 0.5133\n",
            "   4. HistGradientBoosting: 0.4876\n",
            "   5. LightGBM: 0.4588\n",
            "\n",
            "ü•á TRAFFIC_LIGHT_GREEN_%:\n",
            "   1. CatBoost: 0.0000\n",
            "   2. LightGBM: 0.0000\n",
            "   3. HistGradientBoosting: 0.0000\n",
            "   4. RandomForest: 0.0000\n",
            "   5. LogisticRegression: 0.0000\n",
            "\n",
            "ü•á OVERALL_SCORE:\n",
            "   1. RandomForest: 0.5722\n",
            "   2. CatBoost: 0.5716\n",
            "   3. LogisticRegression: 0.5666\n",
            "   4. HistGradientBoosting: 0.5537\n",
            "   5. LightGBM: 0.5422\n",
            "\n",
            "üíæ Resultados guardados en memoria para an√°lisis posterior\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Evaluar todos los modelos\n",
        "if models is not None:\n",
        "    print(\"üìä Evaluando todos los modelos...\")\n",
        "    \n",
        "    # Evaluar todos los modelos\n",
        "    results = model_factory.evaluate_all_models(X_test, y_test, X_train, y_train)\n",
        "    \n",
        "    print(f\"‚úÖ {len(results)} modelos evaluados exitosamente\")\n",
        "    \n",
        "    # Mostrar resultados m√©trica por m√©trica\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìà COMPARACI√ìN M√âTRICA A M√âTRICA DE TODOS LOS MODELOS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # Crear DataFrame con todas las m√©tricas\n",
        "    metrics_data = []\n",
        "    \n",
        "    for model_name, model_results in results.items():\n",
        "        row = {'Modelo': model_name}\n",
        "        \n",
        "        # M√©tricas b√°sicas\n",
        "        if 'basic_metrics' in model_results and 'error' not in model_results['basic_metrics']:\n",
        "            basic = model_results['basic_metrics']\n",
        "            row.update({\n",
        "                'AUC-ROC': basic.get('auc_roc', 0),\n",
        "                'AUC-PR': basic.get('auc_pr', 0),\n",
        "                'Precision': basic.get('precision', 0),\n",
        "                'Recall': basic.get('recall', 0),\n",
        "                'F1-Score': basic.get('f1_score', 0)\n",
        "            })\n",
        "        \n",
        "        # M√©tricas de cr√©dito\n",
        "        if 'credit_metrics' in model_results and 'error' not in model_results['credit_metrics']:\n",
        "            credit = model_results['credit_metrics']\n",
        "            row.update({\n",
        "                'Gini': credit.get('gini_coefficient', 0),\n",
        "                'PSI': credit.get('psi', 0)\n",
        "            })\n",
        "            \n",
        "            # Traffic Light\n",
        "            if 'traffic_light' in credit and 'error' not in credit['traffic_light']:\n",
        "                row['Traffic_Light_Green_%'] = credit['traffic_light'].get('green_percentage', 0)\n",
        "            else:\n",
        "                row['Traffic_Light_Green_%'] = 0\n",
        "        \n",
        "        # Score general\n",
        "        row['Overall_Score'] = model_results.get('overall_score', 0)\n",
        "        \n",
        "        metrics_data.append(row)\n",
        "    \n",
        "    # Crear DataFrame\n",
        "    metrics_df = pd.DataFrame(metrics_data)\n",
        "    \n",
        "    # Mostrar tabla completa\n",
        "    print(\"\\nüìã TABLA COMPLETA DE M√âTRICAS:\")\n",
        "    print(\"-\" * 80)\n",
        "    display(metrics_df.round(4))\n",
        "    \n",
        "    # Mostrar m√©tricas una por una con ranking\n",
        "    print(\"\\nüèÜ RANKING POR M√âTRICA:\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # Lista de m√©tricas para ranking\n",
        "    ranking_metrics = ['AUC-ROC', 'AUC-PR', 'Precision', 'Recall', 'F1-Score', \n",
        "                      'Gini', 'Traffic_Light_Green_%', 'Overall_Score']\n",
        "    \n",
        "    for metric in ranking_metrics:\n",
        "        if metric in metrics_df.columns:\n",
        "            print(f\"\\nü•á {metric.upper()}:\")\n",
        "            sorted_models = metrics_df.sort_values(metric, ascending=False)\n",
        "            for i, (_, row) in enumerate(sorted_models.iterrows(), 1):\n",
        "                print(f\"   {i}. {row['Modelo']}: {row[metric]:.4f}\")\n",
        "    \n",
        "    # Guardar resultados\n",
        "    print(f\"\\nüíæ Resultados guardados en memoria para an√°lisis posterior\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No hay modelos disponibles para evaluar\")\n",
        "    results = None"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
